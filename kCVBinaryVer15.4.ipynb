{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDuRoU5GXU0p"
   },
   "source": [
    "# □ 機械学習パイプライン：２値分類問題 with k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "foopEdtL--I5"
   },
   "source": [
    "Version 15.0  made on 2025.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzbaq5KJM9IU"
   },
   "source": [
    "https://chatgpt.com/share/68148702-d520-8005-aeb5-c3bb3d267bc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh6dULVo0hbS"
   },
   "source": [
    "# ◇ TabNet使用時は、最初にRuntime ⇒ Change Runtime Type から GPUを選択する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIeQk4Aypvvf"
   },
   "source": [
    "# ◆ 環境設定 (最初に実行するだけで良い)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czOpSYtHXsmr"
   },
   "source": [
    "## 1) ランタイムに接続 (Google Colaboratoryで使用する場合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "texxL2QzXq1k"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "from subprocess import check_output, CalledProcessError\n",
    "\n",
    "# 1) Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2) Print Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# 3) Detect whether GPU is available\n",
    "gpu_available = False\n",
    "gpu_name = None\n",
    "\n",
    "# Try with PyTorch (available by default in Colab)\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    if gpu_available:\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Fallback to nvidia-smi if torch isn’t available or didn’t detect\n",
    "if not gpu_available:\n",
    "    try:\n",
    "        output = check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"],\n",
    "            stderr=open('/dev/null', 'w')\n",
    "        ).decode().strip().split('\\n')\n",
    "        if output and output[0]:\n",
    "            gpu_available = True\n",
    "            gpu_name = output[0]\n",
    "    except (FileNotFoundError, CalledProcessError):\n",
    "        gpu_available = False\n",
    "\n",
    "# 4) Print engine and GPU name\n",
    "if gpu_available:\n",
    "    print(\"Engine: GPU\")\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"Engine: CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_zxi3imc1pu"
   },
   "source": [
    "## 2) Parameterの設定と必要なLibrary のインストール (四つのセルを順に評価する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BU82o_cBc404"
   },
   "outputs": [],
   "source": [
    "# Optuna trial counts\n",
    "n_trialsA = 80  # Lasso, Ridge\n",
    "n_trialsB = 20  # RandomForest\n",
    "n_trialsC = 60  # XGBoost\n",
    "n_trialsD = 40  # LightGBM\n",
    "\n",
    "# Optuna trial counts\n",
    "# model                 n_trials default\n",
    "# Lasso & Ridge         60\n",
    "# Random Forest         20\n",
    "# XGBoost               50\n",
    "# LightGBM              40\n",
    "# YDF                   30\n",
    "# LightGBMTuner         500 (num_boost_round)\n",
    "\n",
    "# Yggldrasi Decision Forest default parameters\n",
    "# n1 32  n2 32  step_size\n",
    "\n",
    "# SHAP value sample size\n",
    "shap_sample_size = 100\n",
    "\n",
    "# SHAPを行うか否か\n",
    "shap_for_random_forest = True\n",
    "shap_for_xgboost = True\n",
    "\n",
    "# LIMEを行うか否か\n",
    "perform_lime = True\n",
    "\n",
    "# Feature importance figure size\n",
    "size_x = 8\n",
    "size_y = 4.8\n",
    "\n",
    "# Default values for the project name and folder\n",
    "default_project_name = 'MLclassification'\n",
    "default_project_folder = 'AI'\n",
    "default_random_state = 42\n",
    "default_test_size = 0.2\n",
    "\n",
    "# Function to safely convert input to float\n",
    "def get_float_input(prompt, default):\n",
    "    while True:\n",
    "        user_input = input(prompt) or default\n",
    "        try:\n",
    "            value = float(user_input)\n",
    "            if 0.0 < value < 1.0:\n",
    "                return value\n",
    "            else:\n",
    "                print(\"Please enter a float between 0.0 and 1.0.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid float.\")\n",
    "\n",
    "\n",
    "# Function to safely convert input to int\n",
    "def get_int_input(prompt, default):\n",
    "    while True:\n",
    "        user_input = input(prompt) or default\n",
    "        try:\n",
    "            value = int(user_input)\n",
    "            if 0 <= value <= 4294967295:\n",
    "                return value\n",
    "            else:\n",
    "                print('Please enter an integer between 0 and 4294967295(=2**32-1)')\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\")\n",
    "\n",
    "print('■ Set a random_state [Press Return to use the default value: 42]')\n",
    "random_state = get_int_input(f'Enter the random state (自然数) (default {default_random_state}): ', default_random_state)\n",
    "print('')\n",
    "print(f'◇ Random State: {random_state}')\n",
    "print('')\n",
    "\n",
    "print('■ Set a test size [Press Return to use the default value: 0.2]')\n",
    "test_size = get_float_input(f'Enter the test size (0〜1) (default {default_test_size}): ', default_test_size)\n",
    "print('')\n",
    "print(f'◇ Test Size: {test_size}')\n",
    "print('')\n",
    "\n",
    "\n",
    "# Optunaのインストール\n",
    "!pip install optuna -q\n",
    "\n",
    "# XGBoostのインストール\n",
    "!pip3 install xgboost -q\n",
    "!pip3 install -q pydot\n",
    "!pip3 install graphviz -q\n",
    "\n",
    "# LightGBMTunerCVのためのインストール\n",
    "!pip install optuna-integration[lightgbm] -q\n",
    "\n",
    "# CatBoostのインストール\n",
    "!pip install catboost --quiet\n",
    "\n",
    "# 拡張子 xls を読み込むためのライブラリーのインストール\n",
    "!pip install xlrd -q\n",
    "\n",
    "# rickのインストール\n",
    "# !pip install rich\n",
    "\n",
    "# SHAPとLIMEのインストール\n",
    "!pip install shap -q\n",
    "!pip install lime -q\n",
    "!pip install imgkit -q\n",
    "\n",
    "# Noto Sans CJK JPフォントのダウンロードとインストール\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq fonts-noto-cjk\n",
    "\n",
    "# lifelinesのインストール (2024年7月の時点でErrorが出るがこのProgramには支障は出ない)\n",
    "!pip install lifelines --quiet\n",
    "print('')\n",
    "\n",
    "# Yggdrasil Decision Forestのインストール\n",
    "!pip install ydf -U -q\n",
    "\n",
    "# TabNetのインストール\n",
    "!pip install pytorch-tabnet -q\n",
    "# !pip install dill\n",
    "\n",
    "# 警告文の抑制\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xb9gyu3eqcb_"
   },
   "source": [
    "## 3) 分析対象の(xlsx, xls, csv)の読み込み: スクロールして出力の「ファイル選択」をクリック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uw9bz17SzCsG"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_excel_file():\n",
    "    # ファイルアップロードのためのダイアログを表示\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # アップロードされたファイル名を取得\n",
    "    if uploaded:\n",
    "        for filename in uploaded.keys():\n",
    "            # ファイルの拡張子がExcelファイルか確認\n",
    "            if filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
    "                # Excelファイルをpandasで読み込む\n",
    "                df = pd.read_excel(filename)\n",
    "                print('')\n",
    "                print(f\"読み込んだデータ:  {filename}\")\n",
    "                print('')\n",
    "            elif filename.endswith('.csv'):\n",
    "                df = pd.read_csv(filename)\n",
    "                print('')\n",
    "                print(f'読み込んだファイル:  {filename}')\n",
    "                print('')\n",
    "            else:\n",
    "                print(f\"アップロードされたファイル '{filename}' はExcelまたはCSVのファイルではありません。\")\n",
    "    else:\n",
    "        print(\"ファイルがアップロードされませんでした。\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# 関数を呼び出してExcelファイルを読み込む\n",
    "df = load_excel_file()\n",
    "print('')\n",
    "row0, col0 = df.shape\n",
    "print(f'■ データの次元: {row0}行 {col0}列')\n",
    "print('')\n",
    "print(df.head(10))\n",
    "print('')\n",
    "\n",
    "\n",
    "# データフレームに空のセルが一つでもあるかを確認\n",
    "if df.isnull().values.any():\n",
    "    # 空のセル（NaN）の数をカウント\n",
    "    num_missing = df.isna().sum().sum()\n",
    "    # 全てのセルの数をカウント\n",
    "    total_cells = df.size\n",
    "    # 空のセルの割合を計算\n",
    "    missing_percentage = (num_missing / total_cells) * 100\n",
    "    print(f\"◇ データフレームには{num_missing}個の空のセル(全セルの{round(missing_percentage,3)}%)があります。\")\n",
    "    print('')\n",
    "\n",
    "    # ユーザーに空のセルを削除するか中央値で置換するかを尋ねる\n",
    "    choice = input(\"◆ 空欄を削除しますか？ 中央値で補間しますか？ (削除/補間): \\n\")\n",
    "\n",
    "    if choice == '削除':\n",
    "        print('')\n",
    "        print('■ 空のセルを含むサンプルを削除します。')\n",
    "        print('')\n",
    "        initial_count = len(df)\n",
    "        df.dropna(inplace=True)\n",
    "        final_count = len(df)\n",
    "        deleted_count = initial_count - final_count\n",
    "        row, col = df.shape\n",
    "        print(f'□ {deleted_count} サンプル ({round(100*deleted_count/initial_count,2)}%) が削除されました。')\n",
    "        print(f'□ {final_count} サンプルが残っています。')\n",
    "        print('')\n",
    "        print(f'■ 削除後のデータの次元: {row}行 {col}列')\n",
    "        print('')\n",
    "        print('空のセルを削除した後のデータ')\n",
    "        print('')\n",
    "        print(df.head(10))\n",
    "    elif choice == '補間' or choice == '置換' or choice == '補完':\n",
    "        print('')\n",
    "        print('■ 空欄は中央値で置換します。')\n",
    "        print('')\n",
    "        samples_replaced = 0\n",
    "        # 各列で空のセルをチェックし、中央値で置き換える\n",
    "        for column in df.columns:\n",
    "            if df[column].isnull().any():  # 空のセルがあるかどうかを確認\n",
    "                median = df[column].median()  # その列の中央値を計算\n",
    "                samples_replaced += df[column].isnull().sum()  # 置換するサンプルの数をカウント\n",
    "                df[column].fillna(median, inplace=True)  # 空のセルを中央値で置き換え\n",
    "        row, col = df.shape\n",
    "        print(f'□ {samples_replaced} サンプル ({round(100*samples_replaced/row,2)}%) の空欄が中央値で置換されました。')\n",
    "        print('')\n",
    "        print('')\n",
    "        print(f'■ 置換後のデータの次元: {row}行 {col}列')\n",
    "        print('')\n",
    "        print('空欄を中央値で置換した後のデータ')\n",
    "        print('')\n",
    "        print(df.head(10))\n",
    "    else:\n",
    "        print('◇ 無効な選択です。何も変更しませんでした。')\n",
    "else:\n",
    "    print(\"◇ データフレームに空のセルはありません。\")\n",
    "\n",
    "\n",
    "# Numpyのデータの作成\n",
    "data = df.values\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# k setting for cross-validation\n",
    "n_samples = len(df)\n",
    "min_test_samples = 50\n",
    "k = max(2, np.floor(n_samples / min_test_samples).astype(int))\n",
    "max_k = 10\n",
    "k = min(k, max_k)\n",
    "if k < 3:\n",
    "    k = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XX2xHF6qZog"
   },
   "source": [
    "# ◆ プログラム：プロジェクト名と保存フォルダーの作成 (再計算のたびに実行する)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5y9z8Jk11J2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "%matplotlib inline\n",
    "from google.colab import files\n",
    "import pickle\n",
    "import os, sys\n",
    "import shap\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "from lime import lime_tabular\n",
    "\n",
    "\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "# Matplotlibのデフォルトフォント設定を変更\n",
    "# plt.rcParams['font.family'] = font_prop.get_name()\n",
    "\n",
    "\n",
    "\n",
    "# Detect whether GPU is available\n",
    "gpu_available = False\n",
    "gpu_name = None\n",
    "# Try with PyTorch (available by default in Colab)\n",
    "try:\n",
    "    import torch\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    if gpu_available:\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "except ImportError:\n",
    "    pass\n",
    "# Fallback to nvidia-smi if torch isn’t available or didn’t detect\n",
    "if not gpu_available:\n",
    "    try:\n",
    "        output = check_output(\n",
    "            [\"nvidia-smi\", \"--query-gpu=name\", \"--format=csv,noheader\"],\n",
    "            stderr=open('/dev/null', 'w')\n",
    "        ).decode().strip().split('\\n')\n",
    "        if output and output[0]:\n",
    "            gpu_available = True\n",
    "            gpu_name = output[0]\n",
    "    except (FileNotFoundError, CalledProcessError):\n",
    "        gpu_available = False\n",
    "\n",
    "\n",
    "\n",
    "# 計算結果の保存先の指定\n",
    "print('')\n",
    "print('■ Set a Project Name [Press Return to use the default name: MLclassification]')\n",
    "\n",
    "# Prompt the user for input, with defaults if nothing is entered\n",
    "project_name = input(f\"Enter the project name (default: {default_project_name}): \") or default_project_name\n",
    "print('')\n",
    "print(f'◇ プロジェクト名: {project_name}')\n",
    "\n",
    "print('')\n",
    "print('■ Set a Project Folder [Press Return to use the default folder: AI]')\n",
    "\n",
    "project_folder = input(f\"Enter the project folder (default: {default_project_folder}): \") or default_project_folder\n",
    "\n",
    "# Directory settings based on user input or defaults\n",
    "project_directory = '/content/drive/MyDrive/' + str(project_folder) + '/' + str(project_name)\n",
    "print('')\n",
    "print(f'◇ プロジェクトフォルダ: {project_directory}')\n",
    "\n",
    "# Run number logic\n",
    "try:\n",
    "    runnumber\n",
    "    runnumber += 1\n",
    "except NameError:\n",
    "    runnumber = 1\n",
    "\n",
    "# Create directories for results, models, and figures\n",
    "import os\n",
    "def create_directory(project_directory, folder_name, runnumber):\n",
    "    path_name = 'path_' + str(folder_name)\n",
    "    while True:\n",
    "        # ディレクトリパスを作成\n",
    "        path_new = os.path.join(project_directory, str(folder_name), f'run{runnumber}')\n",
    "\n",
    "        # ディレクトリが存在しない場合は作成\n",
    "        if not os.path.exists(path_new):\n",
    "            os.makedirs(path_new)\n",
    "            # print(f\"Directory created: {path_new}\")\n",
    "            return path_new\n",
    "\n",
    "        # ディレクトリが存在し、かつ、空である場合はそのディレクトリを使用\n",
    "        elif os.path.isdir(path_new) and not os.listdir(path_new):\n",
    "            # print(f\"Directory already exists and is empty: {path_new}\")\n",
    "            return path_new\n",
    "\n",
    "        # ディレクトリが存在し、かつ、空でない場合はrunnumberを増やして次のループで再試行\n",
    "        else:\n",
    "            # print(f\"Directory already exists and is not empty: {path_new}. Incrementing runnumber.\")\n",
    "            runnumber += 1\n",
    "\n",
    "path_table = create_directory(project_directory, 'table', runnumber)\n",
    "path_model = create_directory(project_directory, 'model', runnumber)\n",
    "path_figure = create_directory(project_directory, 'figure', runnumber)\n",
    "\n",
    "\n",
    "# Print the paths\n",
    "print('')\n",
    "print(f'◇ 作成した表の保存先: {path_table}')\n",
    "print('')\n",
    "print(f'◇ 予測モデルの保存先: {path_model}')\n",
    "print('')\n",
    "print(f'◇ 作成した図の保存先: {path_figure}')\n",
    "print('')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# assuming feature_names and label_column are already defined, e.g.:\n",
    "feature_names = df.columns[:-1]\n",
    "label_column  = df.columns[-1]\n",
    "\n",
    "try:\n",
    "    # perform numpy split\n",
    "    x_train, x_test, t_train, t_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # build pandas versions\n",
    "    x_train_pand = pd.DataFrame(x_train, columns=feature_names)\n",
    "    x_test_pand  = pd.DataFrame(x_test,  columns=feature_names)\n",
    "    t_train_pand = pd.Series(t_train, name=label_column)\n",
    "    t_test_pand  = pd.Series(t_test,  name=label_column)\n",
    "\n",
    "    print(\"◇ Train-test split successful (numpy & pandas).\")\n",
    "except Exception as e:\n",
    "    print(f\"◇ An error occurred during train-test split: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 以下補助関数の定義\n",
    "\n",
    "# Sigmoid関数 (to convert a numeric output into a probability in LIME)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 出力をProbability scoreに変換する関数\n",
    "def predict_proba(model, Z):\n",
    "    predictions = model.predict(Z)\n",
    "    return np.vstack([1-sigmoid(predictions), sigmoid(predictions)]).T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SHAPの共通関数。回帰問題にも分類問題にも対応\n",
    "def ShapValueFunction(model_made,\n",
    "                      df_data,\n",
    "                      x_train_data,\n",
    "                      x_test_data,\n",
    "                      size_x_value,\n",
    "                      size_y_value,\n",
    "                      path_figure_info,\n",
    "                      path_table_info,\n",
    "                      figure_name,\n",
    "                      excel_name,\n",
    "                      method_name,\n",
    "                      task_type='classification',\n",
    "                      model_type='general'):\n",
    "    \"\"\"\n",
    "    SHAP値およびBeeswarm図を作成し、結果を保存する関数。\n",
    "\n",
    "    Parameters:\n",
    "    - model_made: 学習済みモデル\n",
    "    - df_data: データフレーム（特徴量とターゲットを含む）\n",
    "    - x_train_data: 学習データの特徴量\n",
    "    - x_test_data: テストデータの特徴量\n",
    "    - size_x_value: プロットの横サイズ\n",
    "    - size_y_value: プロットの縦サイズ\n",
    "    - path_figure_info: 図の保存先パス\n",
    "    - path_table_info: テーブル（Excel）の保存先パス\n",
    "    - figure_name: 図のファイル名（拡張子なし）\n",
    "    - excel_name: Excelファイル名（拡張子なし）\n",
    "    - method_name: モデル名や手法名\n",
    "    - task_type: 'regression' または 'classification'\n",
    "    - model_type: 'tree', 'naive_bayes', 'general' など\n",
    "    \"\"\"\n",
    "\n",
    "    print('')\n",
    "    print(f'■ {method_name} モデルにおける 各変数の SHAP値（{task_type} 問題）')\n",
    "    print('')\n",
    "\n",
    "    import shap\n",
    "\n",
    "    try:\n",
    "        feature_names = df_data.columns[:-1]\n",
    "        # SHAPエクスプレイナーの初期化\n",
    "        if model_type == 'tree':\n",
    "            # 決定木ベースのモデル用\n",
    "            explainer = shap.TreeExplainer(model_made)\n",
    "            shap_values = explainer(x_test_data)\n",
    "\n",
    "        elif model_type == \"ydf\":\n",
    "            X_train_df = pd.DataFrame(x_train_data, columns=feature_names)\n",
    "            X_test_df = pd.DataFrame(x_test_data, columns=feature_names)\n",
    "            explainer = shap.TreeExplainer(model_made, X_train_df)\n",
    "\n",
    "            # create prediction function that provides column-wide dict\n",
    "            def ydf_predict(X):\n",
    "                X_df = pd.DataFrame(X, columns=feature_names)\n",
    "                X_dict = {col: X_df[col].values for col in X_df.columns}\n",
    "                return model_made.predict(X_dict)\n",
    "\n",
    "            explainer = shap.Explainer(ydf_predict, X_train_df)\n",
    "            shap_values = explainer(X_test_df)\n",
    "\n",
    "        else:\n",
    "            # その他のモデル用\n",
    "            explainer = shap.Explainer(model_made, x_train_data)\n",
    "            shap_values = explainer(x_test_data)\n",
    "\n",
    "        print('□ BarPlot of SHAP values')\n",
    "        # SHAP値のバーグラフをプロット\n",
    "        plt.figure(figsize=(size_x_value, size_y_value))\n",
    "        shap.summary_plot(shap_values,\n",
    "                          x_test_data,\n",
    "                          feature_names=df_data.columns[:-1],\n",
    "                          plot_type=\"bar\",\n",
    "                          show=False)\n",
    "\n",
    "        # Y軸のラベルフォントを変更\n",
    "        ax = plt.gca()\n",
    "        for label in ax.get_yticklabels():\n",
    "            try:\n",
    "                label.set_fontproperties(font_prop)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # SHAP値のバーグラフを保存\n",
    "        barplot_path = os.path.join(path_figure_info, f\"{figure_name}_barplot.png\")\n",
    "        plt.savefig(barplot_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()  # メモリ解放のためプロットを閉じる\n",
    "        print(f\"BarPlot saved to: {barplot_path}\")\n",
    "        print('')\n",
    "\n",
    "        print('□ DotPlot of SHAP values (Beeswarm Plot)')\n",
    "        # SHAP値のドットプロット（ビースウォームプロット）をプロット\n",
    "        plt.figure(figsize=(size_x_value, size_y_value))\n",
    "        shap.summary_plot(shap_values,\n",
    "                          x_test_data,\n",
    "                          feature_names=df_data.columns[:-1],\n",
    "                          plot_type=\"dot\",\n",
    "                          show=False)\n",
    "\n",
    "        # Y軸のラベルフォントを変更\n",
    "        ax = plt.gca()\n",
    "        for label in ax.get_yticklabels():\n",
    "            try:\n",
    "                label.set_fontproperties(font_prop)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # SHAP値のドットプロットを保存\n",
    "        dotplot_path = os.path.join(path_figure_info, f\"{figure_name}_dotplot.png\")\n",
    "        plt.savefig(dotplot_path, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()  # メモリ解放のためプロットを閉じる\n",
    "        print(f\"DotPlot saved to: {dotplot_path}\")\n",
    "        print('')\n",
    "\n",
    "        # 各特徴量の平均絶対SHAP値を計算\n",
    "        # feature_names = df_data.columns[:-1]\n",
    "        if isinstance(shap_values, shap.Explanation):\n",
    "            shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "        else:\n",
    "            shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "        # SHAP値をデータフレームに変換し、降順にソート\n",
    "        shap_df = pd.DataFrame(shap_sum, index=feature_names, columns=[\"SHAP Value\"]).sort_values(by=\"SHAP Value\", ascending=False)\n",
    "\n",
    "        # SHAP値をExcelファイルとしてエクスポート\n",
    "        shap_excel_filename = os.path.join(path_table_info, f\"{excel_name}.xlsx\")\n",
    "        shap_df.to_excel(shap_excel_filename, index=True)\n",
    "\n",
    "        print(f\"SHAP値が {shap_excel_filename} に保存されました。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        print(\"SHAP値の計算およびプロットをスキップします。\")\n",
    "\n",
    "\n",
    "\n",
    "# LIME解析（TabNet含む汎用対応）、インライン表示＋3種類の図を保存\n",
    "# 表示コードはそのまま、保存処理のみ追加しています\n",
    "def LimeContributionValueFunction(\n",
    "    model_made,\n",
    "    df_data,\n",
    "    x_train_data,\n",
    "    x_test_data,\n",
    "    t_test_data,\n",
    "    size_x_value,\n",
    "    size_y_value,\n",
    "    path_figure_info,\n",
    "    path_table_info,\n",
    "    figure_name,\n",
    "    excel_name,\n",
    "    method_name,\n",
    "    task_type='classification',\n",
    "    random_state=42,\n",
    "    model_type='general'\n",
    "):\n",
    "\n",
    "    from lime import lime_tabular\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import display\n",
    "\n",
    "    print('')\n",
    "    print(f'■ 各症例における {method_name} モデルのLIME分析（{task_type} 問題）')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df_data.columns[:-1]\n",
    "    label_column  = df_data.columns[-1]\n",
    "    num_features = min(len(feature_names), 10)\n",
    "\n",
    "    # --- データ整形 ---\n",
    "    if model_type == 'YDF':\n",
    "        X_train = pd.DataFrame(x_train_data, columns=feature_names) if isinstance(x_train_data, np.ndarray) else x_train_data.copy()\n",
    "        X_test  = pd.DataFrame(x_test_data,  columns=feature_names) if isinstance(x_test_data,  np.ndarray) else x_test_data.copy()\n",
    "        y_test  = pd.Series(t_test_data, name=label_column)       if isinstance(t_test_data, np.ndarray) else t_test_data.copy()\n",
    "    else:\n",
    "        X_train = x_train_data.values if hasattr(x_train_data, 'values') else np.array(x_train_data)\n",
    "        X_test  = x_test_data.values  if hasattr(x_test_data,  'values') else np.array(x_test_data)\n",
    "        y_test  = t_test_data.values  if hasattr(t_test_data,  'values') else np.array(t_test_data)\n",
    "\n",
    "    # --- LIME Explainer ---\n",
    "    if task_type == 'classification':\n",
    "        mode = 'classification'; class_names = ['NegativeClass','PositiveClass']\n",
    "    elif task_type == 'regression':\n",
    "        mode = 'regression';     class_names = None\n",
    "    else:\n",
    "        raise ValueError(\"task_type must be 'classification' or 'regression'\")\n",
    "\n",
    "    explainer = lime_tabular.LimeTabularExplainer(\n",
    "        training_data=np.array(X_train),\n",
    "        feature_names=feature_names.tolist(),\n",
    "        class_names=class_names,\n",
    "        mode=mode,\n",
    "        discretize_continuous=True\n",
    "    )\n",
    "\n",
    "    # --- 推論関数生成 ---\n",
    "    def get_predict_fn(model, feature_names, model_type='general'):\n",
    "        if model_type in ['general','YDF']:\n",
    "            def pred_fn(x):\n",
    "                x = np.array(x); x = np.atleast_2d(x) if x.ndim==1 else x\n",
    "                df_in = pd.DataFrame(x, columns=feature_names)\n",
    "                preds = np.array(model.predict(df_in)).flatten()\n",
    "                return np.column_stack([1-preds, preds])\n",
    "            return pred_fn\n",
    "        elif model_type=='TabNet':\n",
    "            def pred_fn(x):\n",
    "                x = np.array(x); x = np.atleast_2d(x) if x.ndim==1 else x\n",
    "                df_in = pd.DataFrame(x, columns=feature_names)\n",
    "                probs = []\n",
    "                for idx in range(len(df_in)):\n",
    "                    out = np.array(model.predict(df_in.iloc[[idx]]))\n",
    "                    if out.size==1: p=float(out)\n",
    "                    elif out.ndim==2 and out.shape[0]==1: p=out[0,1]\n",
    "                    else: raise ValueError(f\"Unexpected: {out.shape}\")\n",
    "                    probs.append(p)\n",
    "                return np.column_stack([1-np.array(probs), np.array(probs)])\n",
    "            return pred_fn\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "    base_predict_fn = get_predict_fn(model_made, feature_names, model_type)\n",
    "\n",
    "    # --- インスタンスサンプリング ---\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    total = X_test.shape[0]\n",
    "    n_inst = min(max(1, total//10), 100)\n",
    "    idxs = rng.choice(np.arange(total), size=n_inst, replace=False)[:2]\n",
    "\n",
    "    os.makedirs(path_figure_info, exist_ok=True)\n",
    "    os.makedirs(path_table_info, exist_ok=True)\n",
    "\n",
    "    for i in idxs:\n",
    "        target = y_test.iloc[i] if model_type=='YDF' else y_test[i]\n",
    "        print(f\"□ インスタンス {i} (target={target}) の LIME解析\")\n",
    "        print('')\n",
    "\n",
    "        # --- predict_fn 切替 ---\n",
    "        if task_type=='classification':\n",
    "            predict_fn = base_predict_fn if model_type=='TabNet' else (\n",
    "                model_made.predict_proba if hasattr(model_made,'predict_proba') else base_predict_fn\n",
    "            )\n",
    "        else:\n",
    "            predict_fn = model_made.predict\n",
    "\n",
    "        inst = X_test.iloc[i].values if model_type=='YDF' else X_test[i]\n",
    "        exp  = explainer.explain_instance(inst, predict_fn, num_features=num_features)\n",
    "\n",
    "        # --- 1) デフォルトLIMEプロット（表示＆保存） ---\n",
    "        exp.show_in_notebook(show_table=True)\n",
    "        fig1 = exp.as_pyplot_figure(); plt.show()\n",
    "        fig1_path = os.path.join(path_figure_info, f\"{figure_name}_instance_{i}_default.png\")\n",
    "        fig1.savefig(fig1_path, bbox_inches='tight')\n",
    "        plt.close(fig1)\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        # --- 2) 横棒グラフ（表示＆保存） ---\n",
    "        df_cont = pd.DataFrame({f:[c] for f,c in exp.as_list()}).T\n",
    "        df_cont.columns = [f'Instance_{i}']\n",
    "\n",
    "\n",
    "        # --- 3) テーブルプロット（表示＆保存） ---\n",
    "        display(df_cont)\n",
    "        fig3, ax3 = plt.subplots(figsize=(size_x_value, size_y_value))\n",
    "        ax3.axis('off')\n",
    "        tbl = ax3.table(\n",
    "            cellText=df_cont.values,\n",
    "            rowLabels=df_cont.index,\n",
    "            colLabels=df_cont.columns,\n",
    "            loc='center'\n",
    "        )\n",
    "        tbl.auto_set_font_size(False); tbl.set_fontsize(8)\n",
    "        plt.show()\n",
    "        fig3_path = os.path.join(path_table_info, f\"{excel_name}_instance_{i}_table.png\")\n",
    "        fig3.savefig(fig3_path, bbox_inches='tight')\n",
    "        plt.close(fig3)\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "        # --- Excel保存 ---\n",
    "        excel_path = os.path.join(path_table_info, f\"{excel_name}_instance_{i}.xlsx\")\n",
    "        df_cont.to_excel(excel_path)\n",
    "\n",
    "        print(\n",
    "            f\"Saved figures for instance {i}:\\n\"\n",
    "            f\"  1) Default: {os.path.basename(fig1_path)}\\n\"\n",
    "            # f\"  2) Barh:    {os.path.basename(fig2_path)}\\n\"\n",
    "            f\"  2) Table:   {os.path.basename(fig3_path)}\\n\"\n",
    "            f\"And Excel:   {os.path.basename(excel_path)}\\n\"\n",
    "        )\n",
    "        print('')\n",
    "        print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def display_fold_averages(\n",
    "        k,\n",
    "        df,\n",
    "        fold_cm_percent,\n",
    "        fold_tp_rate,\n",
    "        fold_fp_rate,\n",
    "        fold_fn_rate,\n",
    "        fold_tn_rate,\n",
    "        mean_acc,\n",
    "        mean_prec,\n",
    "        mean_rec,\n",
    "        mean_f1,\n",
    "        mean_spec,\n",
    "        mean_auc,\n",
    "        mean_cind,\n",
    "        mean_prerec,\n",
    "        model_name\n",
    "        ):\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"LightGBMTunerOptuna kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"lightgbmtuneroptuna_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"LightGBMOptuna kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"lightgbmoptuna_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"LightGBM kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"lightgbm_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"MLP kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"mlp_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"AdaBoost kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"adaboost_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"GradientBoosting kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"gradientboosting_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"GaussianProcess kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"gaussianprocess_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"LinearDiscriminantAnalysis kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    hmname = \"lineardiscriminantanalysis_confusion_heatmap_kfCV.png\"\n",
    "    hmpath = os.path.join(path_figure, hmname)\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    print('')\n",
    "    print(f'■ {k}-fold Cross Validation を用いた {model_name} による2値分類の評価結果')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "    print('□　データのサンプル数: ' + str(len(df)))\n",
    "    print('')\n",
    "    print('□　Fold-Averageによる混同行列(%): ')\n",
    "    print(pd.DataFrame(fold_cm_percent,  index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'] ))\n",
    "    print('')\n",
    "    print(f'真陽性 {100*fold_tp_rate:.2f} %, 偽陽性 {100*fold_fp_rate:.2f} %, 偽陰性 {100*fold_fn_rate:.2f} %, 真陰性 {100*fold_tn_rate:.2f} %')\n",
    "    print('')\n",
    "    print(f'   Accuracy(正解率):  {mean_acc:.5f}   precision(精度):  {mean_prec:.5f}    recall(再現率=感度):  {mean_rec:.5f}')\n",
    "    print(f'   f1-score(f1値):  {mean_f1:.5f}   specificity(特異度):  {mean_spec:.5f}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                        [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent,\n",
    "        fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec,\n",
    "        mean_auc, mean_cind, mean_prerec,\n",
    "        \"LinearDiscriminantAnalysis kfCV\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n□ fold-averaged confusion matrix heat-map:\\n\")\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        fold_cm_percent, annot=True, fmt=\".2f\", cbar=False,\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.title(\"fold-averaged Confusion Matrix (%)\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "\n",
    "    print(f'   AUC of ROC curve:  {mean_auc:.5f}    C-index (c-Statistics):  {mean_cind:.5f}')\n",
    "    print(f'   AUC of Precision-Recall plot: {mean_prerec:.5f}')\n",
    "    print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#　　以下、各種機械学習の定義\n",
    "\n",
    "# simple Linear Regression\n",
    "def LinearKFold(k=k, show_shap=True, perform_lime=True, threshold=0.5):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        roc_curve, precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Linear Regression kfCV　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold instead of KFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    aucs = []\n",
    "    accs = []\n",
    "    precs = []\n",
    "    recs = []\n",
    "    f1s = []\n",
    "    specs = []\n",
    "    aps = []\n",
    "\n",
    "    # For ROC and Precision-Recall curve plotting per fold\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates = []\n",
    "    fp_rates = []\n",
    "    fn_rates = []\n",
    "    tp_rates = []\n",
    "\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        lr.fit(X_train, y_train)\n",
    "        predictions = lr.predict(X_test)\n",
    "        # Binarize predictions for classification metrics\n",
    "        predictions_round = [1 if p >= threshold else 0 for p in predictions]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, predictions_round).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Compute metrics per fold\n",
    "        auc_fold = roc_auc_score(y_test, predictions)\n",
    "        acc_fold = accuracy_score(y_test, predictions_round)\n",
    "        prec_fold = precision_score(y_test, predictions_round)\n",
    "        rec_fold = recall_score(y_test, predictions_round)\n",
    "        f1_fold = f1_score(y_test, predictions_round)\n",
    "        ap_fold = average_precision_score(y_test, predictions)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs.append(auc_fold)\n",
    "        accs.append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s.append(f1_fold)\n",
    "        specs.append(spec_fold)\n",
    "        aps.append(ap_fold)\n",
    "\n",
    "        # Compute ROC curve for this fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        # Compute Precision-Recall curve for this fold\n",
    "        precision_vals, recall_vals, _ = precision_recall_curve(y_test, predictions)\n",
    "        precisions.append(precision_vals)\n",
    "        recalls.append(recall_vals)\n",
    "\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = np.mean(aucs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    hmname = 'linear_confusion_heatmap_kfCV.png'\n",
    "    rocname = 'linear_roc_curve_kfCV.png'\n",
    "    prerecname = 'linear_prerec_curve_kfCV.png'\n",
    "    hmpath=os.path.join(path_figure, hmname)\n",
    "    rocpath=os.path.join(path_figure, rocname)\n",
    "    prerecpath=os.path.join(path_figure, prerecname)\n",
    "\n",
    "    # -----------------True fold-averaged confusion matrix-----------------\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                         [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_percent = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_percent, fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Linear Regression kfCV\"\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_percent, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('fold-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    # Interpolate each fold's TPR at mean_fpr\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_linear = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'Linear Regression'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        # Sort by recall for interpolation\n",
    "        idx_sort = np.argsort(recalls[i])\n",
    "        recall_sorted = recalls[i][idx_sort]\n",
    "        precision_sorted = precisions[i][idx_sort]\n",
    "        precisions_interp.append(np.interp(mean_recall, recall_sorted, precision_sorted))\n",
    "    mean_precision_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_precision_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecpath)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Retrain the model on the full dataset-----------------\n",
    "    model_full = LinearRegression()\n",
    "    model_full.fit(X, y)\n",
    "\n",
    "    # Saving the full model\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_filename = os.path.join(path_model, 'linear_model_full.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # -----------------Feature importance (coefficients) extraction-----------------\n",
    "    feature_importances = model_full.coef_\n",
    "    column_names = df.columns[:-1]\n",
    "    feature_importances_df = pd.DataFrame({'Feature': column_names, 'Importance': feature_importances})\n",
    "    feature_importances_df['Abs_Importance'] = feature_importances_df['Importance'].abs()\n",
    "    feature_importances_df = feature_importances_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    excel_filename = os.path.join(path_table, 'linear_feature_importances_kfCV.xlsx')\n",
    "    feature_importances_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    # Print top 10 features\n",
    "    importance_sorted_idx = np.argsort(np.abs(feature_importances))[::-1]\n",
    "    top_idxs = importance_sorted_idx[:10]\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('■ Linear Regression model の 係数による Feature Importance')\n",
    "    print('')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    # plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(range(len(top_idxs)), feature_importances[top_idxs], align='center')\n",
    "    plt.yticks(range(len(top_idxs)), [column_names[i] for i in top_idxs])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Linear Regression')\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.gca().invert_yaxis()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'linear_feature_importances_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Hold-out method for SHAP and LIME analyses-----------------\n",
    "    model_holdout = LinearRegression()\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'linear_shap_values_holdout', 'linear_shap_values_holdout',\n",
    "            'Linear Regression', task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'linear_lime_explanation_holdout', 'linear_lime_feature_contributions_holdout',\n",
    "            'Linear Regression', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # -----------------Prepare and return results-----------------\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame([res], columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'], index=['Linear Regression'])\n",
    "\n",
    "    return [res2, roc_linear]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lasso Regression with normalization and fold-Averaged metrics\n",
    "def LassoKFoldN(alpha=0.01, k=k, show_shap=True, perform_lime=True, threshold=0.5):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import (\n",
    "        mean_squared_error, roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Lasso Regression normalized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    lasso = Lasso(alpha=alpha, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulators\n",
    "    feature_importances = np.zeros((X.shape[1],))\n",
    "    aucs, accs, precs, recs, f1s, aps = [], [], [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    specs, aps = [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        lasso.fit(x_train_scaled, y_train)\n",
    "        predictions = lasso.predict(x_test_scaled)\n",
    "\n",
    "        # Feature importance accumulation\n",
    "        feature_importances += np.abs(lasso.coef_)\n",
    "\n",
    "        # Binarize for classification metrics\n",
    "        preds_round = [1 if p >= threshold else 0 for p in predictions]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_round).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # Compute metrics\n",
    "        aucs.append(roc_auc_score(y_test, predictions))\n",
    "        accs.append(accuracy_score(y_test, preds_round))\n",
    "        precs.append(precision_score(y_test, preds_round, zero_division=0))\n",
    "        recs.append(recall_score(y_test, preds_round))\n",
    "        f1s.append(f1_score(y_test, preds_round))\n",
    "        aps.append(average_precision_score(y_test, predictions))\n",
    "        specs.append(tn/(tn+fp))\n",
    "\n",
    "        # ROC and PR curves per fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, predictions)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_ap = np.mean(aps)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = np.mean(aucs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "\n",
    "    # File paths\n",
    "    hmname = os.path.join(path_figure, 'lasso_normalized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'lasso_normalized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'lasso_normalized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # fold-averaged confusion matrix\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                         [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct, fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Lasso Regression Normalized kfCV\"\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_lassoN = np.array([mean_fpr, mean_tpr, mean_auc, 'Lasso Regression normalized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged ROC Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-ROC (AUC={mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_rec_all = np.linspace(0,1,100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_rec_all, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged Precision-Recall Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_all, mean_prec_curve, label=f'fold-PR (AP={mean_ap:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Feature importance (coefficients) extraction-----------------\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    exname = os.path.join(path_table, 'lasso_feature_importances_normalized_kfCV.xlsx')\n",
    "    feat_df.to_excel(exname, index=False)\n",
    "\n",
    "    print('')\n",
    "    print('◇ Top 10 Feature Importances (fold-Averaged):')\n",
    "    print('')\n",
    "    top_idx = np.argsort(feature_importances)[-10:]\n",
    "    top_feats = feature_names[top_idx]\n",
    "    top_imps = feature_importances[top_idx]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Lasso Regression normalized')\n",
    "    plt.barh(top_feats, top_imps, color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_feature_importances_normalized_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = Lasso(alpha=alpha, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'lasso_model_normalized_full.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_full, f)\n",
    "\n",
    "\n",
    "    # -----------------Hold-out method for SHAP and LIME analyses-----------------\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = Lasso(alpha=alpha, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_normalized_shap_values_holdout', 'lasso_normalized_shap_values_holdout',\n",
    "            'Lasso Regression normalized', task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_normalized_lime_explanation_holdout', 'lasso_normalized_lime_feature_contributions_holdout',\n",
    "            'Lasso Regression normalized', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=[f'Lasso Regression normalized (α={alpha:.4f})']\n",
    "    )\n",
    "    return [res2, roc_lassoN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lasso Regression with standardization and fold-Averaged metrics\n",
    "def LassoKFoldS(alpha=0.01, k=k, show_shap=True, perform_lime=True, threshold=0.5):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.metrics import (\n",
    "        mean_squared_error, roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Lasso Regression standardized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    lasso = Lasso(alpha=alpha, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulators\n",
    "    feature_importances = np.zeros((X.shape[1],))\n",
    "    aucs, accs, precs, recs, f1s, aps = [], [], [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    specs, aps = [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        lasso.fit(x_train_scaled, y_train)\n",
    "        predictions = lasso.predict(x_test_scaled)\n",
    "\n",
    "        # Feature importance accumulation\n",
    "        feature_importances += np.abs(lasso.coef_)\n",
    "\n",
    "        # Binarize for classification metrics\n",
    "        preds_round = [1 if p >= threshold else 0 for p in predictions]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_round).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # Compute metrics\n",
    "        aucs.append(roc_auc_score(y_test, predictions))\n",
    "        accs.append(accuracy_score(y_test, preds_round))\n",
    "        precs.append(precision_score(y_test, preds_round, zero_division=0))\n",
    "        recs.append(recall_score(y_test, preds_round))\n",
    "        f1s.append(f1_score(y_test, preds_round))\n",
    "        aps.append(average_precision_score(y_test, predictions))\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # ROC and PR curves per fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, predictions)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_ap = np.mean(aps)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = np.mean(aucs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # File paths\n",
    "    hmname = os.path.join(path_figure, 'lasso_standardized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'lasso_standardized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'lasso_standardized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # fold-averaged confusion matrix\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                         [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct, fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Lasso Regression standardized kfCV\"\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_lassoS = np.array([mean_fpr, mean_tpr, mean_auc, 'Lasso Regression standardized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged ROC Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-ROC (AUC={mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_rec_all = np.linspace(0,1,100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_rec_all, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged Precision-Recall Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_all, mean_prec_curve, label=f'fold-PR (AP={mean_ap:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Feature importance (coefficients) extraction-----------------\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    exname = os.path.join(path_table, 'lasso_feature_importances_standardized_kfCV.xlsx')\n",
    "    feat_df.to_excel(exname, index=False)\n",
    "\n",
    "    print('')\n",
    "    print('◇ Top 10 Feature Importances (fold-Averaged):')\n",
    "    print('')\n",
    "    top_idx = np.argsort(feature_importances)[-10:]\n",
    "    top_feats = feature_names[top_idx]\n",
    "    top_imps = feature_importances[top_idx]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Lasso Regression standardized')\n",
    "    plt.barh(top_feats, top_imps, color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_feature_importances_standardized_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = Lasso(alpha=alpha, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'lasso_model_standardized_full.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_full, f)\n",
    "\n",
    "\n",
    "    # -----------------Hold-out method for SHAP and LIME analyses-----------------\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = Lasso(alpha=alpha, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_standardized_shap_values_holdout', 'lasso_standardized_shap_values_holdout',\n",
    "            'Lasso Regression standardized', task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_standardized_lime_explanation_holdout', 'lasso_standardized_lime_feature_contributions_holdout',\n",
    "            'Lasso Regression standardized', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=[f'Lasso Regression standardized (α={alpha:.4f})']\n",
    "    )\n",
    "    return [res2, roc_lassoS]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def LassoKFoldOptunaN(k=k, show_shap=True, perform_lime=True, n_trials=50, threshold=0.5, target='logloss'):\n",
    "    import os\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import optuna\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import Lasso, Ridge\n",
    "    from sklearn.model_selection import StratifiedKFold, KFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve,\n",
    "        average_precision_score, mean_squared_error, log_loss\n",
    "    )\n",
    "\n",
    "    # Header for Optuna-based optimization\n",
    "    print('')\n",
    "    print(f'■■■ Lasso Regression normalized kfCV with Optuna (Optimizing {target}, Trial count {n_trials})■■■')\n",
    "    print('')\n",
    "\n",
    "    # Objective for Optuna: minimize the selected target metric (MSE or log-loss)\n",
    "    def objective(trial):\n",
    "        # Suggest alpha\n",
    "        alpha = trial.suggest_float('alpha', 0.0001, 10.0, log=True)\n",
    "        # Stratified K-Fold for balanced splits\n",
    "        kf_inner = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf_inner.split(X, y):\n",
    "            xx_train, xx_test = X[train_idx], X[test_idx]\n",
    "            tt_train, tt_test = y[train_idx], y[test_idx]\n",
    "            scaler_inner = MinMaxScaler()\n",
    "            xx_tr_scaled = scaler_inner.fit_transform(xx_train)\n",
    "            xx_te_scaled = scaler_inner.transform(xx_test)\n",
    "            model = Ridge(alpha=alpha, random_state=random_state)\n",
    "            model.fit(xx_tr_scaled, tt_train)\n",
    "            preds = model.predict(xx_te_scaled)\n",
    "            if target == 'mse':\n",
    "                scores.append(mean_squared_error(tt_test, preds))\n",
    "            elif target == 'logloss':\n",
    "                preds_clipped = np.clip(preds, 1e-15, 1-1e-15)\n",
    "                scores.append(log_loss(tt_test, preds_clipped))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown target: {target}  The target must be either logloss or mse.\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Create and run study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_alpha = study.best_trial.params['alpha']\n",
    "    best_trial_no = study.best_trial.number\n",
    "\n",
    "    # Log best trial\n",
    "    print('')\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization with Optuna for Lasso Regression normalized (detailed logs below)')\n",
    "    print(f'Best trial #{best_trial_no} for minimizing {target.upper()}:')\n",
    "    print(f'  Value: {study.best_trial.value:.4f}')\n",
    "    print('  Params:')\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        print(f'    {key}: {val}')\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler_full = MinMaxScaler()\n",
    "    X_scaled_full = scaler_full.fit_transform(X)\n",
    "    best_model_full = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "    best_model_full.fit(X_scaled_full, y)\n",
    "\n",
    "    # Save full model\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_file = os.path.join(path_model, 'lasso_model_full_normalized_kfCV_optuna.pkl')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(best_model_full, f)\n",
    "\n",
    "    # Header for fold-averaged CV\n",
    "    print('')\n",
    "    print('■■■ Lasso Regression normalized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Stratified K-Fold for fold metrics\n",
    "    kf_outer = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    # Initialize accumulators\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, pr_prec, pr_rec = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for tr_idx, te_idx in kf_outer.split(X, y):\n",
    "        X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        scaler_cv = MinMaxScaler()\n",
    "        X_tr_s = scaler_cv.fit_transform(X_tr)\n",
    "        X_te_s = scaler_cv.transform(X_te)\n",
    "\n",
    "        model_cv = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "        model_cv.fit(X_tr_s, y_tr)\n",
    "        preds_cont = model_cv.predict(X_te_s)\n",
    "        preds_bin = [1 if p >= threshold else 0 for p in preds_cont]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, preds_bin).ravel()\n",
    "        tot = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / tot)\n",
    "        fp_rates.append(fp / tot)\n",
    "        fn_rates.append(fn / tot)\n",
    "        tp_rates.append(tp / tot)\n",
    "        specs.append(tn / (tn + fp))  # specificity\n",
    "\n",
    "        # Metrics\n",
    "        aucs.append(roc_auc_score(y_te, preds_cont))\n",
    "        accs.append(accuracy_score(y_te, preds_bin))\n",
    "        precs.append(precision_score(y_te, preds_bin, zero_division=0))\n",
    "        recs.append(recall_score(y_te, preds_bin))\n",
    "        f1s.append(f1_score(y_te, preds_bin))\n",
    "        aps.append(average_precision_score(y_te, preds_cont))\n",
    "\n",
    "        # Curves\n",
    "        fpr, tpr, _ = roc_curve(y_te, preds_cont)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        pr_p, pr_r, _ = precision_recall_curve(y_te, preds_cont)\n",
    "        pr_prec.append(pr_p); pr_rec.append(pr_r)\n",
    "\n",
    "    # fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = mean_auc\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # fold confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn], [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Lasso Regression normalized with Optuna\"\n",
    "    )\n",
    "\n",
    "    # Plot heatmap\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_normalized_confusion_heatmap_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot ROC\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_lassoNoptuna = np.array([mean_fpr, mean_tpr, mean_auc, 'Lasso Regression normalized with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_normalized_roc_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot Precision-Recall\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(pr_rec)):\n",
    "        idx = np.argsort(pr_rec[i])\n",
    "        pr_interp.append(np.interp(mean_recall, pr_rec[i][idx], pr_prec[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(pr_rec)): plt.plot(pr_rec[i], pr_prec[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_normalized_prerec_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Prepare results\n",
    "    res_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Lasso Regression normalized with Optuna']\n",
    "    )\n",
    "    res = [res_df, roc_lassoNoptuna]\n",
    "\n",
    "    # Feature importance for best full model\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation と Optuna で得られた Lasso Regression normalized の Best Model における Feature Importance')\n",
    "    print('')\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_imp = np.abs(best_model_full.coef_)\n",
    "    sorted_idx = np.argsort(feat_imp)[-10:]\n",
    "    sorted_imp = feat_imp[sorted_idx]\n",
    "    sorted_feat = feature_names[sorted_idx]\n",
    "\n",
    "    fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': feat_imp})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    os.makedirs(path_table, exist_ok=True)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'lasso_normalized_feature_importances_kfCV_optuna.xlsx'), index=False)\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Lasso Regression normalized kfCV with Optuna')\n",
    "    plt.barh(sorted_feat, sorted_imp)\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_normalized_feature_importances_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Hold-out analysis for SHAP and LIME\n",
    "    scaler_ho = MinMaxScaler()\n",
    "    x_train_s = scaler_ho.fit_transform(x_train)\n",
    "    x_test_s = scaler_ho.transform(x_test)\n",
    "    hold_model = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "    hold_model.fit(x_train_s, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_normalized_shap_values_holdout_optuna',\n",
    "            'lasso_normalized_shap_values_holdout_optuna',\n",
    "            'Lasso Regression normalized with Optuna',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_normalized_lime_explanation_holdout_optuna',\n",
    "            'lasso_normalized_lime_feature_contributions_holdout_optuna',\n",
    "            'Lasso Regression normalized with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LassoKFoldOptunaS(k=k, show_shap=True, perform_lime=True, n_trials=50, threshold=0.5, target='logloss'):\n",
    "    import os\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import optuna\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import Lasso, Ridge\n",
    "    from sklearn.model_selection import StratifiedKFold, KFold\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve,\n",
    "        average_precision_score, mean_squared_error, log_loss\n",
    "    )\n",
    "\n",
    "    # Header for Optuna-based optimization\n",
    "    print('')\n",
    "    print(f'■■■ Lasso Regression standardized kfCV with Optuna (Optimizing {target}, Trial count {n_trials}) ■■■')\n",
    "    print('')\n",
    "\n",
    "    # Objective for Optuna: minimize the selected target metric (MSE or log-loss)\n",
    "    def objective(trial):\n",
    "        alpha = trial.suggest_float('alpha', 0.0001, 10.0, log=True)\n",
    "        kf_inner = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf_inner.split(X, y):\n",
    "            xx_train, xx_test = X[train_idx], X[test_idx]\n",
    "            tt_train, tt_test = y[train_idx], y[test_idx]\n",
    "            scaler_inner = StandardScaler()\n",
    "            xx_tr_scaled = scaler_inner.fit_transform(xx_train)\n",
    "            xx_te_scaled = scaler_inner.transform(xx_test)\n",
    "            model = Ridge(alpha=alpha, random_state=random_state)\n",
    "            model.fit(xx_tr_scaled, tt_train)\n",
    "            preds = model.predict(xx_te_scaled)\n",
    "            if target == 'mse':\n",
    "                scores.append(mean_squared_error(tt_test, preds))\n",
    "            elif target == 'logloss':\n",
    "                preds_clipped = np.clip(preds, 1e-15, 1-1e-15)\n",
    "                scores.append(log_loss(tt_test, preds_clipped))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown target: {target}. Must be 'logloss' or 'mse'.\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_alpha = study.best_trial.params['alpha']\n",
    "    best_trial_no = study.best_trial.number\n",
    "\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization with Optuna for Lasso Regression standardized (detailed logs below)')\n",
    "    print(f'Best trial #{best_trial_no} for minimizing {target.upper()}:')\n",
    "    print(f'  Value: {study.best_trial.value:.4f}')\n",
    "    print('  Params:')\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        print(f'    {key}: {val}')\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler_full = StandardScaler()\n",
    "    X_scaled_full = scaler_full.fit_transform(X)\n",
    "    best_model_full = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "    best_model_full.fit(X_scaled_full, y)\n",
    "\n",
    "    # Save full model\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_file = os.path.join(path_model, 'lasso_model_full_standardized_kfCV_optuna.pkl')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(best_model_full, f)\n",
    "\n",
    "    # Header for fold-averaged CV\n",
    "    print('')\n",
    "    print('■■■ Lasso Regression standardized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    kf_outer = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, pr_prec, pr_rec = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    for tr_idx, te_idx in kf_outer.split(X, y):\n",
    "        X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        scaler_cv = StandardScaler()\n",
    "        X_tr_s = scaler_cv.fit_transform(X_tr)\n",
    "        X_te_s = scaler_cv.transform(X_te)\n",
    "\n",
    "        model_cv = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "        model_cv.fit(X_tr_s, y_tr)\n",
    "        preds_cont = model_cv.predict(X_te_s)\n",
    "        preds_bin = [1 if p >= threshold else 0 for p in preds_cont]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, preds_bin).ravel()\n",
    "        tot = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / tot)\n",
    "        fp_rates.append(fp / tot)\n",
    "        fn_rates.append(fn / tot)\n",
    "        tp_rates.append(tp / tot)\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        aucs.append(roc_auc_score(y_te, preds_cont))\n",
    "        accs.append(accuracy_score(y_te, preds_bin))\n",
    "        precs.append(precision_score(y_te, preds_bin, zero_division=0))\n",
    "        recs.append(recall_score(y_te, preds_bin))\n",
    "        f1s.append(f1_score(y_te, preds_bin))\n",
    "        aps.append(average_precision_score(y_te, preds_cont))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_te, preds_cont)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        pr_p, pr_r, _ = precision_recall_curve(y_te, preds_cont)\n",
    "        pr_prec.append(pr_p); pr_rec.append(pr_r)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = mean_auc\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # fold confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn], [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-average table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Lasso Regression standardized with Optuna\"\n",
    "    )\n",
    "\n",
    "    # Plot fold confusion heatmap\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_standardized_confusion_heatmap_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_lassoSoptuna = np.array([mean_fpr, mean_tpr, mean_auc, 'Lasso Regression standardized with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_standardized_roc_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold PR curve\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(pr_rec)):\n",
    "        idx = np.argsort(pr_rec[i])\n",
    "        pr_interp.append(np.interp(mean_recall, pr_rec[i][idx], pr_prec[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(pr_rec)): plt.plot(pr_rec[i], pr_prec[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_standardized_prerec_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Prepare results\n",
    "    res_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Lasso Regression standardized with Optuna']\n",
    "    )\n",
    "    res = [res_df, roc_lassoSoptuna]\n",
    "\n",
    "    # Feature importance for best full model\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation と Optuna で得られた Lasso Regression standardized の Best Model における Feature Importance')\n",
    "    print('')\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_imp = np.abs(best_model_full.coef_)\n",
    "    sorted_idx = np.argsort(feat_imp)[-10:]\n",
    "    sorted_imp = feat_imp[sorted_idx]\n",
    "    sorted_feat = feature_names[sorted_idx]\n",
    "\n",
    "    fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': feat_imp})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    os.makedirs(path_table, exist_ok=True)\n",
    "    excel_file = os.path.join(path_table, 'lasso_standardized_feature_importances_kfCV_optuna.xlsx')\n",
    "    fi_df.to_excel(excel_file, index=False)\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Lasso Regression standardized kfCV with Optuna')\n",
    "    plt.barh(sorted_feat, sorted_imp)\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'lasso_standardized_feature_importances_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Hold-out analysis for SHAP and LIME\n",
    "    scaler_ho = StandardScaler()\n",
    "    x_train_s = scaler_ho.fit_transform(x_train)\n",
    "    x_test_s = scaler_ho.transform(x_test)\n",
    "    hold_model = Lasso(alpha=best_alpha, random_state=random_state)\n",
    "    hold_model.fit(x_train_s, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_standardized_shap_values_holdout_optuna',\n",
    "            'lasso_standardized_shap_values_holdout_optuna',\n",
    "            'Lasso Regression standardized with Optuna',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lasso_standardized_lime_explanation_holdout_optuna',\n",
    "            'lasso_standardized_lime_feature_contributions_holdout_optuna',\n",
    "            'Lasso Regression standardized with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ridge Regression with normalization and fold-Averaged metrics\n",
    "def RidgeKFoldN(alpha=0.01, k=k, show_shap=True, perform_lime=True, threshold=0.5):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import (\n",
    "        mean_squared_error, roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Ridge Regression normalized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    ridge = Ridge(alpha=alpha, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulators\n",
    "    feature_importances = np.zeros((X.shape[1],))\n",
    "    aucs, accs, precs, recs, f1s, aps = [], [], [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    specs, aps = [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        ridge.fit(x_train_scaled, y_train)\n",
    "        predictions = ridge.predict(x_test_scaled)\n",
    "\n",
    "        # Feature importance accumulation\n",
    "        feature_importances += np.abs(ridge.coef_)\n",
    "\n",
    "        # Binarize for classification metrics\n",
    "        preds_round = [1 if p >= threshold else 0 for p in predictions]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_round).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # Compute metrics\n",
    "        aucs.append(roc_auc_score(y_test, predictions))\n",
    "        accs.append(accuracy_score(y_test, preds_round))\n",
    "        precs.append(precision_score(y_test, preds_round, zero_division=0))\n",
    "        recs.append(recall_score(y_test, preds_round))\n",
    "        f1s.append(f1_score(y_test, preds_round))\n",
    "        aps.append(average_precision_score(y_test, predictions))\n",
    "        specs.append(tn/(tn+fp))\n",
    "\n",
    "        # ROC and PR curves per fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, predictions)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_ap = np.mean(aps)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = np.mean(aucs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "\n",
    "    # File paths\n",
    "    hmname = os.path.join(path_figure, 'ridge_normalized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'ridge_normalized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'ridge_normalized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # fold-averaged confusion matrix\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                         [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct, fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Ridge Regression normalized\"\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_ridgeN = np.array([mean_fpr, mean_tpr, mean_auc, 'Ridge Regression normalized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged ROC Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-ROC (AUC={mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_rec_all = np.linspace(0,1,100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_rec_all, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged Precision-Recall Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_all, mean_prec_curve, label=f'fold-PR (AP={mean_ap:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Feature importance (coefficients) extraction-----------------\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    exname = os.path.join(path_table, 'ridge_feature_importances_normalized_kfCV.xlsx')\n",
    "    feat_df.to_excel(exname, index=False)\n",
    "\n",
    "    print('')\n",
    "    print('◇ Top 10 Feature Importances (fold-Averaged):')\n",
    "    print('')\n",
    "    top_idx = np.argsort(feature_importances)[-10:]\n",
    "    top_feats = feature_names[top_idx]\n",
    "    top_imps = feature_importances[top_idx]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Ridge Regression normalized')\n",
    "    plt.barh(top_feats, top_imps, color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_feature_importances_normalized_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = Ridge(alpha=alpha, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'ridge_model_normalized_full.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_full, f)\n",
    "\n",
    "\n",
    "    # -----------------Hold-out method for SHAP and LIME analyses-----------------\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = Ridge(alpha=alpha, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_normalized_shap_values_holdout', 'ridge_normalized_shap_values_holdout',\n",
    "            'Ridge Regression normalized', task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_normalized_lime_explanation_holdout', 'ridge_normalized_lime_feature_contributions_holdholdout',\n",
    "            'Ridge Regression normalized', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=[f'Ridge Regression normalized (α={alpha:.4f})']\n",
    "    )\n",
    "    return [res2, roc_ridgeN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ridge Regression with normalization and fold-Averaged metrics\n",
    "def RidgeKFoldS(alpha=0.01, k=k, show_shap=True, perform_lime=True, threshold=0.5):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.metrics import (\n",
    "        mean_squared_error, roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Ridge Regression standardized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    ridge = Ridge(alpha=alpha, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulators\n",
    "    feature_importances = np.zeros((X.shape[1],))\n",
    "    aucs, accs, precs, recs, f1s, aps = [], [], [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    specs, aps = [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        ridge.fit(x_train_scaled, y_train)\n",
    "        predictions = ridge.predict(x_test_scaled)\n",
    "\n",
    "        # Feature importance accumulation\n",
    "        feature_importances += np.abs(ridge.coef_)\n",
    "\n",
    "        # Binarize for classification metrics\n",
    "        preds_round = [1 if p >= threshold else 0 for p in predictions]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, preds_round).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # Compute metrics\n",
    "        aucs.append(roc_auc_score(y_test, predictions))\n",
    "        accs.append(accuracy_score(y_test, preds_round))\n",
    "        precs.append(precision_score(y_test, preds_round, zero_division=0))\n",
    "        recs.append(recall_score(y_test, preds_round))\n",
    "        f1s.append(f1_score(y_test, preds_round))\n",
    "        aps.append(average_precision_score(y_test, predictions))\n",
    "        specs.append(tn/(tn+fp))\n",
    "\n",
    "        # ROC and PR curves per fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, predictions)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, predictions)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_ap = np.mean(aps)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = np.mean(aucs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "\n",
    "    # File paths\n",
    "    hmname = os.path.join(path_figure, 'ridge_standardized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'ridge_standardized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'ridge_standardized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # fold-averaged confusion matrix\n",
    "    fold_tn_rate = np.mean(tn_rates)\n",
    "    fold_fp_rate = np.mean(fp_rates)\n",
    "    fold_fn_rate = np.mean(fn_rates)\n",
    "    fold_tp_rate = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn_rate, fold_fn_rate],\n",
    "                         [fold_fp_rate, fold_tp_rate]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct, fold_tp_rate, fold_fp_rate, fold_fn_rate, fold_tn_rate,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1, mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Ridge Regression standardized\"\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_ridgeS = np.array([mean_fpr, mean_tpr, mean_auc, 'Ridge Regression standardized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged ROC Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-ROC (AUC={mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_rec_all = np.linspace(0,1,100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_rec_all, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ fold-Averaged Precision-Recall Curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_all, mean_prec_curve, label=f'fold-PR (AP={mean_ap:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------Feature importance (coefficients) extraction-----------------\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    exname = os.path.join(path_table, 'ridge_feature_importances_standardized_kfCV.xlsx')\n",
    "    feat_df.to_excel(exname, index=False)\n",
    "\n",
    "    print('')\n",
    "    print('◇ Top 10 Feature Importances (fold-Averaged):')\n",
    "    print('')\n",
    "    top_idx = np.argsort(feature_importances)[-10:]\n",
    "    top_feats = feature_names[top_idx]\n",
    "    top_imps = feature_importances[top_idx]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Ridge Regression standardized')\n",
    "    plt.barh(top_feats, top_imps, color='skyblue')\n",
    "    plt.xlabel('Importance')\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_feature_importances_standardized_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = Ridge(alpha=alpha, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'ridge_model_standardized_full.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_full, f)\n",
    "\n",
    "\n",
    "    # -----------------Hold-out method for SHAP and LIME analyses-----------------\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = Ridge(alpha=alpha, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_shap_values_holdout_standardized', 'ridge_shap_values_holdout_standardized',\n",
    "            'Ridge Regression standardized', task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_lime_explanation_holdout_standardized', 'ridge_lime_feature_contributions_holdholdout_standardized',\n",
    "            'Ridge Regression standardized', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=[f'Ridge Regression standardized (α={alpha:.4f})']\n",
    "    )\n",
    "    return [res2, roc_ridgeS]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RidgeKFoldOptunaN(k=k, show_shap=True, perform_lime=True, n_trials=50, threshold=0.5, target='logloss'):\n",
    "    import os\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import optuna\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.model_selection import StratifiedKFold, KFold\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve,\n",
    "        average_precision_score, mean_squared_error, log_loss\n",
    "    )\n",
    "\n",
    "    # Header for Optuna-based optimization\n",
    "    print('')\n",
    "    print(f'■■■ Ridge Regression normalized kfCV with Optuna (Optimizing {target}, Trial count {n_trials}) ■■■')\n",
    "    print('')\n",
    "\n",
    "    # Objective for Optuna: minimize the selected target metric (MSE or log-loss)\n",
    "    def objective(trial):\n",
    "        # Suggest alpha\n",
    "        alpha = trial.suggest_float('alpha', 0.0001, 10.0, log=True)\n",
    "        # Stratified K-Fold for balanced splits\n",
    "        kf_inner = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf_inner.split(X, y):\n",
    "            xx_train, xx_test = X[train_idx], X[test_idx]\n",
    "            tt_train, tt_test = y[train_idx], y[test_idx]\n",
    "            scaler_inner = MinMaxScaler()\n",
    "            xx_tr_scaled = scaler_inner.fit_transform(xx_train)\n",
    "            xx_te_scaled = scaler_inner.transform(xx_test)\n",
    "            model = Ridge(alpha=alpha, random_state=random_state)\n",
    "            model.fit(xx_tr_scaled, tt_train)\n",
    "            preds = model.predict(xx_te_scaled)\n",
    "            if target == 'mse':\n",
    "                scores.append(mean_squared_error(tt_test, preds))\n",
    "            elif target == 'logloss':\n",
    "                preds_clipped = np.clip(preds, 1e-15, 1-1e-15)\n",
    "                scores.append(log_loss(tt_test, preds_clipped))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown target: {target}. Must be either 'logloss' or 'mse'.\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    # Create and run study\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_alpha = study.best_trial.params['alpha']\n",
    "    best_trial_no = study.best_trial.number\n",
    "\n",
    "    # Log best trial\n",
    "    print('')\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization with Optuna for Ridge Regression normalized (detailed logs below)')\n",
    "    print(f'Best trial #{best_trial_no} for minimizing {target.upper()}:')\n",
    "    print(f'  Value: {study.best_trial.value:.4f}')\n",
    "    print('  Params:')\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        print(f'    {key}: {val}')\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler_full = MinMaxScaler()\n",
    "    X_scaled_full = scaler_full.fit_transform(X)\n",
    "    best_model_full = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "    best_model_full.fit(X_scaled_full, y)\n",
    "\n",
    "    # Save full model\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_file = os.path.join(path_model, 'ridge_normalize_model_fulld_kfCV_optuna.pkl')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(best_model_full, f)\n",
    "\n",
    "    # Header for fold-averaged CV\n",
    "    print('')\n",
    "    print('■■■ Ridge Regression normalized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Stratified K-Fold for fold metrics\n",
    "    kf_outer = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, pr_prec, pr_rec = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    # Cross-validation loop\n",
    "    for tr_idx, te_idx in kf_outer.split(X, y):\n",
    "        X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        scaler_cv = MinMaxScaler()\n",
    "        X_tr_s = scaler_cv.fit_transform(X_tr)\n",
    "        X_te_s = scaler_cv.transform(X_te)\n",
    "\n",
    "        model_cv = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "        model_cv.fit(X_tr_s, y_tr)\n",
    "        preds_cont = model_cv.predict(X_te_s)\n",
    "        preds_bin = [1 if p >= threshold else 0 for p in preds_cont]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, preds_bin).ravel()\n",
    "        tot = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / tot)\n",
    "        fp_rates.append(fp / tot)\n",
    "        fn_rates.append(fn / tot)\n",
    "        tp_rates.append(tp / tot)\n",
    "        specs.append(tn / (tn + fp))  # specificity\n",
    "\n",
    "        # Metrics\n",
    "        aucs.append(roc_auc_score(y_te, preds_cont))\n",
    "        accs.append(accuracy_score(y_te, preds_bin))\n",
    "        precs.append(precision_score(y_te, preds_bin, zero_division=0))\n",
    "        recs.append(recall_score(y_te, preds_bin))\n",
    "        f1s.append(f1_score(y_te, preds_bin))\n",
    "        aps.append(average_precision_score(y_te, preds_cont))\n",
    "\n",
    "        # Curves\n",
    "        fpr, tpr, _ = roc_curve(y_te, preds_cont)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        pr_p, pr_r, _ = precision_recall_curve(y_te, preds_cont)\n",
    "        pr_prec.append(pr_p); pr_rec.append(pr_r)\n",
    "\n",
    "    # fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = mean_auc\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # fold confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn], [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-average table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Ridge Regression normalized with Optuna\"\n",
    "    )\n",
    "\n",
    "    # Plot fold confusion heatmap\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_normalized_confusion_heatmap_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_ridgeNoptuna = np.array([mean_fpr, mean_tpr, mean_auc, 'Ridge Regression normalized with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_normalized_roc_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold PR curve\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(pr_rec)):\n",
    "        idx = np.argsort(pr_rec[i])\n",
    "        pr_interp.append(np.interp(mean_recall, pr_rec[i][idx], pr_prec[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(pr_rec)): plt.plot(pr_rec[i], pr_prec[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_normalized_prerec_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Prepare results\n",
    "    res_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Ridge Regression normalized with Optuna']\n",
    "    )\n",
    "    res = [res_df, roc_ridgeNoptuna]\n",
    "\n",
    "    # Feature importance for best full model\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation と Optuna で得られた Ridge Regression normalized の Best Model における Feature Importance')\n",
    "    print('')\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_imp = np.abs(best_model_full.coef_)\n",
    "    sorted_idx = np.argsort(feat_imp)[-10:]\n",
    "    sorted_imp = feat_imp[sorted_idx]\n",
    "    sorted_feat = feature_names[sorted_idx]\n",
    "\n",
    "    fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': feat_imp})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    os.makedirs(path_table, exist_ok=True)\n",
    "    excel_file = os.path.join(path_table, 'ridge_normalized_feature_importances_kfCV_optuna.xlsx')\n",
    "    fi_df.to_excel(excel_file, index=False)\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Ridge Regression normalized kfCV with Optuna')\n",
    "    plt.barh(sorted_feat, sorted_imp)\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_normalized_feature_importances_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Hold-out analysis for SHAP and LIME\n",
    "    scaler_ho = MinMaxScaler()\n",
    "    x_train_s = scaler_ho.fit_transform(x_train)\n",
    "    x_test_s = scaler_ho.transform(x_test)\n",
    "    hold_model = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "    hold_model.fit(x_train_s, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_normalized_shap_values_holdout',\n",
    "            'ridge_normalized_shap_values_holdout',\n",
    "            'Ridge Regression normalized with Optuna',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_normalized_lime_explanation_holdout_optuna',\n",
    "            'ridge_normalized_lime_feature_contributions_holdout_optuna',\n",
    "            'Ridge Regression normalized with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RidgeKFoldOptunaS(k=k, show_shap=True, perform_lime=True, n_trials=50, threshold=0.5, target='logloss'):\n",
    "    import os\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import optuna\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "    import seaborn as sns\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.model_selection import StratifiedKFold, KFold\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve,\n",
    "        average_precision_score, mean_squared_error, log_loss\n",
    "    )\n",
    "\n",
    "    # Header for Optuna-based optimization\n",
    "    print('')\n",
    "    print(f'■■■ Ridge Regression standardized kfCV with Optuna (Optimized {target}, Trial count {n_trials}) ■■■')\n",
    "    print('')\n",
    "\n",
    "    # Objective for Optuna: minimize the selected target metric (MSE or log-loss)\n",
    "    def objective(trial):\n",
    "        alpha = trial.suggest_float('alpha', 0.0001, 10.0, log=True)\n",
    "        kf_inner = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        scores = []\n",
    "        for train_idx, test_idx in kf_inner.split(X, y):\n",
    "            xx_train, xx_test = X[train_idx], X[test_idx]\n",
    "            tt_train, tt_test = y[train_idx], y[test_idx]\n",
    "            scaler_inner = StandardScaler()\n",
    "            xx_tr_scaled = scaler_inner.fit_transform(xx_train)\n",
    "            xx_te_scaled = scaler_inner.transform(xx_test)\n",
    "            model = Ridge(alpha=alpha, random_state=random_state)\n",
    "            model.fit(xx_tr_scaled, tt_train)\n",
    "            preds = model.predict(xx_te_scaled)\n",
    "            if target == 'mse':\n",
    "                scores.append(mean_squared_error(tt_test, preds))\n",
    "            elif target == 'logloss':\n",
    "                preds_clipped = np.clip(preds, 1e-15, 1-1e-15)\n",
    "                scores.append(log_loss(tt_test, preds_clipped))\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown target: {target}. Must be 'logloss' or 'mse'.\")\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_alpha = study.best_trial.params['alpha']\n",
    "    best_trial_no = study.best_trial.number\n",
    "\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization with Optuna for Ridge Regression standardized (detailed logs below)')\n",
    "    print(f'Best trial #{best_trial_no} for minimizing {target.upper()}:')\n",
    "    print(f'  Value: {study.best_trial.value:.4f}')\n",
    "    print('  Params:')\n",
    "    for key, val in study.best_trial.params.items():\n",
    "        print(f'    {key}: {val}')\n",
    "    print('')\n",
    "\n",
    "    # Retrain on full dataset\n",
    "    scaler_full = StandardScaler()\n",
    "    X_scaled_full = scaler_full.fit_transform(X)\n",
    "    best_model_full = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "    best_model_full.fit(X_scaled_full, y)\n",
    "\n",
    "    # Save full model\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_file = os.path.join(path_model, 'ridge_standardized_model_full_kfCV_optuna.pkl')\n",
    "    with open(model_file, 'wb') as f:\n",
    "        pickle.dump(best_model_full, f)\n",
    "\n",
    "    # Header for fold-averaged CV\n",
    "    print('')\n",
    "    print('■■■ Ridge Regression standardized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    kf_outer = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, pr_prec, pr_rec = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    for tr_idx, te_idx in kf_outer.split(X, y):\n",
    "        X_tr, X_te = X[tr_idx], X[te_idx]\n",
    "        y_tr, y_te = y[tr_idx], y[te_idx]\n",
    "        scaler_cv = StandardScaler()\n",
    "        X_tr_s = scaler_cv.fit_transform(X_tr)\n",
    "        X_te_s = scaler_cv.transform(X_te)\n",
    "\n",
    "        model_cv = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "        model_cv.fit(X_tr_s, y_tr)\n",
    "        preds_cont = model_cv.predict(X_te_s)\n",
    "        preds_bin = [1 if p >= threshold else 0 for p in preds_cont]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, preds_bin).ravel()\n",
    "        tot = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / tot)\n",
    "        fp_rates.append(fp / tot)\n",
    "        fn_rates.append(fn / tot)\n",
    "        tp_rates.append(tp / tot)\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        aucs.append(roc_auc_score(y_te, preds_cont))\n",
    "        accs.append(accuracy_score(y_te, preds_bin))\n",
    "        precs.append(precision_score(y_te, preds_bin, zero_division=0))\n",
    "        recs.append(recall_score(y_te, preds_bin))\n",
    "        f1s.append(f1_score(y_te, preds_bin))\n",
    "        aps.append(average_precision_score(y_te, preds_cont))\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_te, preds_cont)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        pr_p, pr_r, _ = precision_recall_curve(y_te, preds_cont)\n",
    "        pr_prec.append(pr_p); pr_rec.append(pr_r)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_cind = mean_auc\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # fold confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn], [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-average table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Ridge Regression standardized with Optuna\"\n",
    "    )\n",
    "\n",
    "    # Plot fold confusion heatmap\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_standardized_confusion_heatmap_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    roc_ridgeSoptuna = np.array([mean_fpr, mean_tpr, mean_auc, 'Ridge Regression standardized_with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_standardized_roc_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold PR curve\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(pr_rec)):\n",
    "        idx = np.argsort(pr_rec[i])\n",
    "        pr_interp.append(np.interp(mean_recall, pr_rec[i][idx], pr_prec[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(pr_rec)): plt.plot(pr_rec[i], pr_prec[i], alpha=0.3)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_standardized_prerec_curve_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Prepare results\n",
    "    res_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Ridge Regression standardized with Optuna']\n",
    "    )\n",
    "    res = [res_df, roc_ridgeSoptuna]\n",
    "\n",
    "    # Feature importance for best full model\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation と Optuna で得られた Ridge Regression standardized の Best Model における Feature Importance')\n",
    "    print('')\n",
    "    feature_names = df.columns[:-1]\n",
    "    feat_imp = np.abs(best_model_full.coef_)\n",
    "    sorted_idx = np.argsort(feat_imp)[-10:]\n",
    "    sorted_imp = feat_imp[sorted_idx]\n",
    "    sorted_feat = feature_names[sorted_idx]\n",
    "\n",
    "    fi_df = pd.DataFrame({'Feature': feature_names, 'Importance': feat_imp})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    os.makedirs(path_table, exist_ok=True)\n",
    "    excel_file = os.path.join(path_table, 'ridge_standardized_feature_importances_kfCV_optuna.xlsx')\n",
    "    fi_df.to_excel(excel_file, index=False)\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Ridge Regression standardized kfCV with Optuna')\n",
    "    plt.barh(sorted_feat, sorted_imp)\n",
    "    ax = plt.gca()\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'ridge_standardized_feature_importances_kfCV_optuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Hold-out analysis for SHAP and LIME\n",
    "    scaler_ho = StandardScaler()\n",
    "    x_train_s = scaler_ho.fit_transform(x_train)\n",
    "    x_test_s = scaler_ho.transform(x_test)\n",
    "    hold_model = Ridge(alpha=best_alpha, random_state=random_state)\n",
    "    hold_model.fit(x_train_s, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_standardized_shap_values_holdout',\n",
    "            'ridge_standardized_shap_values_holdout',\n",
    "            'Ridge Regression standardized with Optuna',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            hold_model, df, x_train_s, x_test_s, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'ridge_standardized_lime_explanation_holdout_optuna',\n",
    "            'ridge_standardized_lime_feature_contributions_holdout_optuna',\n",
    "            'Ridge Regression standardized with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression normalized kfCV with fold-Averaged metrics\n",
    "def LogisticKFoldN(k=k, show_shap=True, perform_lime=True):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    # Hold-out 用のデータの分割\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Logistic Regression normalized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold instead of KFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    # For ROC and Precision-Recall curves per fold\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    # Initialize accumulator for feature importances\n",
    "    feature_importances = np.zeros((df.shape[1] - 1,))\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_pred_probs = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Initialize and fit the Logistic Regression model\n",
    "        model = LogisticRegression(random_state=random_state)\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "\n",
    "        # Accumulate feature importances (absolute coefficients)\n",
    "        feature_importances += np.abs(model.coef_[0])\n",
    "\n",
    "        # Predict classes and probabilities\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        # specificity\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        aucs.append(roc_auc_score(y_test, y_pred_prob))\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        precs.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recs.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        aps.append(average_precision_score(y_test, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test)\n",
    "        all_pred_probs.extend(y_pred_prob)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "    mean_cind = mean_auc\n",
    "\n",
    "    # Compute true fold-averaged confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Logistic Regression normalized\"\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "\n",
    "    # Paths for figures\n",
    "    hmname = os.path.join(path_figure, 'logistic_normalized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'logistic_normalized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'logistic_normalized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # Plot fold-averaged confusion matrix heatmap\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged ROC curve\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_logisticN = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'Logistic Regression normalized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged Precision-Recall curve\n",
    "    mean_rec_curve = np.linspace(0,1,100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Average the feature importances over all folds\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    sorted_idx = np.argsort(feature_importances)[-10:]\n",
    "    sorted_importance = feature_importances[sorted_idx]\n",
    "    sorted_features = feature_names[sorted_idx]\n",
    "\n",
    "    # Export feature importances\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    excel_filename = os.path.join(path_table, 'logistic_normalized_feature_importances_kfCV.xlsx')\n",
    "    feat_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation で得られた Logistic Regression normalized における Feature Importance')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_features, sorted_importance, color='skyblue')\n",
    "    plt.xlabel('Average Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Logistic Regression normalized')\n",
    "    font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    plt.savefig(os.path.join(path_figure, 'logistic_normalized_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = LogisticRegression(random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'logistic_normalized_model_full.pkl'), 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = LogisticRegression(random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap == True:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'logistic_normalized_shap_values_holdout',\n",
    "            'logistic_normalized_shap_values_holdout',\n",
    "            'Logistic Regression normalized',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            t_test, size_x, size_y, path_figure, path_table,\n",
    "            'logistic_normalized_lime_explanation_holdout',\n",
    "            'logistic_normalized_lime_feature_contributions_holdout',\n",
    "            'Logistic Regression normalized',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['Logistic Regression normalized']\n",
    "    )\n",
    "    return [res2, roc_logisticN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression standardized kfCV with fold-Averaged metrics\n",
    "def LogisticKFoldS(k=k, show_shap=True, perform_lime=True):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    # Hold-out 用のデータの分割\n",
    "    x_train, x_test, t_train, t_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Logistic Regression standardized kfCV with fold-Averaged metrics　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold instead of KFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    # For ROC and Precision-Recall curves per fold\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    # Initialize accumulator for feature importances\n",
    "    feature_importances = np.zeros((df.shape[1] - 1,))\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_pred_probs = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        x_train_scaled = scaler.fit_transform(X_train)\n",
    "        x_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Initialize and fit the Logistic Regression model\n",
    "        model = LogisticRegression(random_state=random_state)\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "\n",
    "        # Accumulate feature importances (absolute coefficients)\n",
    "        feature_importances += np.abs(model.coef_[0])\n",
    "\n",
    "        # Predict classes and probabilities\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        # specificity\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        aucs.append(roc_auc_score(y_test, y_pred_prob))\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        precs.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recs.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        aps.append(average_precision_score(y_test, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(prec_vals); recalls.append(rec_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test)\n",
    "        all_pred_probs.extend(y_pred_prob)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(aucs)\n",
    "    mean_acc = np.mean(accs)\n",
    "    mean_prec = np.mean(precs)\n",
    "    mean_rec = np.mean(recs)\n",
    "    mean_f1 = np.mean(f1s)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "    mean_cind = mean_auc\n",
    "\n",
    "    # Compute true fold-averaged confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Logistic Regression standardized\"\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "\n",
    "    # Paths for figures\n",
    "    hmname = os.path.join(path_figure, 'logistic_standardized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'logistic_standardized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'logistic_standardized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # Plot fold-averaged confusion matrix heatmap\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_logisticS = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'Logistic Regression standardized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged Precision-Recall curve\n",
    "    mean_rec_curve = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Average the feature importances over all folds\n",
    "    feature_importances /= k\n",
    "    feature_names = df.columns[:-1]\n",
    "    sorted_idx = np.argsort(feature_importances)[-10:]\n",
    "    sorted_importance = feature_importances[sorted_idx]\n",
    "    sorted_features = feature_names[sorted_idx]\n",
    "\n",
    "    # Export feature importances\n",
    "    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feat_df['Abs_Importance'] = feat_df['Importance'].abs()\n",
    "    feat_df = feat_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    excel_filename = os.path.join(path_table, 'logistic_standardized_feature_importances_kfCV.xlsx')\n",
    "    feat_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation で得られた Logistic Regression standardized における Feature Importance')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_features, sorted_importance, color='skyblue')\n",
    "    plt.xlabel('Average Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Logistic Regression standardized')\n",
    "    font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels(): label.set_fontproperties(font_prop)\n",
    "    plt.savefig(os.path.join(path_figure, 'logistic_standardized_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    model_full = LogisticRegression(random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'logistic_standardized_model_full.pkl'), 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = LogisticRegression(random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'logistic_standardized_shap_values_holdout',\n",
    "            'logistic_standardized_shap_values_holdout',\n",
    "            'Logistic Regression standardized',\n",
    "            task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            t_test, size_x, size_y, path_figure, path_table,\n",
    "            'logistic_standardized_lime_explanation_holdout',\n",
    "            'logistic_standardized_lime_feature_contributions_holdout',\n",
    "            'Logistic Regression standardized',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Logistic Regression standardized']\n",
    "    )\n",
    "    return [res2, roc_logisticS]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SVM Normalized kfCV with fold-Averaged metrics\n",
    "def SVMKFoldN(k=k, show_shap=False, perform_lime=True):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    # Hold-out 用のデータの分割\n",
    "    x_train, x_test, t_train, t_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Support Vector Machine normalized kfCV with fold-Averaged metrics ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # データの線形性の確認\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred_lr = lr.predict(X)\n",
    "    r2 = r2_score(y, y_pred_lr)\n",
    "    if r2 >= 0.8:\n",
    "        linear = 1\n",
    "    elif r2 < 0.2:\n",
    "        linear = 0\n",
    "    else:\n",
    "        linear = 0\n",
    "\n",
    "    kernel_option = 'linear' if linear == 1 else 'rbf'\n",
    "\n",
    "    # Initialize MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulator for feature importances\n",
    "    feature_importances = np.zeros((df.shape[1] - 1,))\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    specs = []\n",
    "    aps = []\n",
    "\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates = []\n",
    "    fp_rates = []\n",
    "    fn_rates = []\n",
    "    tp_rates = []\n",
    "\n",
    "    # For ROC and Precision-Recall curves per fold\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_pred_probs = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled, y):\n",
    "        X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the SVM model with probability estimation enabled\n",
    "        model = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Assuming a linear SVM, extract the coefficients\n",
    "        # For non-linear SVM, this part is not applicable\n",
    "        if kernel_option == 'linear':\n",
    "            feature_importances += np.abs(model.coef_[0])\n",
    "\n",
    "        # Predict classes and probabilities for evaluation\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "        y_pred_prob = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_fold, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        # specificity\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_prob))\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_test_fold, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred))\n",
    "        aps.append(average_precision_score(y_test_fold, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test_fold, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test_fold, y_pred_prob)\n",
    "        precisions.append(prec_vals)\n",
    "        recalls.append(rec_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test_fold)\n",
    "        all_pred_probs.extend(y_pred_prob)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    mean_acc = np.mean(accuracy_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_rec = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "    mean_cind = mean_auc\n",
    "\n",
    "    # Compute true fold-averaged confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Support Vector Machine normalized\"\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "\n",
    "    # Paths for figures\n",
    "    hmname = os.path.join(path_figure, 'svm_normalized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'svm_normalized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'svm_normalized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # Plot fold-averaged confusion matrix heatmap\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_SVMN = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'SVM normalized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged Precision-Recall curve\n",
    "    mean_rec_curve = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Initialize the SVM model with probability estimation enabled for full data\n",
    "    model_full = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Ensure the path exists\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_filename = os.path.join(path_model, 'svm_normalized_full_kfCV.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Feature importance for SVM can be calculated only when the kernel is linear.\n",
    "    if kernel_option == 'linear':\n",
    "        # Average the feature importances over all folds\n",
    "        feature_importances /= k\n",
    "        # Get the feature names\n",
    "        feature_names = df.columns[:-1]\n",
    "        # Sort the features by importance\n",
    "        sorted_idx = np.argsort(feature_importances)[-10:]\n",
    "        sorted_importance = feature_importances[sorted_idx]\n",
    "        sorted_features = feature_names[sorted_idx]\n",
    "\n",
    "        # Export feature importances\n",
    "        feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "        feature_importances_df['Abs_Importance'] = feature_importances_df['Importance'].abs()\n",
    "        feature_importances_df = feature_importances_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "        excel_filename = os.path.join(path_table, 'svm_normalized_feature_importances_kfold_fold.xlsx')\n",
    "        feature_importances_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "        print('')\n",
    "        print(f'◇ {k}-fold Cross Validation で得られた SVM normalized kfCV における Feature Importance (fold-Averaged)')\n",
    "        print('')\n",
    "        plt.figure(figsize=(size_x, size_y))\n",
    "        plt.barh(sorted_features, sorted_importance, color='skyblue')\n",
    "        plt.xlabel('Average Feature Importance')\n",
    "        plt.title(f'Top 10 Feature Importances - fold-Averaged over {k} Folds (Linear SVM)')\n",
    "        font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "        font_prop = fm.FontProperties(fname=font_path)\n",
    "        ax = plt.gca()\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_fontproperties(font_prop)\n",
    "        plt.savefig(os.path.join(path_figure, 'svm_normalized_feature_importances_kfCV_fold.png'))\n",
    "        plt.show(); plt.close()\n",
    "        print('')\n",
    "\n",
    "    elif kernel_option == 'rbf':\n",
    "        print('')\n",
    "        print('・ Feature importance cannot be figured out from SVM with NON-LINEAR kernel due to the kernel trick.')\n",
    "        print('')\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    print('')\n",
    "    print('◇ SVM normalized の 各変数の SHAP値')\n",
    "    print('')\n",
    "\n",
    "    if show_shap:\n",
    "        # For non-linear kernels, use KernelExplainer to calculate SHAP values\n",
    "        explainer = shap.KernelExplainer(model_holdout.predict_proba, x_train_scaled)\n",
    "        shap_values = explainer.shap_values(x_test_scaled)\n",
    "        shap.summary_plot(shap_values, x_test_scaled, feature_names=df.columns[:-1], plot_type=\"bar\")\n",
    "        plt.title('SHAP summary plot for SVM with RBF kernel')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('・　SVMのSHAP値の計算には長時間を要するため skip する。')\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'svm_normalized_lime_explanation_holdout_kfCV_fold',\n",
    "            'svm_normalized_lime_feature_contributions_holdout_kfCV_fold',\n",
    "            'SVM normalized',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([\n",
    "        np.mean(auc_scores), np.mean(accuracy_scores),\n",
    "        np.mean(precision_scores), np.mean(recall_scores),\n",
    "        np.mean(f1_scores)\n",
    "    ], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['SVM normalized']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_SVMN]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# SVM Standardized kfCV with fold-Averaged metrics\n",
    "def SVMKFoldS(k=k, show_shap=False, perform_lime=True):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    # Hold-out 用のデータの分割\n",
    "    x_train, x_test, t_train, t_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Support Vector Machine standardized kfCV with fold-Averaged metrics ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # データの線形性の確認\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred_lr = lr.predict(X)\n",
    "    r2 = r2_score(y, y_pred_lr)\n",
    "    if r2 >= 0.8:\n",
    "        linear = 1\n",
    "    elif r2 < 0.2:\n",
    "        linear = 0\n",
    "    else:\n",
    "        linear = 0\n",
    "\n",
    "    kernel_option = 'linear' if linear == 1 else 'rbf'\n",
    "\n",
    "    # Initialize StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Initialize accumulator for feature importances\n",
    "    feature_importances = np.zeros((df.shape[1] - 1,))\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    specs = []\n",
    "    aps = []\n",
    "\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates = []\n",
    "    fp_rates = []\n",
    "    fn_rates = []\n",
    "    tp_rates = []\n",
    "\n",
    "    # For ROC and Precision-Recall curves per fold\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_pred_probs = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled, y):\n",
    "        X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the SVM model with probability estimation enabled\n",
    "        model = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Assuming a linear SVM, extract the coefficients\n",
    "        # For non-linear SVM, this part is not applicable\n",
    "        if kernel_option == 'linear':\n",
    "            feature_importances += np.abs(model.coef_[0])\n",
    "\n",
    "        # Predict classes and probabilities for evaluation\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "        y_pred_prob = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_fold, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        # specificity\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_prob))\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_test_fold, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred))\n",
    "        aps.append(average_precision_score(y_test_fold, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test_fold, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test_fold, y_pred_prob)\n",
    "        precisions.append(prec_vals)\n",
    "        recalls.append(rec_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test_fold)\n",
    "        all_pred_probs.extend(y_pred_prob)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    mean_acc = np.mean(accuracy_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_rec = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_spec = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "    mean_cind = mean_auc\n",
    "\n",
    "    # Compute true fold-averaged confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Support Vector Machine standardized\"\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "\n",
    "    # Paths for figures\n",
    "    hmname = os.path.join(path_figure, 'svm_standardized_confusion_heatmap_kfCV.png')\n",
    "    rocname = os.path.join(path_figure, 'svm_standardized_roc_curve_kfCV.png')\n",
    "    prerecname = os.path.join(path_figure, 'svm_standardized_prerec_curve_kfCV.png')\n",
    "\n",
    "    # Plot fold-averaged confusion matrix heatmap\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged ROC curve\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_SVMS = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'SVM standardized'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged Precision-Recall curve\n",
    "    mean_rec_curve = np.linspace(0, 1, 100)\n",
    "    pr_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Initialize the SVM model with probability estimation enabled for full data\n",
    "    model_full = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Ensure the path exists\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_filename = os.path.join(path_model, 'svm_standardized_full_kfCV.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Feature importance for SVM can be calculated only when the kernel is linear.\n",
    "    if kernel_option == 'linear':\n",
    "        # Average the feature importances over all folds\n",
    "        feature_importances /= k\n",
    "        # Get the feature names\n",
    "        feature_names = df.columns[:-1]\n",
    "        # Sort the features by importance\n",
    "        sorted_idx = np.argsort(feature_importances)[-10:]\n",
    "        sorted_importance = feature_importances[sorted_idx]\n",
    "        sorted_features = feature_names[sorted_idx]\n",
    "\n",
    "        # Export feature importances\n",
    "        feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "        feature_importances_df['Abs_Importance'] = feature_importances_df['Importance'].abs()\n",
    "        feature_importances_df = feature_importances_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "        excel_filename = os.path.join(path_table, 'svm_standardized_feature_importances_kfCV.xlsx')\n",
    "        feature_importances_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "        print('')\n",
    "        print(f'◇ {k}-fold Cross Validation で得られた SVM standardized kfCV における Feature Importance (fold-Averaged)')\n",
    "        print('')\n",
    "        plt.figure(figsize=(size_x, size_y))\n",
    "        plt.barh(sorted_features, sorted_importance, color='skyblue')\n",
    "        plt.xlabel('Average Feature Importance')\n",
    "        plt.title(f'Top 10 Feature Importances - fold-Averaged over {k} Folds (Linear SVM)')\n",
    "        font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "        font_prop = fm.FontProperties(fname=font_path)\n",
    "        ax = plt.gca()\n",
    "        for label in ax.get_yticklabels():\n",
    "            label.set_fontproperties(font_prop)\n",
    "        plt.savefig(os.path.join(path_figure, 'svm_standardized_feature_importances_kfCV.png'))\n",
    "        plt.show(); plt.close()\n",
    "        print('')\n",
    "\n",
    "    elif kernel_option == 'rbf':\n",
    "        print('')\n",
    "        print('・ Feature importance cannot be figured out from SVM with NON-LINEAR kernel due to the kernel trick.')\n",
    "        print('')\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = SVC(kernel=kernel_option, probability=True, random_state=random_state)\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    print('')\n",
    "    print('◇ SVM standardized の 各変数の SHAP値')\n",
    "    print('')\n",
    "\n",
    "    if show_shap:\n",
    "        # For non-linear kernels, use KernelExplainer to calculate SHAP values\n",
    "        explainer = shap.KernelExplainer(model_holdout.predict_proba, x_train_scaled)\n",
    "        shap_values = explainer.shap_values(x_test_scaled)\n",
    "        shap.summary_plot(shap_values, x_test_scaled, feature_names=df.columns[:-1], plot_type=\"bar\")\n",
    "        plt.title('SHAP summary plot for SVM with RBF kernel')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('・　SVMのSHAP値の計算には長時間を要するため skip する。')\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'svm_standardized_lime_explanation_holdout_kfCV_fold',\n",
    "            'svm_standardized_lime_feature_contributions_holdout_kfCV_fold',\n",
    "            'SVM standardized',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([\n",
    "        np.mean(auc_scores), np.mean(accuracy_scores),\n",
    "        np.mean(precision_scores), np.mean(recall_scores),\n",
    "        np.mean(f1_scores)\n",
    "    ], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['SVM standardized']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_SVMS]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RandomForest kfCV with fold-Averaged metrics\n",
    "def RandomForestKFold(k=k, show_shap=True, perform_lime=True, shap_sample_size=100):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Random Forest kfCV with fold-Averaged metrics ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # Stratified KFold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    specs = []\n",
    "    aps = []\n",
    "\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates = []\n",
    "    fp_rates = []\n",
    "    fn_rates = []\n",
    "    tp_rates = []\n",
    "\n",
    "    # For ROC and Precision-Recall curves per fold\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # Accumulate feature importances per fold\n",
    "    feature_importance_list = []\n",
    "\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_pred_probs = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the RandomForest model with default parameters\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Collect feature importances\n",
    "        feature_importances = model.feature_importances_\n",
    "        feature_importance_list.append(feature_importances)\n",
    "\n",
    "        # Predict classes and probabilities for evaluation\n",
    "        y_pred = model.predict(X_test_fold)\n",
    "        y_pred_prob = model.predict_proba(X_test_fold)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test_fold, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        # specificity\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        auc_scores.append(roc_auc_score(y_test_fold, y_pred_prob))\n",
    "        accuracy_scores.append(accuracy_score(y_test_fold, y_pred))\n",
    "        precision_scores.append(precision_score(y_test_fold, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_test_fold, y_pred))\n",
    "        f1_scores.append(f1_score(y_test_fold, y_pred))\n",
    "        aps.append(average_precision_score(y_test_fold, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test_fold, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test_fold, y_pred_prob)\n",
    "        precisions.append(prec_vals)\n",
    "        recalls.append(rec_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test_fold)\n",
    "        all_pred_probs.extend(y_pred_prob)\n",
    "\n",
    "    # Compute fold-averaged scores\n",
    "    mean_auc   = np.mean(auc_scores)\n",
    "    mean_acc   = np.mean(accuracy_scores)\n",
    "    mean_prec  = np.mean(precision_scores)\n",
    "    mean_rec   = np.mean(recall_scores)\n",
    "    mean_f1    = np.mean(f1_scores)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_prerec= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # Compute true fold-averaged confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_prerec,\n",
    "        \"Random Forest\"\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "\n",
    "    # Paths for figures\n",
    "    hmname      = os.path.join(path_figure, 'random_forest_confusion_heatmap_kfCV.png')\n",
    "    rocname     = os.path.join(path_figure, 'random_forest_roc_curve_kfCV.png')\n",
    "    prerecname  = os.path.join(path_figure, 'random_forest_prerec_curve_kfCV.png')\n",
    "\n",
    "    # Plot fold-averaged confusion matrix heatmap\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged ROC curve\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_randomforest = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'Random Forest'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Fold-Average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot fold-averaged Precision-Recall curve\n",
    "    mean_rec_curve    = np.linspace(0, 1, 100)\n",
    "    pr_interp         = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve   = np.mean(pr_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'Fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Calculate the average feature importance across all folds\n",
    "    mean_feature_importances = np.mean(feature_importance_list, axis=0)\n",
    "    column_names = df.columns[:-1]\n",
    "    feature_importances_df = pd.DataFrame({'Feature': column_names, 'Importance': mean_feature_importances})\n",
    "    feature_importances_df['Abs_Importance'] = feature_importances_df['Importance'].abs()\n",
    "    feature_importances_df = feature_importances_df.sort_values(by='Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    excel_filename = os.path.join(path_table, 'random_forest_feature_importances_kfCV.xlsx')\n",
    "    feature_importances_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    # Get the top 10 features and their importances\n",
    "    indices       = np.argsort(mean_feature_importances)[-10:]\n",
    "    top_features  = df.columns[indices]\n",
    "    top_importances = mean_feature_importances[indices]\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation における Random Forest Feature Importance (fold-Averaged)')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(top_features, top_importances, align='center')\n",
    "    plt.xlabel('Average Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances - fold-Averaged over {k} Folds')\n",
    "    font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.savefig(os.path.join(path_figure, 'random_forest_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = RandomForestClassifier(random_state=random_state)\n",
    "    model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_filename = os.path.join(path_model, 'random_forest_full_model.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    model_holdout = RandomForestClassifier(random_state=random_state)\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        if len(df.columns) < 1000:\n",
    "            print('')\n",
    "            print('□ Random Forest model の 各変数のSHAP値')\n",
    "            print('')\n",
    "            shap_sample_size = min(shap_sample_size, len(x_train))\n",
    "            print(f'◇ SHAPのサンプルサイズ: {shap_sample_size}')\n",
    "            print('')\n",
    "            print('----- Be patient. It takes a few minutes. -----')\n",
    "            print('')\n",
    "\n",
    "            background_data = shap.utils.sample(x_train, shap_sample_size)\n",
    "            explainer = shap.KernelExplainer(model_holdout.predict_proba, background_data)\n",
    "            shap_values = explainer.shap_values(x_test)\n",
    "\n",
    "            print(f'◇ Random Forest の SHAP値の計算には時間がかかるため、{shap_sample_size}個のデータを抽出して計算します。')\n",
    "            positive_shap = shap_values[:, :, 1]\n",
    "\n",
    "            plt.figure(figsize=(size_x, size_y))\n",
    "            shap.summary_plot(positive_shap, x_test, feature_names=df.columns[:-1], plot_type=\"bar\", show=False)\n",
    "            ax = plt.gca()\n",
    "            for label in ax.get_yticklabels():\n",
    "                label.set_fontproperties(font_prop)\n",
    "            plt.savefig(os.path.join(path_figure, 'random_forest_positive_shap_values_holdout.png'))\n",
    "            plt.show(); plt.close()\n",
    "            print('')\n",
    "\n",
    "            mean_abs_shap = np.abs(positive_shap).mean(axis=0)\n",
    "            shap_df = pd.DataFrame(mean_abs_shap.reshape(-1, 1), columns=[\"SHAP Value\"], index=df.columns[:-1])\n",
    "            shap_df = shap_df.sort_values(by=\"SHAP Value\", ascending=False)\n",
    "            shap_excel = os.path.join(path_table, 'random_forest_shap_values_holdout.xlsx')\n",
    "            shap_df.to_excel(shap_excel)\n",
    "\n",
    "        else:\n",
    "            print('◇ 説明変数が1,000個を超えるため、Random ForestのSHAP値の計算をskipします。')\n",
    "            print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'random_forest_lime_explanation_holdout',\n",
    "            'random_forest_lime_feature_contributions_holdout',\n",
    "            'Random Forest',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([\n",
    "        mean_auc, mean_acc,\n",
    "        mean_prec, mean_rec,\n",
    "        mean_f1\n",
    "    ], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Random Forest']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_randomforest]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RandomForestOptunaKFold(\n",
    "    k=k,\n",
    "    show_shap=True,\n",
    "    perform_lime=True,\n",
    "    shap_sample_size=100,\n",
    "    threshold=0.5,\n",
    "    n_trials=30,\n",
    "    target='logloss'\n",
    "):\n",
    "    import os\n",
    "    import pickle\n",
    "    import logging\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "    import optuna\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "\n",
    "    # 初期出力\n",
    "    print('')\n",
    "    print(f'■■■ Random Forest kfCV with Optuna (Foldwise averaged, Optimizing {target})　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): '\n",
    "          + str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5))\n",
    "          + ' %)')\n",
    "    print('')\n",
    "    print('----- Be patient. It would take a few minutes. -----')\n",
    "    print('')\n",
    "\n",
    "    # Optuna ログを INFO レベルで出力\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    logging.getLogger(\"optuna\").propagate = False\n",
    "\n",
    "    def objective(trial):\n",
    "        # ハイパーパラメータ探索空間\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 10, 500),\n",
    "            'max_depth': trial.suggest_categorical('max_depth', [None]+list(range(2, 65))),\n",
    "            # 'max_depth': trial.suggest_int('max_depth', 2, 32, log=True),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "            'random_state': random_state\n",
    "        }\n",
    "        model = RandomForestClassifier(**params)\n",
    "        cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "        if target == 'auc':\n",
    "            scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')\n",
    "            return np.mean(scores)\n",
    "        else:  # 'logloss'\n",
    "            scores = cross_val_score(model, X, y, cv=cv, scoring='neg_log_loss')\n",
    "            return np.mean(scores)\n",
    "\n",
    "    # Optuna Study 作成\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    # ベストパラメータ出力\n",
    "    best_trial_no = study.best_trial.number\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization for Random Forest with Optuna (detailed logs below)')\n",
    "    print(f'Best trial #{best_trial_no} for maximizing {target}:')\n",
    "    print(\"Best hyperparameters: \", study.best_params)\n",
    "    print('')\n",
    "\n",
    "    # 最良モデルの準備\n",
    "    best_params = study.best_params.copy()\n",
    "    best_params['random_state'] = random_state\n",
    "    best_model = RandomForestClassifier(**best_params)\n",
    "\n",
    "    # # ホールドアウト分割\n",
    "    # x_train, x_test, t_train, t_test = train_test_split(\n",
    "    #     X, y, test_size=test_size, random_state=random_state\n",
    "    # )\n",
    "\n",
    "    # 各種蓄積用リスト\n",
    "    aucs = []; accs = []; precs = []; recs = []; f1s = []; specs = []; aps = []\n",
    "    tn_rates = []; fp_rates = []; fn_rates = []; tp_rates = []\n",
    "    fprs = []; tprs = []; precisions = []; recalls = []\n",
    "    feature_importances = np.zeros(X.shape[1])\n",
    "    all_y_test = []; all_pred_probs = []\n",
    "\n",
    "    # k-fold クロスバリデーションによる評価\n",
    "    cv = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = RandomForestClassifier(**best_params)\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        # 予測確率および閾値0.5でのクラス予測\n",
    "        probs = model.predict_proba(X_te)[:, 1]\n",
    "        preds = (probs >= threshold).astype(int)\n",
    "\n",
    "        # 混同行列レート\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, preds).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total); fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total); tp_rates.append(tp/total)\n",
    "        specs.append(tn/(tn+fp))\n",
    "\n",
    "        # 各種メトリクス\n",
    "        aucs.append(roc_auc_score(y_te, probs))\n",
    "        accs.append(accuracy_score(y_te, preds))\n",
    "        precs.append(precision_score(y_te, preds, zero_division=0))\n",
    "        recs.append(recall_score(y_te, preds))\n",
    "        f1s.append(f1_score(y_te, preds))\n",
    "        aps.append(average_precision_score(y_te, probs))\n",
    "\n",
    "        # ROC/PR 曲線データ\n",
    "        fpr, tpr, _ = roc_curve(y_te, probs)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_te, probs)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        # 全体プロット用蓄積\n",
    "        all_y_test.extend(y_te); all_pred_probs.extend(probs)\n",
    "\n",
    "        # 特徴量重要度\n",
    "        feature_importances += model.feature_importances_\n",
    "\n",
    "    # 平均化\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "    feature_importances /= k\n",
    "\n",
    "    # 混同行列マクロ平均\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                         [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    # display_fold_averages 呼び出し\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_auc, mean_prerec,\n",
    "        \"Random Forest with Optuna\"\n",
    "    )\n",
    "\n",
    "    # プロット設定共通\n",
    "    fig_kwargs = dict(figsize=(size_x, size_y))\n",
    "    font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "\n",
    "    # ヒートマップ\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    sns.heatmap(fold_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'randomforest_optuna_confusion_heatmap.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # ROC 曲線\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    interp_tprs = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr = np.mean(interp_tprs, axis=0)\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'randomforest_optuna_roc_curve.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Precision-Recall 曲線\n",
    "    mean_rec = np.linspace(0,1,100)\n",
    "    interp_prec = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        interp_prec.append(np.interp(mean_rec, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(interp_prec, axis=0)\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.plot(mean_rec, mean_prec_curve, label=f'Fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'randomforest_optuna_pr_curve.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Feature Importance\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': df.columns[:-1],\n",
    "        'Importance': feature_importances\n",
    "    })\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values('Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'randomforest_optuna_feature_importances.xlsx'), index=False)\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold CV + Optuna による Random Forest の Feature Importance')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.barh(fi_df['Feature'][:10], fi_df['Importance'][:10])\n",
    "    plt.xlabel('Importance'); plt.title(f'Top 10 Feature Importances ({k}-fold CV + Optuna)')\n",
    "    ax = plt.gca()\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'randomforest_optuna_feature_importances.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # モデル保存\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'randomforest_optuna_best_model.pkl'), 'wb') as f:\n",
    "        pickle.dump(best_model, f)\n",
    "\n",
    "    # SHAP と LIME\n",
    "    holdout_model = RandomForestClassifier(**best_params)\n",
    "    holdout_model.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        print('□ Random Forest best model (Optuna) の SHAP 値')\n",
    "        shap_sample = min(shap_sample_size, len(x_train))\n",
    "        print(f'◇ SHAPのサンプルサイズ: {shap_sample}')\n",
    "        background = shap.utils.sample(x_train, shap_sample)\n",
    "        explainer = shap.KernelExplainer(holdout_model.predict_proba, background)\n",
    "        shap_vals = explainer.shap_values(x_test)\n",
    "        pos_shap = shap_vals[:, :, 1]\n",
    "        plt.figure(**fig_kwargs)\n",
    "        shap.summary_plot(pos_shap, x_test, feature_names=df.columns[:-1], plot_type=\"bar\", show=False)\n",
    "        ax = plt.gca()\n",
    "        for lbl in ax.get_yticklabels():\n",
    "            lbl.set_fontproperties(font_prop)\n",
    "        plt.savefig(os.path.join(path_figure, 'randomforest_optuna_shap.png'))\n",
    "        plt.show(); plt.close()\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        print('□ Random Forest best model (Optuna) の LIME 分析')\n",
    "        LimeContributionValueFunction(\n",
    "            holdout_model, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'randomforest_optuna_lime_explain', 'randomforest_optuna_lime_features',\n",
    "            'Random Forest kfCV with Optuna', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # 結果返却\n",
    "    res = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['Random Forest with Optuna']\n",
    "    )\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return [res, (mean_fpr, mean_tpr, mean_auc, 'Random Forest with Optuna')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# XGBoost kfCV with fold-Averaged metrics\n",
    "def XGBoostKFold(k=k, show_shap=True, perform_lime=True):\n",
    "    from xgboost import XGBClassifier\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import (\n",
    "        r2_score, roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    print('')\n",
    "    print('■■■ XGBoost kfCV with fold-Averaged metrics ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): '\n",
    "          + str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5))\n",
    "          + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # データの線形性の確認\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred_lr = lr.predict(X)\n",
    "    r2 = r2_score(y, y_pred_lr)\n",
    "    linear = 1 if r2 >= 0.8 else 0\n",
    "\n",
    "    booster_option = 'gblinear' if linear == 1 else 'gbtree'\n",
    "\n",
    "    # Use StratifiedKFold instead of KFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for fold metrics\n",
    "    auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    specs = []\n",
    "    aps = []\n",
    "\n",
    "    # For ROC and Precision-Recall curve plotting per fold\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    # For true fold-averaged confusion matrix\n",
    "    tn_rates = []\n",
    "    fp_rates = []\n",
    "    fn_rates = []\n",
    "    tp_rates = []\n",
    "\n",
    "    # For aggregation of test labels and predicted probabilities\n",
    "    all_y_test = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Accumulate feature importances per fold\n",
    "    feature_importances = defaultdict(list)\n",
    "    feature_names = df.columns.tolist()\n",
    "    feature_index_to_name = {f'f{i}': name for i, name in enumerate(feature_names)}\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            booster=booster_option,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=random_state\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Retrieve feature importances based on booster type\n",
    "        if linear == 0:\n",
    "            weight_imp = model.get_booster().get_score(importance_type='weight')\n",
    "            for idx, name in feature_index_to_name.items():\n",
    "                feature_importances[name].append(weight_imp.get(idx, 0))\n",
    "        else:\n",
    "            coeffs = model.coef_.ravel()\n",
    "            for i, name in enumerate(feature_names):\n",
    "                feature_importances[name].append(abs(coeffs[i]))\n",
    "\n",
    "        # Predict classes and probabilities for evaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # Compute per-fold metrics\n",
    "        auc_scores.append(roc_auc_score(y_test, y_pred_prob))\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        precision_scores.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recall_scores.append(recall_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        aps.append(average_precision_score(y_test, y_pred_prob))\n",
    "\n",
    "        # Collect for fold ROC/PR curves\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(p_vals)\n",
    "        recalls.append(r_vals)\n",
    "\n",
    "        # Aggregate for overall ROC call\n",
    "        all_y_test.extend(y_test)\n",
    "        all_predictions.extend(y_pred_prob)\n",
    "\n",
    "    # -----------------Calculate fold-average scores-----------------\n",
    "    mean_auc    = np.mean(auc_scores)\n",
    "    mean_acc    = np.mean(accuracy_scores)\n",
    "    mean_prec   = np.mean(precision_scores)\n",
    "    mean_rec    = np.mean(recall_scores)\n",
    "    mean_f1     = np.mean(f1_scores)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_prerec = np.mean(aps)\n",
    "\n",
    "    # -----------------True fold-averaged confusion matrix-----------------\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]])\n",
    "    fold_cm_pct = fold_cm * 100\n",
    "\n",
    "    # Display fold-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm_pct,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_auc, mean_prerec,\n",
    "        \"XGBoost kfCV\"\n",
    "    )\n",
    "\n",
    "    # Common plot settings\n",
    "    fig_kwargs = dict(figsize=(size_x, size_y))\n",
    "    font_prop  = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "\n",
    "    # -----------------Plot fold-averaged confusion matrix heatmap-----------------\n",
    "    print('')\n",
    "    print('□　fold-Averageによる混同行列のヒートマップ:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    sns.heatmap(fold_cm_pct, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('fold-Averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'xgboost_confusion_heatmap_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot fold-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    rocname        = os.path.join(path_figure, 'xgboost_roc_curve_kfCV.png')\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Fold-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)): plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot fold-averaged Precision-Recall curve-----------------\n",
    "    mean_rec_curve  = np.linspace(0, 1, 100)\n",
    "    pr_interp       = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        pr_interp.append(np.interp(mean_rec_curve, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_prec_curve = np.mean(pr_interp, axis=0)\n",
    "    prerecname      = os.path.join(path_figure, 'xgboost_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.plot(mean_rec_curve, mean_prec_curve, label=f'Fold-average PRC (AUC = {mean_prerec:.4f})')\n",
    "    for i in range(len(recalls)): plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Fold-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Fold-based Feature-importance extraction-----------------\n",
    "    avg_imp = {f: np.mean(vals) for f, vals in feature_importances.items()}\n",
    "    sorted_imp = dict(sorted(avg_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': list(sorted_imp.keys()),\n",
    "        'Importance': list(sorted_imp.values())\n",
    "    })\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values('Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'xgboost_feature_importances_kfCV.xlsx'), index=False)\n",
    "\n",
    "    print('')\n",
    "    print(f'□ {k}-fold Cross Validation における XGBoost Feature Importance (fold-Averaged)')\n",
    "    print('')\n",
    "    fig_kwargs['figsize'] = (12, 8)\n",
    "    plt.figure(**fig_kwargs)\n",
    "    plt.barh(fi_df['Feature'][:10], fi_df['Importance'][:10])\n",
    "    plt.xlabel('Average Importance')\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of XGBoost')\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis()\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.savefig(os.path.join(path_figure, 'xgboost_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Retrain the model on the full dataset-----------------\n",
    "    model_full = XGBClassifier(\n",
    "        booster=booster_option,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'xgboost_kfCV_model.pkl'), 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out method for SHAP and LIME analyses\n",
    "    model_holdout = XGBClassifier(\n",
    "        booster=booster_option,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'xgboost_shap_values_holdout_holdout',\n",
    "            'xgboost_shap_values_holdout_holdout',\n",
    "            'XGBoost', task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'xgboost_lime_explanation_holdout',\n",
    "            'xgboost_lime_feature_contributions_holdout',\n",
    "            'XGBoost', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # -----------------Prepare and return results-----------------\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame([res], columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'], index=['XGBoost'])\n",
    "    roc_xgboost = (mean_fpr, mean_tpr_curve, mean_auc, 'XGBoost')\n",
    "\n",
    "    return [res2, roc_xgboost]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def XGBoostOptunaKFold(k=k,\n",
    "                       show_shap=True,\n",
    "                       perform_lime=True,\n",
    "                       target='auc',\n",
    "                       n_trials=50):\n",
    "    import xgboost as xgb\n",
    "    import optuna\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        log_loss, roc_curve,\n",
    "        precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import matplotlib.font_manager as fm\n",
    "    from collections import defaultdict\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ XGBoost kfCV with Optuna (Foldwise averaged, Optimizing {target}) ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): '\n",
    "          + str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5))\n",
    "          + ' %)')\n",
    "    print('')\n",
    "    print('----- Be patient. It takes a whole. -----')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    # Boosterの“f0, f1, …”インデックスを元の特徴量名にマッピング\n",
    "    feature_index_to_name = {f'f{i}': name for i, name in enumerate(feature_names)}\n",
    "\n",
    "    # データの線形性の確認\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, y)\n",
    "    y_pred_lr = lr.predict(X)\n",
    "    r2 = r2_score(y, y_pred_lr)\n",
    "    if r2 >= 0.8:\n",
    "        linear = 1\n",
    "    elif r2 < 0.2:\n",
    "        linear = 0\n",
    "    else:\n",
    "        linear = 0\n",
    "\n",
    "    booster_option = 'gblinear' if linear == 1 else 'gbtree'\n",
    "\n",
    "    # right after you define `target`\n",
    "    target2_map = {\n",
    "        'auc': 'AUC',\n",
    "        'logloss': 'minus_logloss'\n",
    "    }\n",
    "\n",
    "    if target not in target2_map:\n",
    "        raise ValueError(f\"Unknown target: {target}\")\n",
    "    display_name = target2_map[target]\n",
    "\n",
    "    def objective(trial):\n",
    "        # ハイパーパラメータ探索空間の定義\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True)\n",
    "        }\n",
    "        model = xgb.XGBClassifier(\n",
    "            **params,\n",
    "            booster=booster_option,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            random_state=random_state,\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        # StratifiedKFold に変更\n",
    "        kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "        fold_metrics = []\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "            X_tr, X_te = X[train_index], X[test_index]\n",
    "            y_tr, y_te = y[train_index], y[test_index]\n",
    "\n",
    "            model.fit(X_tr, y_tr, eval_set=[(X_te, y_te)], verbose=False)\n",
    "            y_prob = model.predict_proba(X_te)[:, 1]\n",
    "\n",
    "            # Optuna の目的関数を target パラメータで切り替え\n",
    "            if target == 'auc':\n",
    "                m = roc_auc_score(y_te, y_prob)\n",
    "            elif target == 'logloss':\n",
    "                m = -log_loss(y_te, y_prob)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown target: {target}\")\n",
    "            fold_metrics.append(m)\n",
    "\n",
    "        return np.mean(fold_metrics)\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    optuna.logging.enable_default_handler()\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    best_trial_no = study.best_trial.number\n",
    "    print('')\n",
    "    print('')\n",
    "    print('◇ Hyperparameter Optimization with Optuna for XGBoost (detailed logs below)')\n",
    "    print(f'   Best trial #{best_trial_no} for maximizing {display_name}')\n",
    "    print(f'   The booster used: {booster_option}')\n",
    "    print(\"   Best hyperparameters: \", study.best_params)\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "    # # 結果の表示（Foldwise-averaged）\n",
    "    # print('')\n",
    "    # print(f'□ {k}-fold Cross Validation を用いた XGBoost optimized with Optuna による2値分類の検定結果 (Foldwise-averaged)')\n",
    "\n",
    "    # StratifiedKFold による最終評価\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # フォールド毎の混同行列率、各種指標、曲線データを格納するリスト\n",
    "    tns, fps, fns, tps = [], [], [], []\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    feature_importances = defaultdict(list)\n",
    "\n",
    "    # フォールド毎の評価ループ\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_tr, X_te = X[train_index], X[test_index]\n",
    "        y_tr, y_te = y[train_index], y[test_index]\n",
    "\n",
    "        best_model = xgb.XGBClassifier(\n",
    "            **study.best_params,\n",
    "            booster=booster_option,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=target,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        best_model.fit(X_tr, y_tr)\n",
    "\n",
    "        # Feature‐importance の抽出\n",
    "        if linear == 0:\n",
    "            imp = best_model.get_booster().get_score(importance_type='weight')\n",
    "            for idx, fname in feature_index_to_name.items():\n",
    "                feature_importances[fname].append(imp.get(idx, 0))\n",
    "        else:\n",
    "            coefs = best_model.coef_\n",
    "            if coefs.ndim != 1:\n",
    "                raise ValueError(\"Unexpected coefficient shape.\")\n",
    "            imp = {feature_names[i]: abs(c) for i, c in enumerate(coefs)}\n",
    "            for fname in feature_names:\n",
    "                feature_importances[fname].append(imp.get(fname, 0))\n",
    "\n",
    "        # 予測と混同行列\n",
    "        y_prob = best_model.predict_proba(X_te)[:, 1]\n",
    "        y_pred = best_model.predict(X_te)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tns.append(tn/total); fps.append(fp/total)\n",
    "        fns.append(fn/total); tps.append(tp/total)\n",
    "\n",
    "        # 指標を計算\n",
    "        aucs.append(roc_auc_score(y_te, y_prob))\n",
    "        accs.append(accuracy_score(y_te, y_pred))\n",
    "        precs.append(precision_score(y_te, y_pred, zero_division=0))\n",
    "        recs.append(recall_score(y_te, y_pred))\n",
    "        f1s.append(f1_score(y_te, y_pred))\n",
    "        specs.append(tn/(tn+fp))\n",
    "        aps.append(average_precision_score(y_te, y_prob))\n",
    "\n",
    "        # ROC 曲線データ\n",
    "        fpr, tpr, _ = roc_curve(y_te, y_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision‐Recall 曲線データ\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_te, y_prob)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "    # Foldwise-averaged 混同行列\n",
    "    macro_tn, macro_fp = np.mean(tns), np.mean(fps)\n",
    "    macro_fn, macro_tp = np.mean(fns), np.mean(tps)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        np.mean(accs), np.mean(precs), np.mean(recs), np.mean(f1s),\n",
    "        np.mean(specs), np.mean(aucs), np.mean(aucs), np.mean(aps),\n",
    "        \"XGBoost with Optuna\"\n",
    "    )\n",
    "\n",
    "    # ヒートマップ表示\n",
    "    print('')\n",
    "    print('□　Foldwise-averaged Confusion Matrix (Heatmap):')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(\n",
    "        macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "        xticklabels=['Pred 0', 'Pred 1'],\n",
    "        yticklabels=['True 0', 'True 1']\n",
    "    )\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title(f'Foldwise-averaged Confusion Matrix (%) over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    hmname = os.path.join(path_figure, 'xgboost_confusion_heatmap_kfCV_optuna.png')\n",
    "    plt.savefig(hmname)\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Foldwise-averaged ROC 曲線\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　ROC Curve (Foldwise-averaged):')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve,\n",
    "             label=f'Foldwise-avg ROC (AUC = {np.mean(aucs):.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    rocname = os.path.join(path_figure, 'xgboost_roc_curve_kfCV_optuna.png')\n",
    "    plt.savefig(rocname)\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Foldwise-averaged Precision‐Recall 曲線\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    pr_interps = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx_sort = np.argsort(recalls[i])\n",
    "        rec_s = recalls[i][idx_sort]\n",
    "        prec_s = precisions[i][idx_sort]\n",
    "        pr_interps.append(np.interp(mean_recall, rec_s, prec_s))\n",
    "    mean_precision_curve = np.mean(pr_interps, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□　Precision-Recall Curve (Foldwise-averaged):')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_precision_curve,\n",
    "             label=f'Foldwise-avg PRC (AUC = {np.mean(aps):.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    prerecname = os.path.join(path_figure, 'xgboost_prerec_curve_kfCV_optuna.png')\n",
    "    plt.savefig(prerecname)\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # ----------------- Foldwise-averaged Feature-importance extraction -----------------\n",
    "    avg_imp = {f: np.mean(vals) for f, vals in feature_importances.items()}\n",
    "    sorted_imp = dict(sorted(avg_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': list(sorted_imp.keys()),\n",
    "        'Importance': list(sorted_imp.values())\n",
    "    })\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values(\n",
    "        'Abs_Importance', ascending=False\n",
    "    ).drop('Abs_Importance', axis=1)\n",
    "    fi_df.to_excel(\n",
    "        os.path.join(path_table, 'xgboost_feature_importances_kfCV_optuna.xlsx'),\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation を用いた '\n",
    "          'XGBoost with Optuna による '\n",
    "          'Feature Importance (Foldwise-averaged)')\n",
    "    print('')\n",
    "\n",
    "    # プロット\n",
    "    font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(fi_df['Feature'][:10], fi_df['Importance'][:10], color='skyblue')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Average Importance')\n",
    "    ax.set_title(\n",
    "        f'Top 10 Feature Importances in {k}-fold CV of '\n",
    "        'XGBoost with Optuna (Foldwise-averaged)'\n",
    "    )\n",
    "    for lbl in ax.get_yticklabels():\n",
    "        lbl.set_fontproperties(font_prop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        os.path.join(path_figure, 'xgboost_feature_importances_kfCV_optuna.png')\n",
    "    )\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Full データで再学習しモデル保存\n",
    "    best_model_full = xgb.XGBClassifier(\n",
    "        **study.best_params,\n",
    "        booster=booster_option,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=random_state\n",
    "    )\n",
    "    best_model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(\n",
    "        os.path.join(path_model, 'xgboost_kfCV_optuna_model_full.pkl'),\n",
    "        'wb'\n",
    "    ) as f:\n",
    "        pickle.dump(best_model_full, f)\n",
    "\n",
    "    # Hold-out モデル\n",
    "    best_model_holdout = xgb.XGBClassifier(random_state=random_state)\n",
    "    best_model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            best_model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'xgboost_shap_values_holdout_optuna',\n",
    "            'xgboost_shap_values_holdout_optuna',\n",
    "            'XGBoost with Optuna',\n",
    "            task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            best_model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'xgboost_lime_explanation_holdout_optuna',\n",
    "            'xgboost_lime_feature_contributions_holdout_optuna',\n",
    "            'XGBoost with Optuna',\n",
    "            task_type='classification',\n",
    "            random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # 結果を DataFrame で返却\n",
    "    res = [\n",
    "        np.mean(aucs),\n",
    "        np.mean(accs),\n",
    "        np.mean(precs),\n",
    "        np.mean(recs),\n",
    "        np.mean(f1s)\n",
    "    ]\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['XGBoost with Optuna']\n",
    "    )\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return [res2,\n",
    "            (mean_fpr, mean_tpr_curve, np.mean(aucs), 'XGBoost with Optuna')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LightGBM KFold Cross Validation\n",
    "def LightGBMKFold(k=k, show_shap=True, perform_lime=True):\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    from collections import defaultdict\n",
    "    import contextlib\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import os\n",
    "    import pickle\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print('■■■ LightGBM kfCV (Foldwise-Averaged) ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "\n",
    "    # Use StratifiedKFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for macro metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For ROC/PR curve plotting per fold\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    # For true macro-averaged confusion matrix\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    # For aggregated showscores (no longer used)\n",
    "    all_y_test, all_predictions = [], []\n",
    "    # For collecting feature importances\n",
    "    feature_importances = defaultdict(list)\n",
    "\n",
    "    # ----------------- Stratified K-fold Cross Validation -----------------\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = LGBMClassifier(boosting_type='gbdt', random_state=random_state, verbose=-1)\n",
    "        with open(os.devnull, \"w\") as f_null, contextlib.redirect_stdout(f_null), contextlib.redirect_stderr(f_null):\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred      = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Metrics per fold\n",
    "        auc_fold  = roc_auc_score           (y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score          (y_test, y_pred)\n",
    "        prec_fold = precision_score         (y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score            (y_test, y_pred)\n",
    "        f1_fold   = f1_score                (y_test, y_pred)\n",
    "        ap_fold   = average_precision_score (y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs .append(auc_fold)\n",
    "        accs .append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs .append(rec_fold)\n",
    "        f1s .append(f1_fold)\n",
    "        specs.append(spec_fold)\n",
    "        aps .append(ap_fold)\n",
    "\n",
    "        # ROC curve\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        # Feature importances\n",
    "        for i, imp in enumerate(model.feature_importances_):\n",
    "            feature_importances[feature_names[i]].append(imp)\n",
    "\n",
    "    # -----------------True macro-averaged confusion matrix & macro metrics-----------------\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_cind   = mean_auc\n",
    "    mean_pr_auc = np.mean(aps)\n",
    "\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]])\n",
    "    macro_cm_percent = macro_cm * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df,\n",
    "        macro_cm_percent,\n",
    "        macro_tp, macro_fp,\n",
    "        macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec,\n",
    "        mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc,\n",
    "        mean_cind, mean_pr_auc,\n",
    "        \"LightGBM\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve & build roc_lightgbm-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "\n",
    "    rocname = os.path.join(path_figure, 'lightGBM_roc_curve_kfCV.png')\n",
    "    roc_lightgbm = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'lightGBM'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Foldwise-average ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        recall_sorted    = recalls[i][idx]\n",
    "        precision_sorted = precisions[i][idx]\n",
    "        precisions_interp.append(np.interp(mean_recall, recall_sorted, precision_sorted))\n",
    "    mean_precision_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname = os.path.join(path_figure, 'lightGBM_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_precision_curve, label=f'Foldwise-average PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Average feature importance & Excel export-----------------\n",
    "    avg_importance = {feat: np.mean(imps) for feat, imps in feature_importances.items()}\n",
    "    sorted_avg_imp = dict(sorted(avg_importance.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': list(sorted_avg_imp.keys()),\n",
    "        'Importance': list(sorted_avg_imp.values())\n",
    "    })\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values('Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    excel_filename = os.path.join(path_table, 'lightgbm_feature_importances_kfold.xlsx')\n",
    "    fi_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    # -----------------Plot feature importances-----------------\n",
    "    def plot_importance(title, imp_dict, xlabel):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.set_title(title)\n",
    "        keys   = list(imp_dict.keys())[:10]\n",
    "        values = list(imp_dict.values())[:10]\n",
    "        ax.barh(keys, values)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "        for lbl in ax.get_yticklabels():\n",
    "            lbl.set_fontproperties(font_prop)\n",
    "        ax.invert_yaxis(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(path_figure, 'lightgbm_feature_importances_kfCV.png'))\n",
    "        plt.show(); plt.close()\n",
    "\n",
    "    print('')\n",
    "    print(f'◆ {k}-fold Cross Validation を用いた LightGBM による Feature Importance (Foldwise-Averaged)')\n",
    "    print('')\n",
    "    plot_importance(f\"Top 10 Feature Importances in {k}-fold CV of LightGBM\", sorted_avg_imp, \"Average Importance\")\n",
    "\n",
    "    # -----------------Retrain on full dataset & save model-----------------\n",
    "    model_full = LGBMClassifier(boosting_type='gbdt', random_state=random_state, verbose=-1)\n",
    "    with open(os.devnull, \"w\") as f_null, contextlib.redirect_stdout(f_null), contextlib.redirect_stderr(f_null):\n",
    "        model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'lightgbm_full_model.pkl'), 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # -----------------Hold-out for SHAP/LIME analyses-----------------\n",
    "    model_holdout = LGBMClassifier(boosting_type='gbdt', random_state=random_state, verbose=-1)\n",
    "    with open(os.devnull, \"w\") as f_null, contextlib.redirect_stdout(f_null), contextlib.redirect_stderr(f_null):\n",
    "        model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_shap_values_holdout',\n",
    "            'lightgbm_shap_values_holdout',\n",
    "            'LightGBM',\n",
    "            task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_lime_explanation_holdout',\n",
    "            'lightgbm_lime_feature_contributions_holdout',\n",
    "            'LightGBM',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # -----------------Return results-----------------\n",
    "    res  = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['LightGBM']\n",
    "    )\n",
    "    return [res2, roc_lightgbm]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# target: 'auc' or 'log_loss'\n",
    "def LightGBMOptunaKFold(k=k, show_shap=True, perform_lime=True, n_trials=50, target='log_loss'):\n",
    "    import lightgbm as lgb\n",
    "    from lightgbm import early_stopping\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve,\n",
    "        precision_recall_curve, average_precision_score,\n",
    "        log_loss\n",
    "    )\n",
    "    import contextlib\n",
    "    from contextlib import redirect_stderr\n",
    "    import optuna\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from collections import defaultdict\n",
    "    import pickle\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ LightGBM kfCV with Optuna (Foldwise-Averaged, Optimizing {target}) ■■■')\n",
    "    print('')\n",
    "    print('')\n",
    "    print('----- Be patient. It may take a while. -----')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "\n",
    "    def objective(trial):\n",
    "        import contextlib\n",
    "        # Hyperparameter search space\n",
    "        max_depth   = trial.suggest_int('max_depth', 3, 9)\n",
    "        num_leaves  = trial.suggest_int(\n",
    "            'num_leaves',\n",
    "            int(2 ** max_depth / 2),\n",
    "            2 ** max_depth,\n",
    "            log=True\n",
    "        )\n",
    "        params = {\n",
    "            'n_estimators':      trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth':         max_depth,\n",
    "            'num_leaves':        num_leaves,\n",
    "            'learning_rate':     trial.suggest_float('learning_rate', 1e-3, 1e-1, log=True),\n",
    "            'subsample':         trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'min_child_weight':  trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'reg_lambda':        trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "            'reg_alpha':         trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        }\n",
    "\n",
    "        model = lgb.LGBMClassifier(\n",
    "            **params,\n",
    "            random_state=random_state,\n",
    "            objective='binary',\n",
    "            verbosity=0\n",
    "        )\n",
    "\n",
    "        # Stratified K-fold for objective\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "        aucs, loglosses = [], []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            X_tr, X_te = X[train_idx], X[test_idx]\n",
    "            y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                 contextlib.redirect_stdout(f), \\\n",
    "                 contextlib.redirect_stderr(f):\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_te, y_te)],\n",
    "                    callbacks=[early_stopping(stopping_rounds=50, verbose=False)],\n",
    "                )\n",
    "\n",
    "            y_prob = model.predict_proba(X_te)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_te, y_prob))\n",
    "            loglosses.append(log_loss(y_te, y_prob))\n",
    "\n",
    "        if target == 'auc':\n",
    "            return np.mean(aucs)\n",
    "        else:  # 'log_loss'\n",
    "            # maximize negative log loss\n",
    "            return -np.mean(loglosses)\n",
    "\n",
    "    # Enable Optuna log handler\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    print('')\n",
    "    print('◇ Best hyperparameters: ', study.best_params)\n",
    "    print('')\n",
    "\n",
    "    # Final foldwise evaluation with best params\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    feature_importances = defaultdict(list)\n",
    "\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx], y[test_idx]\n",
    "\n",
    "        best_model = lgb.LGBMClassifier(\n",
    "            **study.best_params,\n",
    "            random_state=random_state,\n",
    "            objective='binary',\n",
    "            verbosity=-1\n",
    "        )\n",
    "\n",
    "        with open(os.devnull, 'w') as err:\n",
    "            with redirect_stderr(err):\n",
    "                best_model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_pred      = best_model.predict(X_te)\n",
    "        y_pred_prob = best_model.predict_proba(X_te)[:, 1]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Metrics per fold\n",
    "        aucs .append(roc_auc_score           (y_te, y_pred_prob))\n",
    "        accs .append(accuracy_score          (y_te, y_pred))\n",
    "        precs.append(precision_score         (y_te, y_pred, zero_division=0))\n",
    "        recs .append(recall_score            (y_te, y_pred))\n",
    "        f1s .append(f1_score                  (y_te, y_pred))\n",
    "        aps .append(average_precision_score  (y_te, y_pred_prob))\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_te, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_te, y_pred_prob)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        # Feature importances\n",
    "        for i, imp in enumerate(best_model.feature_importances_):\n",
    "            feature_importances[feature_names[i]].append(imp)\n",
    "\n",
    "    # Compute foldwise-averaged scores\n",
    "    mean_auc     = np.mean(aucs)\n",
    "    mean_acc     = np.mean(accs)\n",
    "    mean_prec    = np.mean(precs)\n",
    "    mean_rec     = np.mean(recs)\n",
    "    mean_f1      = np.mean(f1s)\n",
    "    mean_spec    = np.mean(specs)\n",
    "    mean_pr_auc  = np.mean(aps)\n",
    "    mean_cind    = mean_auc\n",
    "\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged confusion & metrics table\n",
    "    display_fold_averages(\n",
    "        k, df,\n",
    "        macro_cm,\n",
    "        macro_tp, macro_fp,\n",
    "        macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec,\n",
    "        mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc,\n",
    "        mean_cind, mean_pr_auc,\n",
    "        \"LightGBM with Optuna\"\n",
    "    )\n",
    "\n",
    "    # Plot foldwise-averaged ROC & build return object\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    rocname        = os.path.join(path_figure, 'lightGBM_roc_curve_kfCV_optuna.png')\n",
    "    roc_lightgbmOptuna = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'lightGBM with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # Plot foldwise-averaged Precision-Recall curve\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'lightGBM_prerec_curve_kfCV_optuna.png')\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # Average feature importances & export\n",
    "    avg_imp = {f: np.mean(imps) for f, imps in feature_importances.items()}\n",
    "    sorted_imp = dict(sorted(avg_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({'Feature': list(sorted_imp.keys()), 'Importance': list(sorted_imp.values())})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values('Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'lightgbm_feature_importances_kfCV_optuna.xlsx'), index=False)\n",
    "\n",
    "    # Plot feature importances\n",
    "    def plot_importance(title, imp_dict, xlabel):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.set_title(title)\n",
    "        keys   = list(imp_dict.keys())[:10]\n",
    "        values = list(imp_dict.values())[:10]\n",
    "        ax.barh(keys, values)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "        for lbl in ax.get_yticklabels():\n",
    "            lbl.set_fontproperties(font_prop)\n",
    "        ax.invert_yaxis()\n",
    "        plt.savefig(os.path.join(path_figure, 'lightgbm_feature_importances_kfCV_optuna.png'))\n",
    "        plt.show(); plt.close()\n",
    "\n",
    "    print('')\n",
    "    print(f'◆ {k}-fold CV による LightGBM Feature Importance (Optuna)')\n",
    "    print('')\n",
    "    plot_importance(\n",
    "        f\"Top 10 Feature Importances in {k}-fold CV of LightGBM (Optuna)\",\n",
    "        sorted_imp, \"Average Importance\"\n",
    "    )\n",
    "\n",
    "    # Retrain best model on full data & save\n",
    "    best_full = lgb.LGBMClassifier(\n",
    "        **study.best_params,\n",
    "        random_state=random_state,\n",
    "        objective='binary',\n",
    "        verbosity=-1\n",
    "    )\n",
    "    with open(os.devnull, \"w\") as f, \\\n",
    "         contextlib.redirect_stdout(f), \\\n",
    "         contextlib.redirect_stderr(f):\n",
    "        best_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'lightgbm_full_model_optuna.pkl'), 'wb') as file:\n",
    "        pickle.dump(best_full, file)\n",
    "\n",
    "    # Hold-out for SHAP & LIME\n",
    "    holdout = lgb.LGBMClassifier(\n",
    "        **study.best_params,\n",
    "        random_state=random_state,\n",
    "        objective='binary',\n",
    "        verbosity=-1\n",
    "    )\n",
    "    holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_shap_values_holdout_optuna',\n",
    "            'lightgbm_shap_values_holdout_optuna',\n",
    "            'LightGBM kfCV with Optuna',\n",
    "            task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_lime_explanation_holdout_optuna',\n",
    "            'lightgbm_lime_feature_contributions_holdout_optuna',\n",
    "            'LightGBM kfCV with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return\n",
    "    res = [mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]\n",
    "    res2 = pd.DataFrame([res],\n",
    "                        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "                        index=['LightGBM with Optuna'])\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "    return [res2, roc_lightgbmOptuna]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LightGBMTunerOptunaKFold(k=k, show_shap=True, perform_lime=True, target='log_loss'):\n",
    "    import os\n",
    "    import pickle\n",
    "    import contextlib\n",
    "    from contextlib import redirect_stderr\n",
    "    from collections import defaultdict\n",
    "\n",
    "    import lightgbm as lgb\n",
    "    from optuna.integration import LightGBMTunerCV\n",
    "    import optuna\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score, recall_score, f1_score,\n",
    "        confusion_matrix, roc_curve, precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.font_manager as fm\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ LightGBMTuner k-Fold CV with Optuna (Foldwise-Averaged, optimizing {target}) ■■■')\n",
    "    print('')\n",
    "    print('----- Be patient. It may take a while. -----')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1].tolist()\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "\n",
    "    # Stratified K-Fold cross-validation setup\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    folds = list(skf.split(X, y))\n",
    "\n",
    "    # Prepare LightGBM dataset\n",
    "    train_data = lgb.Dataset(X, label=y)\n",
    "\n",
    "    # Fixed parameters with chosen metric\n",
    "    metric_name = 'auc' if target == 'auc' else 'binary_logloss'\n",
    "    fixed_params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": metric_name,\n",
    "        \"verbosity\": -1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "\n",
    "    # Initialize LightGBMTunerCV\n",
    "    tuner = LightGBMTunerCV(\n",
    "        params=fixed_params,\n",
    "        train_set=train_data,\n",
    "        folds=folds,\n",
    "        num_boost_round=1000\n",
    "    )\n",
    "\n",
    "    # Enable Optuna INFO logs, silence LightGBM warnings\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    with open(os.devnull, 'w') as err:\n",
    "        with redirect_stderr(err):\n",
    "            tuner.run()\n",
    "\n",
    "    # Best hyperparameters\n",
    "    best_params = tuner.best_params\n",
    "    print('')\n",
    "    print(\"◇ Best hyperparameters: \", best_params)\n",
    "    print('')\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    feature_importances = defaultdict(list)\n",
    "\n",
    "    # Foldwise evaluation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = lgb.LGBMClassifier(**best_params, random_state=random_state)\n",
    "        with open(os.devnull, 'w') as err:\n",
    "            with redirect_stderr(err):\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred      = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Metrics per fold\n",
    "        aucs .append(roc_auc_score            (y_test, y_pred_prob))\n",
    "        accs .append(accuracy_score            (y_test, y_pred))\n",
    "        precs.append(precision_score           (y_test, y_pred, zero_division=0))\n",
    "        recs .append(recall_score              (y_test, y_pred))\n",
    "        f1s .append(f1_score                    (y_test, y_pred))\n",
    "        aps .append(average_precision_score    (y_test, y_pred_prob))\n",
    "        specs.append(tn / (tn + fp))\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        # Feature importances\n",
    "        for i, imp in enumerate(model.feature_importances_):\n",
    "            feature_importances[feature_names[i]].append(imp)\n",
    "\n",
    "    # Compute foldwise-averaged scores\n",
    "    mean_auc     = np.mean(aucs)\n",
    "    mean_acc     = np.mean(accs)\n",
    "    mean_prec    = np.mean(precs)\n",
    "    mean_rec     = np.mean(recs)\n",
    "    mean_f1      = np.mean(f1s)\n",
    "    mean_spec    = np.mean(specs)\n",
    "    mean_pr_auc  = np.mean(aps)\n",
    "    mean_cind    = mean_auc\n",
    "\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged confusion & metrics table\n",
    "    display_fold_averages(\n",
    "        k, df,\n",
    "        macro_cm,\n",
    "        macro_tp, macro_fp,\n",
    "        macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec,\n",
    "        mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc,\n",
    "        mean_cind, mean_pr_auc,\n",
    "        \"LightGBMTuner with Optuna\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    rocname        = os.path.join(path_figure, 'lightGBM_tuner_roc_curve_kfCV_optuna.png')\n",
    "    roc_lightgbm_tuner_optuna = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'lightGBMtuner with Optuna'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        recall_sorted    = recalls[i][idx]\n",
    "        precision_sorted = precisions[i][idx]\n",
    "        precisions_interp.append(np.interp(mean_recall, recall_sorted, precision_sorted))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'lightGBM_tuner_prerec_curve_kfCV_optuna.png')\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Average feature importances & export-----------------\n",
    "    avg_imp = {f: np.mean(imps) for f, imps in feature_importances.items()}\n",
    "    sorted_imp = dict(sorted(avg_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({'Feature': list(sorted_imp.keys()), 'Importance': list(sorted_imp.values())})\n",
    "    fi_df['Abs_Importance'] = fi_df['Importance'].abs()\n",
    "    fi_df = fi_df.sort_values('Abs_Importance', ascending=False).drop('Abs_Importance', axis=1)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'lightgbm_tuner_feature_importances_kfCV_optuna.xlsx'), index=False)\n",
    "\n",
    "    # -----------------Plot feature importances-----------------\n",
    "    def plot_importance(title, imp_dict, xlabel):\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax.set_title(title)\n",
    "        keys   = list(imp_dict.keys())[:10]\n",
    "        values = list(imp_dict.values())[:10]\n",
    "        ax.barh(keys, values)\n",
    "        ax.set_xlabel(xlabel)\n",
    "        font_prop = fm.FontProperties(fname='/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc')\n",
    "        for lbl in ax.get_yticklabels():\n",
    "            lbl.set_fontproperties(font_prop)\n",
    "        ax.invert_yaxis()\n",
    "        plt.savefig(os.path.join(path_figure, 'lightgbm_tuner_feature_importances_kfCV_optuna.png'))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    print('')\n",
    "    print(f'◆ {k}-Fold CV による LightGBM Feature Importance (Optuna)')\n",
    "    print('')\n",
    "    plot_importance(\n",
    "        f\"Top 10 Feature Importances in {k}-Fold CV optimized with LightGBMTunerCV from Optuna\",\n",
    "        sorted_imp, \"Average Importance\"\n",
    "    )\n",
    "\n",
    "    # Retrain on full dataset & save model\n",
    "    best_model_full = lgb.LGBMClassifier(**best_params, random_state=random_state)\n",
    "    with open(os.devnull, \"w\") as f, \\\n",
    "         contextlib.redirect_stdout(f), \\\n",
    "         contextlib.redirect_stderr(f):\n",
    "        best_model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'lightgbm_tuner_full_model_optuna.pkl'), 'wb') as file:\n",
    "        pickle.dump(best_model_full, file)\n",
    "\n",
    "    # Hold-out for SHAP & LIME\n",
    "    best_model_holdout = lgb.LGBMClassifier(**best_params, random_state=random_state)\n",
    "    best_model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            best_model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_tuner_shap_values_holdout_optuna',\n",
    "            'lightgbm_tuner_shap_values_holdout_optuna',\n",
    "            'LightGBMTuner kfCV with Optuna',\n",
    "            task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            best_model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'lightgbm_tuner_lime_explanation_holdout_optuna',\n",
    "            'ligthgbm_tuner_lime_feature_contributions_holdout_optuna',\n",
    "            'LightGBMTuner kfCV with Optuna',\n",
    "            task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    optuna.logging.disable_default_handler()\n",
    "\n",
    "    res = [mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['LightGBMTuner with Optuna']\n",
    "    )\n",
    "    return [res2, roc_lightgbm_tuner_optuna]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# CatBoost K-Fold Cross Validation\n",
    "def CatBoostKFold(k=k, show_shap=True, perform_lime=True):\n",
    "    from catboost import CatBoostClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, roc_curve,\n",
    "        precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pickle\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    print('')\n",
    "    print('■■■ CatBoost kfCV　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(df.iloc[:, -1] > 0) / len(df)), 5)) + ' %)')\n",
    "    print('')\n",
    "    print('----- Be patient. It might take a little while. -----')\n",
    "    print('')\n",
    "\n",
    "    # X = df.iloc[:, :-1].values\n",
    "    # y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise-averaged metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # ROC/PR plotting data\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    # confusion rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    # Feature importances per fold\n",
    "    feature_importances = defaultdict(list)\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(X, y), 1):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = CatBoostClassifier(random_state=random_state, verbose=False)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred      = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score(y_test, y_pred)\n",
    "        prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score(y_test, y_pred)\n",
    "        f1_fold   = f1_score(y_test, y_pred)\n",
    "        ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs .append(auc_fold)\n",
    "        accs .append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs .append(rec_fold)\n",
    "        f1s .append(f1_fold)\n",
    "        specs.append(spec_fold)\n",
    "        aps  .append(ap_fold)\n",
    "\n",
    "        # ROC curve data for this fold\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data for this fold\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        print(f\"Fold {fold_idx:>2}: \"\n",
    "              f\"AUC={auc_fold:.4f}, Acc={acc_fold:.4f}, \"\n",
    "              f\"Prec={prec_fold:.4f}, Rec={rec_fold:.4f}, F1={f1_fold:.4f}\")\n",
    "\n",
    "        # collect feature importances\n",
    "        for i, imp in enumerate(model.feature_importances_):\n",
    "            feature_importances[feature_names[i]].append(imp)\n",
    "\n",
    "    # -----------------Calculate foldwise-averaged scores-----------------\n",
    "    mean_auc   = np.mean(aucs)\n",
    "    mean_acc   = np.mean(accs)\n",
    "    mean_prec  = np.mean(precs)\n",
    "    mean_rec   = np.mean(recs)\n",
    "    mean_f1    = np.mean(f1s)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_pr_auc= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # foldwise-averaged confusion matrix\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # display foldwise-averaged table\n",
    "    display_fold_averages(\n",
    "        k, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"CatBoost\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged confusion heatmap-----------------\n",
    "    print('\\n□ Foldwise-averaged Confusion Matrix (%):')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'],\n",
    "                yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Foldwise-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    hmname = os.path.join(path_figure, 'catboost_confusion_heatmap_kfCV.png')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr    = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr    = np.mean(tprs_interp, axis=0)\n",
    "    rocname     = os.path.join(path_figure, 'catboost_roc_curve_kfCV.png')\n",
    "    roc_catboost = np.array([mean_fpr, mean_tpr, mean_auc, 'Catboost'], dtype=object)\n",
    "\n",
    "    print('\\n□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'catboost_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {k} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Retrain on full data & save model-----------------\n",
    "    model_full = CatBoostClassifier(random_state=random_state, verbose=False)\n",
    "    model_full.fit(X, y)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    with open(os.path.join(path_model, 'catboost_kfCV_full.pkl'), 'wb') as f:\n",
    "        pickle.dump(model_full, f)\n",
    "\n",
    "    # -----------------Aggregate & save feature importances-----------------\n",
    "    avg_imp = {f: np.mean(imps) for f, imps in feature_importances.items()}\n",
    "    sorted_imp = dict(sorted(avg_imp.items(), key=lambda x: x[1], reverse=True))\n",
    "    fi_df = pd.DataFrame({'Feature': list(sorted_imp.keys()),\n",
    "                          'Importance': list(sorted_imp.values())})\n",
    "    fi_df['Abs'] = fi_df.Importance.abs()\n",
    "    fi_df = fi_df.sort_values('Abs', ascending=False).drop('Abs', axis=1)\n",
    "    fi_df.to_excel(os.path.join(path_table, 'catboost_feature_importances_kfCV.xlsx'), index=False)\n",
    "\n",
    "    # -----------------Plot top-10 feature importances-----------------\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top10 = fi_df.head(10)\n",
    "    ax.barh(top10.Feature, top10.Importance)\n",
    "    ax.set_xlabel('Average Importance')\n",
    "    ax.set_title(f'Top 10 Feature Importances in {k}-fold CV of CatBoost')\n",
    "    ax.invert_yaxis()\n",
    "    # no aspect enforcement for importances\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'catboost_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # SHAP & LIME (unchanged)\n",
    "    model_holdout = CatBoostClassifier(random_state=random_state, verbose=False)\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'catboost_shap_values_holdout',\n",
    "            'catboost_shap_values_holdout',\n",
    "            'CatBoost', task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'catboost_lime_explanation_holdout',\n",
    "            'catboost_lime_feature_contributions_holdout',\n",
    "            'CatBoost', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # -----------------Prepare and return results-----------------\n",
    "    res = [mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]\n",
    "    res2 = pd.DataFrame([res],\n",
    "                        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "                        index=['CatBoost'])\n",
    "\n",
    "    return [res2, roc_catboost]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Yggdrasil Decision Forest (K-Fold CV版, truly bullet-proof importance parsing with foldwise-averaged metrics)\n",
    "def YggdrasilDecisionForestKFold(\n",
    "    n_splits=k,\n",
    "    show_shap=False,\n",
    "    perform_lime=True,\n",
    "    importance_key_preference=None,\n",
    "    random_state=random_state\n",
    "):\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        roc_curve, precision_recall_curve, confusion_matrix, average_precision_score\n",
    "    )\n",
    "    import ydf\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Yggdrasil Decision Forest kfCV (Foldwise averaged)　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(df.iloc[:, -1] > 0) / len(df)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "    df[label_column] = df[label_column].astype(int)\n",
    "\n",
    "    # Use StratifiedKFold instead of KFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    feature_importance_list = []\n",
    "\n",
    "    default_keys = ['TRAINING_GAIN','SUM_SCORE','NUM_NODES','NUM_AS_ROOT','GAIN_SUM']\n",
    "    keys_to_try = importance_key_preference or default_keys\n",
    "    printed_key = False\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df, df[label_column]), 1):\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df  = df.iloc[test_idx]\n",
    "\n",
    "        # train model\n",
    "        model = ydf.GradientBoostedTreesLearner(\n",
    "            label=label_column,\n",
    "            num_trees=400, max_depth=10,\n",
    "            shrinkage=0.02, min_examples=2,\n",
    "            subsample=0.9, sampling_method=\"RANDOM\"\n",
    "        ).train(train_df)\n",
    "\n",
    "        # --- bullet-proof importance parsing ---\n",
    "        var_imp = model.variable_importances()\n",
    "        tuple_key = None\n",
    "        for key in keys_to_try:\n",
    "            cand = var_imp.get(key)\n",
    "            if isinstance(cand, (list, tuple)) and cand and isinstance(cand[0], tuple) and len(cand[0]) >= 2:\n",
    "                tuple_key = key; break\n",
    "        if tuple_key is None:\n",
    "            for key, cand in var_imp.items():\n",
    "                if isinstance(cand, (list, tuple)) and cand and isinstance(cand[0], tuple) and len(cand[0]) >= 2:\n",
    "                    tuple_key = key; break\n",
    "\n",
    "        if tuple_key:\n",
    "            imp_list = var_imp[tuple_key]\n",
    "            if not printed_key:\n",
    "                print(f\"◆ Using importance key: {tuple_key}\")\n",
    "                printed_key = True\n",
    "            norm = {}\n",
    "            for item in imp_list:\n",
    "                if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                    if isinstance(item[0], str) and isinstance(item[1], (int, float, np.floating, np.integer)):\n",
    "                        feat, score = item[0], item[1]\n",
    "                    elif isinstance(item[1], str) and isinstance(item[0], (int, float, np.floating, np.integer)):\n",
    "                        feat, score = item[1], item[0]\n",
    "                    else:\n",
    "                        continue\n",
    "                elif hasattr(item, 'feature') and hasattr(item, 'importance'):\n",
    "                    feat, score = item.feature, item.importance\n",
    "                else:\n",
    "                    continue\n",
    "                norm[str(feat).strip().lower()] = float(score)\n",
    "            imp_vector = np.array(\n",
    "                [norm.get(str(f).strip().lower(), 0.0) for f in feature_names],\n",
    "                dtype=float\n",
    "            )\n",
    "        else:\n",
    "            imp_vector = None\n",
    "            for key, cand in var_imp.items():\n",
    "                if isinstance(cand, (list, tuple, np.ndarray)) and len(cand) == len(feature_names):\n",
    "                    if all(isinstance(v, (int, float, np.floating, np.integer)) for v in cand):\n",
    "                        imp_vector = np.array(cand, dtype=float)\n",
    "                        if not printed_key:\n",
    "                            print(f\"◆ Using numeric importances from key: {key}\")\n",
    "                            printed_key = True\n",
    "                        break\n",
    "            if imp_vector is None:\n",
    "                print(\"◇ Warning: no valid importances found; using zeros.\")\n",
    "                imp_vector = np.zeros(len(feature_names), dtype=float)\n",
    "        feature_importance_list.append(imp_vector)\n",
    "\n",
    "        # --- predictions & metrics (batch) ---\n",
    "        y_true = test_df[label_column].to_numpy()\n",
    "        X_dict = {col: test_df[col].values for col in feature_names}\n",
    "        distr = model.predict(X_dict)\n",
    "        if isinstance(distr, dict):\n",
    "            probs = np.array(distr['probabilities'])[:, 1]\n",
    "        elif isinstance(distr, np.ndarray):\n",
    "            if distr.ndim == 2 and distr.shape[1] >= 2:\n",
    "                probs = distr[:, 1]\n",
    "            else:\n",
    "                probs = distr\n",
    "        else:\n",
    "            probs = distr.probabilities_[:, 1]\n",
    "        bins = (probs >= 0.5).astype(int)\n",
    "\n",
    "        # per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, bins).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # per-fold metrics\n",
    "        aucs .append(roc_auc_score(y_true, probs))\n",
    "        accs .append(accuracy_score(y_true, bins))\n",
    "        precs.append(precision_score(y_true, bins, zero_division=0))\n",
    "        recs .append(recall_score(y_true, bins))\n",
    "        f1s .append(f1_score(y_true, bins))\n",
    "        specs.append(tn / (tn + fp))\n",
    "        aps .append(average_precision_score(y_true, probs))\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        # Precision-Recall curve data\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_true, probs)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        print(\n",
    "            f\"Fold {fold_idx:>2} — \"\n",
    "            f\"AUC: {aucs[-1]:.4f}, Acc: {accs[-1]:.4f}, \"\n",
    "            f\"Prec: {precs[-1]:.4f}, Rec: {recs[-1]:.4f}, F1: {f1s[-1]:.4f}\"\n",
    "        )\n",
    "\n",
    "    # -----------------Calculate foldwise-averaged scores-----------------\n",
    "    mean_auc   = np.mean(aucs)\n",
    "    mean_acc   = np.mean(accs)\n",
    "    mean_prec  = np.mean(precs)\n",
    "    mean_rec   = np.mean(recs)\n",
    "    mean_f1    = np.mean(f1s)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_pr_auc= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # foldwise-averaged confusion matrix\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # display foldwise-averaged table\n",
    "    display_fold_averages(\n",
    "        n_splits, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"Yggdrasil Decision Forest\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged confusion heatmap-----------------\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Confusion Matrix (%):')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Foldwise-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    hmname = os.path.join(path_figure, 'YDF_confusion_heatmap_kfCV.png')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    rocname = os.path.join(path_figure, 'YDF_roc_curve_kfCV.png')\n",
    "    roc_array = np.array([mean_fpr, mean_tpr_curve, mean_auc, 'Ygggdrasil Decision Forest'], dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {n_splits} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname = os.path.join(path_figure, 'YDF_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {n_splits} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # retrain on full data\n",
    "    model_full = ydf.GradientBoostedTreesLearner(label=label_column).train(df)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_full.save(os.path.join(path_model, \"YDF_KFold_CV_full\"))\n",
    "\n",
    "    # aggregate & save importances\n",
    "    mean_imp = np.mean(feature_importance_list, axis=0)\n",
    "    imp_df = pd.DataFrame({'Feature': feature_names, 'YDF_Importance': mean_imp})\n",
    "    imp_df['Abs'] = imp_df.YDF_Importance.abs()\n",
    "    imp_df = imp_df.sort_values('Abs', ascending=False).drop('Abs', axis=1)\n",
    "    imp_df.to_excel(os.path.join(path_table, 'YDF_feature_importances_kfCV.xlsx'), index=False)\n",
    "\n",
    "    # plot top-10 importances\n",
    "    top10 = imp_df.head(10)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(top10.Feature, top10.YDF_Importance)\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title(f'Top 10 Feature Importances ({n_splits}-Fold CV)')\n",
    "    ax.invert_yaxis()\n",
    "    # ax.set_aspect('equal', adjustable='box')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'YDF_feature_importances_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # SHAP & LIME (unchanged)\n",
    "    if show_shap:\n",
    "        ShapValueFunction(\n",
    "            model_made=model_full, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='YDF_SHAP', excel_name='YDF_SHAP_values',\n",
    "            method_name='Yggdrasil Decision Forest',\n",
    "            task_type='classification', model_type='ydf'\n",
    "        )\n",
    "    if perform_lime:\n",
    "        X = df[feature_names].to_numpy()\n",
    "        y = df[label_column].to_numpy()\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=model_full, df_data=df,\n",
    "            x_train_data=X, x_test_data=X, t_test_data=y,\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='YDF_lime_explanation_full',\n",
    "            excel_name='YDF_lime_feature_contributions_full',\n",
    "            method_name='Yggdrasil Decision Forest',\n",
    "            task_type='classification', random_state=random_state,\n",
    "            model_type='general'\n",
    "        )\n",
    "\n",
    "    # return metrics\n",
    "    metrics_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['Yggdrasil Decision Forest']\n",
    "    )\n",
    "    return [metrics_df, roc_array]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Yggdrasil Decision Forest (K-Fold CV + Optuna版, foldwise-averaged metrics)\n",
    "def YggdrasilDecisionForestOptunaKFold(\n",
    "    n_trials=20,\n",
    "    n_splits=k,\n",
    "    show_shap=False,\n",
    "    perform_lime=True,\n",
    "    importance_key_preference=None,\n",
    "    random_state=random_state,\n",
    "    target='log_loss'\n",
    "):\n",
    "    import ydf\n",
    "    import optuna\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, log_loss, roc_curve,\n",
    "        precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    from collections import defaultdict\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ Yggdrasil Decision Forest kfCV with Optuna (Foldwise-Averaged, optimizing {target}, Trial count {n_trials}) ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(df.iloc[:, -1] > 0) / len(df)), 5)) + ' %)')\n",
    "    print('')\n",
    "    print('----- Be patient. It takes a while.-----')\n",
    "    print('')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "\n",
    "    # --- Optuna Objective: maximize CV AUC or minimize CV LogLoss over k folds ---\n",
    "    def objective(trial):\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "        all_y, all_preds = [], []\n",
    "\n",
    "        # suggest hyperparameters\n",
    "        num_trees    = trial.suggest_int('num_trees', 100, 500)\n",
    "        max_depth    = trial.suggest_int('max_depth', 4, 16)\n",
    "        shrinkage    = trial.suggest_float('shrinkage', 0.01, 0.30, log=True)\n",
    "        min_examples = trial.suggest_int('min_examples', 1, 10)\n",
    "        subsample    = trial.suggest_float('subsample', 0.60, 1.00)\n",
    "\n",
    "        for train_idx, test_idx in kf.split(df, df[label_column]):\n",
    "            train_df = df.iloc[train_idx]\n",
    "            test_df  = df.iloc[test_idx]\n",
    "\n",
    "            model = ydf.GradientBoostedTreesLearner(\n",
    "                label=label_column,\n",
    "                num_trees=num_trees,\n",
    "                max_depth=max_depth,\n",
    "                shrinkage=shrinkage,\n",
    "                min_examples=min_examples,\n",
    "                subsample=subsample,\n",
    "                sampling_method=\"RANDOM\"\n",
    "            ).train(train_df, verbose=0)\n",
    "\n",
    "            # batch predict: true probabilities\n",
    "            X_dict = {col: test_df[col].values for col in feature_names}\n",
    "            distr = model.predict(X_dict)\n",
    "            if isinstance(distr, dict):\n",
    "                probs = np.array(distr['probabilities'])[:, 1]\n",
    "            elif isinstance(distr, np.ndarray):\n",
    "                if distr.ndim == 2 and distr.shape[1] >= 2:\n",
    "                    probs = distr[:, 1]\n",
    "                else:\n",
    "                    probs = distr.astype(float)\n",
    "            else:\n",
    "                probs = distr.probabilities_[:, 1]\n",
    "\n",
    "            all_preds.extend(probs.tolist())\n",
    "            all_y.extend(test_df[label_column].to_numpy().tolist())\n",
    "\n",
    "        if target == 'auc':\n",
    "            return roc_auc_score(all_y, all_preds)\n",
    "        else:\n",
    "            return -log_loss(all_y, all_preds)\n",
    "\n",
    "    # Enable Optuna logging\n",
    "    optuna.logging.enable_default_handler()\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    optuna.logging.disable_default_handler()\n",
    "\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for hk, hv in study.best_params.items():\n",
    "        print(f\"  {hk}: {hv}\")\n",
    "    if target == 'auc':\n",
    "        print(f\"Best CV AUC: {study.best_value:.4f}\\n\")\n",
    "    else:\n",
    "        print(f\"Best CV LogLoss: {-study.best_value:.4f}\\n\")\n",
    "\n",
    "    # --- Final k-fold CV with best params ---\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    all_y_test = []\n",
    "    all_prob_preds = []\n",
    "    all_bin_preds  = []\n",
    "    feature_importance_list = []\n",
    "    fold_aucs, fold_accs, fold_precs, fold_recs, fold_f1s = [], [], [], [], []\n",
    "    specs, aps = [], []\n",
    "\n",
    "    # for ROC/PR plotting\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    # for confusion matrix rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    printed_key = False\n",
    "    keys_to_try = importance_key_preference or ['TRAINING_GAIN','SUM_SCORE','NUM_NODES','NUM_AS_ROOT','GAIN_SUM']\n",
    "\n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(df, df[label_column]), 1):\n",
    "        train_df = df.iloc[train_idx]\n",
    "        test_df  = df.iloc[test_idx]\n",
    "\n",
    "        # train with best params\n",
    "        p = study.best_params\n",
    "        model = ydf.GradientBoostedTreesLearner(\n",
    "            label=label_column,\n",
    "            num_trees=p['num_trees'],\n",
    "            max_depth=p['max_depth'],\n",
    "            shrinkage=p['shrinkage'],\n",
    "            min_examples=p['min_examples'],\n",
    "            subsample=p['subsample'],\n",
    "            sampling_method=\"RANDOM\"\n",
    "        ).train(train_df, verbose=0)\n",
    "\n",
    "        # --- bullet-proof importance parsing ---\n",
    "        var_imp = model.variable_importances()\n",
    "        tuple_key = None\n",
    "        for key in keys_to_try:\n",
    "            cand = var_imp.get(key)\n",
    "            if isinstance(cand, (list, tuple)) and cand and isinstance(cand[0], tuple) and len(cand[0]) >= 2:\n",
    "                tuple_key = key; break\n",
    "        if tuple_key is None:\n",
    "            for key, cand in var_imp.items():\n",
    "                if isinstance(cand, (list, tuple)) and cand and isinstance(cand[0], tuple) and len(cand[0]) >= 2:\n",
    "                    tuple_key = key; break\n",
    "        if tuple_key:\n",
    "            imp_list = var_imp[tuple_key]\n",
    "            if not printed_key:\n",
    "                print(f\"◆ Using importance key: {tuple_key}\"); printed_key = True\n",
    "            norm = {}\n",
    "            for item in imp_list:\n",
    "                if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                    if isinstance(item[0], str) and isinstance(item[1], (int, float, np.floating, np.integer)):\n",
    "                        feat, score = item[0], item[1]\n",
    "                    elif isinstance(item[1], str) and isinstance(item[0], (int, float, np.floating, np.integer)):\n",
    "                        feat, score = item[1], item[0]\n",
    "                    else: continue\n",
    "                elif hasattr(item, 'feature') and hasattr(item, 'importance'):\n",
    "                    feat, score = item.feature, item.importance\n",
    "                else:\n",
    "                    continue\n",
    "                norm[str(feat).strip().lower()] = float(score)\n",
    "            imp_vector = np.array([norm.get(f.strip().lower(),0.0) for f in feature_names], dtype=float)\n",
    "        else:\n",
    "            imp_vector = None\n",
    "            for key, cand in var_imp.items():\n",
    "                if isinstance(cand, (list, tuple, np.ndarray)) and len(cand)==len(feature_names) and all(isinstance(v,(int,float,np.floating,np.integer)) for v in cand):\n",
    "                    imp_vector = np.array(cand, dtype=float)\n",
    "                    if not printed_key:\n",
    "                        print(f\"◆ Using numeric importances from key: {key}\"); printed_key=True\n",
    "                    break\n",
    "            if imp_vector is None:\n",
    "                print(\"◇ Warning: no valid importances found; using zeros.\")\n",
    "                imp_vector = np.zeros(len(feature_names), dtype=float)\n",
    "        feature_importance_list.append(imp_vector)\n",
    "\n",
    "        # --- batch predictions & metrics ---\n",
    "        X_dict = {col: test_df[col].values for col in feature_names}\n",
    "        distr = model.predict(X_dict)\n",
    "        if isinstance(distr, dict):\n",
    "            probs = np.array(distr['probabilities'])[:, 1]\n",
    "        elif isinstance(distr, np.ndarray):\n",
    "            if distr.ndim == 2 and distr.shape[1] >= 2:\n",
    "                probs = distr[:, 1]\n",
    "            else:\n",
    "                probs = distr.astype(float)\n",
    "        else:\n",
    "            probs = distr.probabilities_[:, 1]\n",
    "        bins = (probs >= 0.5).astype(int)\n",
    "\n",
    "        y_true = test_df[label_column].to_numpy()\n",
    "        all_y_test.extend(y_true.tolist())\n",
    "        all_prob_preds.extend(probs.tolist())\n",
    "        all_bin_preds.extend(bins.tolist())\n",
    "\n",
    "        # confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, bins).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # per-fold metrics\n",
    "        fold_aucs .append(roc_auc_score(y_true, probs))\n",
    "        fold_accs .append(accuracy_score(y_true, bins))\n",
    "        fold_precs.append(precision_score(y_true, bins, zero_division=0))\n",
    "        fold_recs .append(recall_score(y_true, bins))\n",
    "        fold_f1s  .append(f1_score(y_true, bins))\n",
    "        specs    .append(tn/(tn+fp))\n",
    "        aps      .append(average_precision_score(y_true, probs))\n",
    "\n",
    "        # ROC/PR data\n",
    "        fpr, tpr, _ = roc_curve(y_true, probs)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_true, probs)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        print(f\"Fold {fold_idx:>2}: AUC={fold_aucs[-1]:.4f}, Acc={fold_accs[-1]:.4f}, Prec={fold_precs[-1]:.4f}, Rec={fold_recs[-1]:.4f}, F1={fold_f1s[-1]:.4f}\")\n",
    "\n",
    "    # -----------------Calculate foldwise-averaged scores-----------------\n",
    "    mean_auc   = np.mean(fold_aucs)\n",
    "    mean_acc   = np.mean(fold_accs)\n",
    "    mean_prec  = np.mean(fold_precs)\n",
    "    mean_rec   = np.mean(fold_recs)\n",
    "    mean_f1    = np.mean(fold_f1s)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_pr_auc= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # foldwise-averaged confusion matrix\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # display foldwise-averaged table\n",
    "    display_fold_averages(\n",
    "        n_splits, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"Yggdrasil Decision Forest with Optuna\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged confusion heatmap-----------------\n",
    "    print('\\n□ Foldwise-averaged Confusion Matrix (%):')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'], yticklabels=['True 0','True 1'])\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Foldwise-averaged Confusion Matrix (%)')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    hmname = os.path.join(path_figure, 'YDF_confusion_heatmap_kfCV_optuna.png')\n",
    "    plt.savefig(hmname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr    = np.linspace(0,1,100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr    = np.mean(tprs_interp, axis=0)\n",
    "    rocname     = os.path.join(path_figure, 'YDF_roc_curve_kfCV_optuna.png')\n",
    "    roc_array   = np.array([mean_fpr, mean_tpr, mean_auc, 'Yggdrasil Decision Forest with Optuna'], dtype=object)\n",
    "\n",
    "    print('\\n□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {n_splits} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0,1,100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'YDF_prerec_curve_kfCV_optuna.png')\n",
    "\n",
    "    print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {n_splits} Folds')\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right'); plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # retrain on full data with best params\n",
    "    p = study.best_params\n",
    "    model_full = ydf.GradientBoostedTreesLearner(\n",
    "        label=label_column,\n",
    "        num_trees=p['num_trees'],\n",
    "        max_depth=p['max_depth'],\n",
    "        shrinkage=p['shrinkage'],\n",
    "        min_examples=p['min_examples'],\n",
    "        subsample=p['subsample'],\n",
    "        sampling_method=\"RANDOM\"\n",
    "    ).train(df, verbose=0)\n",
    "    os.makedirs(path_model, exist_ok=True)\n",
    "    model_full.save(os.path.join(path_model, \"YDF_KFoldOptuna_full\"))\n",
    "\n",
    "    # aggregate & save importances\n",
    "    mean_imp = np.mean(feature_importance_list, axis=0)\n",
    "    imp_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'YDF_Importance': mean_imp\n",
    "    })\n",
    "    imp_df['Abs'] = imp_df.YDF_Importance.abs()\n",
    "    imp_df = imp_df.sort_values('Abs', ascending=False).drop('Abs', axis=1)\n",
    "    imp_df.to_excel(os.path.join(path_table, 'YDF_feature_importances_KFoldOptuna.xlsx'), index=False)\n",
    "\n",
    "    # plot top-10 importances\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top10 = imp_df.head(10)\n",
    "    ax.barh(top10.Feature, top10.YDF_Importance)\n",
    "    ax.set_xlabel('Relative Importance')\n",
    "    ax.set_title(f'Top 10 Feature Importances ({n_splits}-Fold Optuna)')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'YDF_feature_importances_KFoldOptuna.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # SHAP & LIME (unchanged)\n",
    "    if show_shap:\n",
    "        ShapValueFunction(\n",
    "            model_made=model_full, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='YDF_SHAP_Optuna', excel_name='YDF_SHAP_values_Optuna',\n",
    "            method_name='Yggdrasil Decision Forest with Optuna',\n",
    "            task_type='classification', model_type='ydf'\n",
    "        )\n",
    "    if perform_lime:\n",
    "        X = df[feature_names].to_numpy()\n",
    "        y = df[label_column].to_numpy()\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=model_full, df_data=df,\n",
    "            x_train_data=X, x_test_data=X, t_test_data=y,\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='YDF_lime_explanation_full_optuna',\n",
    "            excel_name='YDF_lime_feature_contributions_full_optuna',\n",
    "            method_name='Yggdrasil Decision Forest with Optuna',\n",
    "            task_type='classification', random_state=random_state,\n",
    "            model_type='general'\n",
    "        )\n",
    "\n",
    "    # return metrics\n",
    "    metrics_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['Yggdrasil Decision Forest with Optuna']\n",
    "    )\n",
    "    return [metrics_df, roc_array]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TabNet を用いた K-Fold CV版（Foldwise-Averaged Metrics, Normalization）\n",
    "def TabNetKFoldN(\n",
    "    n_splits=k,\n",
    "    perform_lime=True,\n",
    "    n1=16,\n",
    "    n2=16,\n",
    "    step_size=20,\n",
    "    max_epochs=20,\n",
    "    batch_size=32,\n",
    "    show_shap=False,\n",
    "    random_state=random_state\n",
    "):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import contextlib\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        roc_curve, precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    import torch\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "    # --- PyTorch TabNet Wrapper with scaling & true validation split ---\n",
    "    class TorchTabNetWrapper:\n",
    "        def __init__(self, feature_names, label_column):\n",
    "            self.feature_names = feature_names\n",
    "            self.label_column  = label_column\n",
    "            self.model         = None\n",
    "            self.scaler        = None\n",
    "\n",
    "        def __getstate__(self):\n",
    "            state = self.__dict__.copy()\n",
    "            if getattr(self, 'model', None) is not None:\n",
    "                tmp = tempfile.mkdtemp()\n",
    "                base = os.path.join(tmp, \"model\")\n",
    "                self.model.save_model(base)\n",
    "                with open(base + \".zip\", \"rb\") as f:\n",
    "                    state['model_bytes'] = f.read()\n",
    "                shutil.rmtree(tmp)\n",
    "                del state['model']\n",
    "            return state\n",
    "\n",
    "        def __setstate__(self, state):\n",
    "            self.__dict__.update(state)\n",
    "            if 'model_bytes' in state:\n",
    "                tmp = tempfile.mkdtemp()\n",
    "                base = os.path.join(tmp, \"model\")\n",
    "                with open(base + \".zip\", \"wb\") as f:\n",
    "                    f.write(state['model_bytes'])\n",
    "                self.model = TabNetClassifier(\n",
    "                    n_d=n1, n_a=n2, n_steps=5, gamma=1.5,\n",
    "                    lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "                    optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=2e-2),\n",
    "                    scheduler_params={\"step_size\": step_size, \"gamma\": 0.9},\n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    mask_type='entmax'\n",
    "                )\n",
    "                self.model.load_model(base)\n",
    "                shutil.rmtree(tmp)\n",
    "\n",
    "        def train(self, train_df):\n",
    "            X_full = train_df[self.feature_names].values.astype(np.float32)\n",
    "            y_full = train_df[self.label_column].values.astype(np.int64)\n",
    "            X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "                X_full, y_full,\n",
    "                test_size=0.2,\n",
    "                stratify=y_full,\n",
    "                random_state=random_state\n",
    "            )\n",
    "            self.scaler = MinMaxScaler().fit(X_tr)\n",
    "            X_tr = self.scaler.transform(X_tr)\n",
    "            X_val = self.scaler.transform(X_val)\n",
    "            self.model = TabNetClassifier(\n",
    "                n_d=n1, n_a=n2, n_steps=5, gamma=1.5,\n",
    "                lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "                optimizer_fn=torch.optim.Adam,\n",
    "                optimizer_params=dict(lr=2e-2),\n",
    "                scheduler_params={\"step_size\": step_size, \"gamma\": 0.9},\n",
    "                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                mask_type='entmax'\n",
    "            )\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                 contextlib.redirect_stdout(f), \\\n",
    "                 contextlib.redirect_stderr(f):\n",
    "                self.model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs,\n",
    "                    patience=10,\n",
    "                    batch_size=min(batch_size, X_tr.shape[0]),\n",
    "                    virtual_batch_size=min(batch_size, X_tr.shape[0]),\n",
    "                    num_workers=0,\n",
    "                    drop_last=False\n",
    "                )\n",
    "            return self\n",
    "\n",
    "        def predict_proba(self, data):\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                X = data[self.feature_names].values.astype(np.float32)\n",
    "            else:\n",
    "                arr = np.array(data, dtype=np.float32)\n",
    "                X = np.atleast_2d(arr)\n",
    "            X = self.scaler.transform(X)\n",
    "            return self.model.predict_proba(X)\n",
    "\n",
    "        def predict(self, data):\n",
    "            proba = self.predict_proba(data)\n",
    "            return (proba[:,1] >= 0.5).astype(int)\n",
    "\n",
    "        def variable_importances(self):\n",
    "            imp = self.model.feature_importances_\n",
    "            return [(name, float(imp[i])) for i, name in enumerate(self.feature_names)]\n",
    "\n",
    "        def save_model(self, file_name):\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"No model to save. Train first.\")\n",
    "            os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "            self.model.save_model(file_name)\n",
    "\n",
    "    # ————————————————————————————————————————————————\n",
    "    # 1) 準備\n",
    "    print('')\n",
    "    print('■■■ TabNet (PyTorch) with Normalization kfCV ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(df.iloc[:, -1] > 0) / len(df)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    if gpu_available:\n",
    "        using_device = \"GPU \" + gpu_name\n",
    "    else:\n",
    "        using_device = \"CPU\"\n",
    "    print(f\"Using device: {using_device}\\n\")\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    splits = list(skf.split(df, df[label_column]))\n",
    "\n",
    "\n",
    "    # merge tiny folds (既存の処理)\n",
    "    cleaned_splits = []\n",
    "    for idx, (tr_idx, te_idx) in enumerate(splits):\n",
    "        if idx == 0:\n",
    "            cleaned_splits.append((tr_idx, te_idx))\n",
    "            continue\n",
    "        p_tr, p_te = cleaned_splits[-1]\n",
    "        if len(tr_idx)<2 or len(te_idx)<2:\n",
    "            merged_te = np.concatenate([p_te, te_idx])\n",
    "            merged_tr = np.setdiff1d(np.arange(len(df)), merged_te)\n",
    "            cleaned_splits[-1] = (merged_tr, merged_te)\n",
    "        else:\n",
    "            cleaned_splits.append((tr_idx, te_idx))\n",
    "    splits = cleaned_splits\n",
    "    n_effective = len(splits)\n",
    "\n",
    "    # Lists for foldwise-averaged metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    imps_list = []\n",
    "    printed_key = False\n",
    "\n",
    "    # 2) CV ループ\n",
    "    for fold_no, (tr_idx, te_idx) in enumerate(splits, 1):\n",
    "        train_df = df.iloc[tr_idx].reset_index(drop=True)\n",
    "        test_df  = df.iloc[te_idx].reset_index(drop=True)\n",
    "\n",
    "        mdl = TorchTabNetWrapper(feature_names, label_column).train(train_df)\n",
    "\n",
    "        imp_pairs = mdl.variable_importances()\n",
    "        if not printed_key:\n",
    "            print(\"◆ Using importance key: TABNET_IMPORTANCE\")\n",
    "            printed_key = True\n",
    "        norm = {k.lower():v for k,v in imp_pairs}\n",
    "        imps_list.append(np.array([norm.get(f.lower(),0) for f in feature_names]))\n",
    "\n",
    "        proba     = mdl.predict_proba(test_df)[:,1]\n",
    "        preds_bin = (proba>=0.5).astype(int)\n",
    "        y_true    = test_df[label_column].to_numpy()\n",
    "\n",
    "        # per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, preds_bin).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_true, proba)\n",
    "        acc_fold  = accuracy_score(y_true, preds_bin)\n",
    "        prec_fold = precision_score(y_true, preds_bin, zero_division=0)\n",
    "        rec_fold  = recall_score(y_true, preds_bin)\n",
    "        f1_fold   = f1_score(y_true, preds_bin)\n",
    "        ap_fold   = average_precision_score(y_true, proba)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs .append(auc_fold)\n",
    "        accs .append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs .append(rec_fold)\n",
    "        f1s .append(f1_fold)\n",
    "        specs.append(spec_fold)\n",
    "        aps  .append(ap_fold)\n",
    "\n",
    "        # ROC curve for this fold\n",
    "        fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall for this fold\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_true, proba)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        print(f\"Fold {fold_no:>2} — \"\n",
    "              f\"AUC: {auc_fold:.4f}, Acc: {acc_fold:.4f}, \"\n",
    "              f\"Prec: {prec_fold:.4f}, Rec: {rec_fold:.4f}, F1: {f1_fold:.4f}\")\n",
    "\n",
    "\n",
    "    # -----------------Calculate foldwise-averaged scores-----------------\n",
    "    mean_auc   = np.mean(aucs)\n",
    "    mean_acc   = np.mean(accs)\n",
    "    mean_prec  = np.mean(precs)\n",
    "    mean_rec   = np.mean(recs)\n",
    "    mean_f1    = np.mean(f1s)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_pr_auc= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # foldwise-averaged confusion matrix\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # display foldwise-averaged table\n",
    "    display_fold_averages(\n",
    "        n_effective, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"TabNet with Normalization\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # -----------------Plot foldwise-averaged confusion heatmap-----------------\n",
    "    print('\\n□ Foldwise-averaged Confusion Matrix (%):')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'],\n",
    "                yticklabels=['True 0','True 1'])\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Foldwise-averaged Confusion Matrix (%)')\n",
    "    plt.savefig(os.path.join(path_figure, 'TabNet_confusion_heatmap_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr    = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr    = np.mean(tprs_interp, axis=0)\n",
    "    rocname     = os.path.join(path_figure, 'TabNet_roc_curve_kfCV.png')\n",
    "    roc_tabnet  = np.array([mean_fpr, mean_tpr, mean_auc, 'TabNet normalized'], dtype=object)\n",
    "\n",
    "    print('\\n□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {n_effective} Folds')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'TabNet_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {n_effective} Folds')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Retrain full model & save-----------------\n",
    "    full_mdl = TorchTabNetWrapper(feature_names, label_column).train(df)\n",
    "    full_mdl.save_model(os.path.join(path_model, \"TabNet_normalized_full_model_kFoldCV\"))\n",
    "\n",
    "    # -----------------Aggregate & save feature importances-----------------\n",
    "    mean_imp = np.mean(imps_list, axis=0)\n",
    "    imp_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'TabNet_Importance': mean_imp\n",
    "    })\n",
    "    imp_df['Abs'] = imp_df.TabNet_Importance.abs()\n",
    "    imp_df = imp_df.sort_values('Abs', ascending=False).drop('Abs', axis=1)\n",
    "    imp_df.to_excel(os.path.join(path_table, 'TabNet_normalized_feature_importances_KFold_CV.xlsx'), index=False)\n",
    "\n",
    "    # -----------------Plot top-10 feature importances-----------------\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top10 = imp_df.head(10)\n",
    "    ax.barh(top10.Feature, top10.TabNet_Importance)\n",
    "    ax.set_xlabel('Average Importance')\n",
    "    ax.set_title(f'Top 10 Feature Importances ({n_effective}-Fold CV of TabNet)')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'TabNet_normalized_feature_importances_KFold_CV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # SHAP & LIME (unchanged)\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_made=full_mdl,\n",
    "            df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x,\n",
    "            size_y_value=size_y,\n",
    "            path_figure_info=path_figure,\n",
    "            path_table_info=path_table,\n",
    "            figure_name='TabNet_SHAP_normalized',\n",
    "            excel_name='TabNet_SHAP_values_normalized',\n",
    "            method_name='TabNet normalized',\n",
    "            task_type='classification',\n",
    "            model_type='TabNet'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=full_mdl,\n",
    "            df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            t_test_data=df[label_column].to_numpy(),\n",
    "            size_x_value=size_x,\n",
    "            size_y_value=size_y,\n",
    "            path_figure_info=path_figure,\n",
    "            path_table_info=path_table,\n",
    "            figure_name='TabNet_normalized_lime_explanation_full',\n",
    "            excel_name='TabNet_normalized_lime_feature_contributions_full',\n",
    "            method_name='TabNet normazlied',\n",
    "            task_type='classification',\n",
    "            random_state=random_state,\n",
    "            model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    # -----------------Prepare and return results-----------------\n",
    "    metrics_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['TabNet normalized']\n",
    "    )\n",
    "    return [metrics_df, roc_tabnet]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TabNet を用いた K-Fold CV版（Foldwise-Averaged Metrics, Standardization）\n",
    "def TabNetKFoldS(\n",
    "    n_splits=k,\n",
    "    perform_lime=True,\n",
    "    n1=16,\n",
    "    n2=16,\n",
    "    step_size=20,\n",
    "    max_epochs=20,\n",
    "    batch_size=32,\n",
    "    show_shap=False,\n",
    "    random_state=random_state\n",
    "):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import contextlib\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score,\n",
    "        precision_score, recall_score, f1_score,\n",
    "        roc_curve, precision_recall_curve, confusion_matrix,\n",
    "        average_precision_score\n",
    "    )\n",
    "    import torch\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "    # --- PyTorch TabNet Wrapper with standardization & true validation split ---\n",
    "    class TorchTabNetWrapper:\n",
    "        def __init__(self, feature_names, label_column):\n",
    "            self.feature_names = feature_names\n",
    "            self.label_column  = label_column\n",
    "            self.model         = None\n",
    "            self.scaler        = None\n",
    "\n",
    "        def __getstate__(self):\n",
    "            state = self.__dict__.copy()\n",
    "            if getattr(self, 'model', None) is not None:\n",
    "                tmp = tempfile.mkdtemp()\n",
    "                base = os.path.join(tmp, \"model\")\n",
    "                self.model.save_model(base)\n",
    "                with open(base + \".zip\", \"rb\") as f:\n",
    "                    state['model_bytes'] = f.read()\n",
    "                shutil.rmtree(tmp)\n",
    "                del state['model']\n",
    "            return state\n",
    "\n",
    "        def __setstate__(self, state):\n",
    "            self.__dict__.update(state)\n",
    "            if 'model_bytes' in state:\n",
    "                tmp = tempfile.mkdtemp()\n",
    "                base = os.path.join(tmp, \"model\")\n",
    "                with open(base + \".zip\", \"wb\") as f:\n",
    "                    f.write(state['model_bytes'])\n",
    "                self.model = TabNetClassifier(\n",
    "                    n_d=n1, n_a=n2, n_steps=5, gamma=1.5,\n",
    "                    lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "                    optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=2e-2),\n",
    "                    scheduler_params={\"step_size\": step_size, \"gamma\": 0.9},\n",
    "                    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                    mask_type='entmax'\n",
    "                )\n",
    "                self.model.load_model(base)\n",
    "                shutil.rmtree(tmp)\n",
    "\n",
    "        def train(self, train_df):\n",
    "            X_full = train_df[self.feature_names].values.astype(np.float32)\n",
    "            y_full = train_df[self.label_column].values.astype(np.int64)\n",
    "            X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "                X_full, y_full,\n",
    "                test_size=0.2,\n",
    "                stratify=y_full,\n",
    "                random_state=random_state\n",
    "            )\n",
    "            self.scaler = StandardScaler().fit(X_tr)\n",
    "            X_tr = self.scaler.transform(X_tr)\n",
    "            X_val = self.scaler.transform(X_val)\n",
    "            self.model = TabNetClassifier(\n",
    "                n_d=n1, n_a=n2, n_steps=5, gamma=1.5,\n",
    "                lambda_sparse=1e-3, momentum=0.3, clip_value=2.,\n",
    "                optimizer_fn=torch.optim.Adam,\n",
    "                optimizer_params=dict(lr=2e-2),\n",
    "                scheduler_params={\"step_size\": step_size, \"gamma\": 0.9},\n",
    "                scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                mask_type='entmax'\n",
    "            )\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                 contextlib.redirect_stdout(f), \\\n",
    "                 contextlib.redirect_stderr(f):\n",
    "                self.model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs,\n",
    "                    patience=10,\n",
    "                    batch_size=min(batch_size, X_tr.shape[0]),\n",
    "                    virtual_batch_size=min(batch_size, X_tr.shape[0]),\n",
    "                    num_workers=0,\n",
    "                    drop_last=False\n",
    "                )\n",
    "            return self\n",
    "\n",
    "        def predict_proba(self, data):\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                X = data[self.feature_names].values.astype(np.float32)\n",
    "            else:\n",
    "                arr = np.array(data, dtype=np.float32)\n",
    "                X = np.atleast_2d(arr)\n",
    "            X = self.scaler.transform(X)\n",
    "            return self.model.predict_proba(X)\n",
    "\n",
    "        def predict(self, data):\n",
    "            proba = self.predict_proba(data)\n",
    "            return (proba[:,1] >= 0.5).astype(int)\n",
    "\n",
    "        def variable_importances(self):\n",
    "            imp = self.model.feature_importances_\n",
    "            return [(name, float(imp[i])) for i, name in enumerate(self.feature_names)]\n",
    "\n",
    "        def save_model(self, file_name):\n",
    "            if self.model is None:\n",
    "                raise ValueError(\"No model to save. Train first.\")\n",
    "            os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "            self.model.save_model(file_name)\n",
    "\n",
    "    # ————————————————————————————————————————————————\n",
    "    # 1) 準備\n",
    "    print('')\n",
    "    print('■■■ TabNet (PyTorch) with Standardization kfCV ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(df.iloc[:, -1] > 0) / len(df)), 5)) + ' %)')\n",
    "    print('')\n",
    "    if gpu_available:\n",
    "        using_device = \"GPU \" + gpu_name\n",
    "    else:\n",
    "        using_device = \"CPU\"\n",
    "    print(f\"Using device: {using_device}\\n\")\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    splits = list(skf.split(df, df[label_column]))\n",
    "\n",
    "    # merge tiny folds (既存の処理)\n",
    "    cleaned_splits = []\n",
    "    for idx, (tr_idx, te_idx) in enumerate(splits):\n",
    "        if idx == 0:\n",
    "            cleaned_splits.append((tr_idx, te_idx))\n",
    "            continue\n",
    "        p_tr, p_te = cleaned_splits[-1]\n",
    "        if len(tr_idx)<2 or len(te_idx)<2:\n",
    "            merged_te = np.concatenate([p_te, te_idx])\n",
    "            merged_tr = np.setdiff1d(np.arange(len(df)), merged_te)\n",
    "            cleaned_splits[-1] = (merged_tr, merged_te)\n",
    "        else:\n",
    "            cleaned_splits.append((tr_idx, te_idx))\n",
    "    splits = cleaned_splits\n",
    "    n_effective = len(splits)\n",
    "\n",
    "    # Lists for foldwise-averaged metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs, precisions, recalls = [], [], [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "    imps_list = []\n",
    "    printed_key = False\n",
    "\n",
    "    # 2) CV ループ\n",
    "    for fold_no, (tr_idx, te_idx) in enumerate(splits, 1):\n",
    "        train_df = df.iloc[tr_idx].reset_index(drop=True)\n",
    "        test_df  = df.iloc[te_idx].reset_index(drop=True)\n",
    "\n",
    "        mdl = TorchTabNetWrapper(feature_names, label_column).train(train_df)\n",
    "\n",
    "        imp_pairs = mdl.variable_importances()\n",
    "        if not printed_key:\n",
    "            print(\"◆ Using importance key: TABNET_IMPORTANCE\")\n",
    "            printed_key = True\n",
    "        norm = {k.lower():v for k,v in imp_pairs}\n",
    "        imps_list.append(np.array([norm.get(f.lower(),0) for f in feature_names]))\n",
    "\n",
    "        proba     = mdl.predict_proba(test_df)[:,1]\n",
    "        preds_bin = (proba>=0.5).astype(int)\n",
    "        y_true    = test_df[label_column].to_numpy()\n",
    "\n",
    "        # per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, preds_bin).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn/total)\n",
    "        fp_rates.append(fp/total)\n",
    "        fn_rates.append(fn/total)\n",
    "        tp_rates.append(tp/total)\n",
    "\n",
    "        # per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_true, proba)\n",
    "        acc_fold  = accuracy_score(y_true, preds_bin)\n",
    "        prec_fold = precision_score(y_true, preds_bin, zero_division=0)\n",
    "        rec_fold  = recall_score(y_true, preds_bin)\n",
    "        f1_fold   = f1_score(y_true, preds_bin)\n",
    "        ap_fold   = average_precision_score(y_true, proba)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs .append(auc_fold)\n",
    "        accs .append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s .append(f1_fold)\n",
    "        specs.append(spec_fold)\n",
    "        aps  .append(ap_fold)\n",
    "\n",
    "        # ROC curve for this fold\n",
    "        fpr, tpr, _ = roc_curve(y_true, proba)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall for this fold\n",
    "        p_vals, r_vals, _ = precision_recall_curve(y_true, proba)\n",
    "        precisions.append(p_vals); recalls.append(r_vals)\n",
    "\n",
    "        print(f\"Fold {fold_no:>2} — \"\n",
    "              f\"AUC: {auc_fold:.4f}, Acc: {acc_fold:.4f}, \"\n",
    "              f\"Prec: {prec_fold:.4f}, Rec: {rec_fold:.4f}, F1: {f1_fold:.4f}\")\n",
    "\n",
    "    # -----------------Calculate foldwise-averaged scores-----------------\n",
    "    mean_auc   = np.mean(aucs)\n",
    "    mean_acc   = np.mean(accs)\n",
    "    mean_prec  = np.mean(precs)\n",
    "    mean_rec   = np.mean(recs)\n",
    "    mean_f1    = np.mean(f1s)\n",
    "    mean_spec  = np.mean(specs)\n",
    "    mean_pr_auc= np.mean(aps)\n",
    "    mean_cind  = mean_auc\n",
    "\n",
    "    # foldwise-averaged confusion matrix\n",
    "    macro_tn = np.mean(tn_rates)\n",
    "    macro_fp = np.mean(fp_rates)\n",
    "    macro_fn = np.mean(fn_rates)\n",
    "    macro_tp = np.mean(tp_rates)\n",
    "    macro_cm = np.array([[macro_tn, macro_fn],\n",
    "                         [macro_fp, macro_tp]]) * 100\n",
    "\n",
    "    # display foldwise-averaged table\n",
    "    display_fold_averages(\n",
    "        n_effective, df, macro_cm,\n",
    "        macro_tp, macro_fp, macro_fn, macro_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"TabNet standardizated\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged confusion heatmap-----------------\n",
    "    print('\\n□ Foldwise-averaged Confusion Matrix (%):')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    sns.heatmap(macro_cm, annot=True, fmt='.2f', cbar=False,\n",
    "                xticklabels=['Pred 0','Pred 1'],\n",
    "                yticklabels=['True 0','True 1'])\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('Predicted label'); plt.ylabel('True label')\n",
    "    plt.title('Foldwise-averaged Confusion Matrix (%)')\n",
    "    plt.savefig(os.path.join(path_figure, 'TabNet_standardized_confusion_heatmap_kfCV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr    = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr    = np.mean(tprs_interp, axis=0)\n",
    "    rocname     = os.path.join(path_figure, 'TabNet_standardized_roc_curve_kfCV.png')\n",
    "    roc_tabnet  = np.array([mean_fpr, mean_tpr, mean_auc, 'TabNet standardized'], dtype=object)\n",
    "\n",
    "    print('\\n□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-averaged over {n_effective} Folds')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(rocname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall       = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls)):\n",
    "        idx = np.argsort(recalls[i])\n",
    "        precisions_interp.append(np.interp(mean_recall, recalls[i][idx], precisions[i][idx]))\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "    prerecname    = os.path.join(path_figure, 'TabNet_standardized_prerec_curve_kfCV.png')\n",
    "\n",
    "    print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve, label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls)):\n",
    "        plt.plot(recalls[i], precisions[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    ax = plt.gca(); ax.set_aspect('equal', adjustable='box')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-averaged over {n_effective} Folds')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(prerecname); plt.show(); plt.close()\n",
    "\n",
    "    # -----------------Retrain full model & save-----------------\n",
    "    full_mdl = TorchTabNetWrapper(feature_names, label_column).train(df)\n",
    "    full_mdl.save_model(os.path.join(path_model, \"TabNet_standardized_full_model\"))\n",
    "\n",
    "    # -----------------Aggregate & save feature importances-----------------\n",
    "    mean_imp = np.mean(imps_list, axis=0)\n",
    "    imp_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'TabNet_Importance': mean_imp\n",
    "    })\n",
    "    imp_df['Abs'] = imp_df.TabNet_Importance.abs()\n",
    "    imp_df = imp_df.sort_values('Abs', ascending=False).drop('Abs', axis=1)\n",
    "    imp_df.to_excel(os.path.join(path_table, 'TabNet_standardized_feature_importances_KFold_CV.xlsx'), index=False)\n",
    "\n",
    "    # -----------------Plot top-10 feature importances-----------------\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    top10 = imp_df.head(10)\n",
    "    ax.barh(top10.Feature, top10.TabNet_Importance)\n",
    "    ax.set_xlabel('Average Importance')\n",
    "    ax.set_title(f'Top 10 Feature Importances ({n_effective}-Fold CV of TabNet)')\n",
    "    ax.invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_figure, 'TabNet_standardized_feature_importances_KFold_CV.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # SHAP & LIME (unchanged)\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_made=full_mdl,\n",
    "            df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x,\n",
    "            size_y_value=size_y,\n",
    "            path_figure_info=path_figure,\n",
    "            path_table_info=path_table,\n",
    "            figure_name='TabNet_SHAP_standardized',\n",
    "            excel_name='TabNet_SHAP_values_standardized',\n",
    "            method_name='TabNet standardized',\n",
    "            task_type='classification',\n",
    "            model_type='TabNet'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=full_mdl,\n",
    "            df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(),\n",
    "            x_test_data=df[feature_names].to_numpy(),\n",
    "            t_test_data=df[label_column].to_numpy(),\n",
    "            size_x_value=size_x,\n",
    "            size_y_value=size_y,\n",
    "            path_figure_info=path_figure,\n",
    "            path_table_info=path_table,\n",
    "            figure_name='TabNet_standardized_lime_explanation_full',\n",
    "            excel_name='TabNet_standardized_lime_feature_contributions_full',\n",
    "            method_name='TabNet standardized',\n",
    "            task_type='classification',\n",
    "            random_state=random_state,\n",
    "            model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    # -----------------Prepare and return results-----------------\n",
    "    metrics_df = pd.DataFrame(\n",
    "        [[mean_auc, mean_acc, mean_prec, mean_rec, mean_f1]],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=['TabNet standardized']\n",
    "    )\n",
    "    return [metrics_df, roc_tabnet]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# With true early stopping mechanism by validation\n",
    "def TabNetOptunaKFoldN(\n",
    "     n_splits=k,\n",
    "     show_shap=False,\n",
    "     perform_lime=True,\n",
    "     max_epochs=100,\n",
    "     batch_size=32,\n",
    "     random_state=random_state,\n",
    "     n_trials=20,     # Number of Optuna trials\n",
    "     target='log_loss'     # 'auc' or 'log_loss'\n",
    " ):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import contextlib\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    from datetime import datetime\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score,\n",
    "        accuracy_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        f1_score,\n",
    "        roc_curve,\n",
    "        auc,\n",
    "        precision_recall_curve,\n",
    "        average_precision_score,\n",
    "        log_loss,\n",
    "        confusion_matrix\n",
    "    )\n",
    "    import torch\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import optuna\n",
    "    import warnings\n",
    "    # suppress absolutely all warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "    # ────── PERFORMING K-FOLD CV WITH OPTUNA TO FIND OUT BEST PARAMS ──────\n",
    "    print('')\n",
    "    print(f'■■■ TabNet (PyTorch) {n_splits}-fold Cross Validation with Optuna (Optimizing {target}, Trial count {n_trials})　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if gpu_available:\n",
    "        using_device = \"GPU \" + gpu_name\n",
    "    else:\n",
    "        using_device = \"CPU\"\n",
    "    print(f\"Using device: {using_device}\")\n",
    "    print('\\n----- Be patient. It will take several tens of minutes. -----\\n')\n",
    "    if using_device == \"CPU\":\n",
    "        print('Warning: Since CPU is selected, it will take many hours. GPU is highly recommended.\\n')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "\n",
    "    # — prepare outer folds\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    raw_splits = list(skf.split(df, df[label_column]))\n",
    "    cleaned_splits = []\n",
    "    for idx, (train_idx, test_idx) in enumerate(raw_splits):\n",
    "        if idx == 0 or (len(train_idx) >= 2 and len(test_idx) >= 2):\n",
    "            cleaned_splits.append((train_idx, test_idx))\n",
    "        else:\n",
    "            prev_tr, prev_te = cleaned_splits[-1]\n",
    "            merged_te = np.concatenate([prev_te, test_idx])\n",
    "            merged_tr = np.setdiff1d(np.arange(len(df)), merged_te)\n",
    "            cleaned_splits[-1] = (merged_tr, merged_te)\n",
    "    splits = cleaned_splits\n",
    "\n",
    "    trial_history = []\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_d': trial.suggest_int('n_d', 8, 64),\n",
    "            'n_a': trial.suggest_int('n_a', 8, 64),\n",
    "            'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "            'lambda_sparse': trial.suggest_loguniform('lambda_sparse', 1e-6, 1e-2),\n",
    "            'momentum': trial.suggest_float('momentum', 0.0, 0.9),\n",
    "            'clip_value': trial.suggest_float('clip_value', 1.0, 5.0),\n",
    "            'optimizer_fn': torch.optim.Adam,\n",
    "            'optimizer_params': {\n",
    "                'lr': trial.suggest_float('lr', 1e-3, 1e-1, log=True),\n",
    "                'weight_decay': trial.suggest_float('wd', 1e-6, 1e-2, log=True)\n",
    "            },\n",
    "            'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "            'scheduler_params': {\n",
    "                'step_size': trial.suggest_int('step_size', 10, 50),\n",
    "                'gamma': trial.suggest_float('scheduler_gamma', 0.5, 0.99)\n",
    "            },\n",
    "            'mask_type': 'entmax',\n",
    "            'device_name': device\n",
    "        }\n",
    "\n",
    "        aucs, loglosses = [], []\n",
    "        for tr_idx, te_idx in splits:\n",
    "            if len(tr_idx) < 2:\n",
    "                continue\n",
    "\n",
    "            X_tr = df.iloc[tr_idx][feature_names].values.astype(np.float32)\n",
    "            y_tr = df.iloc[tr_idx][label_column].values.astype(np.int64)\n",
    "            X_te = df.iloc[te_idx][feature_names].values.astype(np.float32)\n",
    "            y_te = df.iloc[te_idx][label_column].values.astype(np.int64)\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            X_tr = scaler.fit_transform(X_tr)\n",
    "            X_te = scaler.transform(X_te)\n",
    "\n",
    "            X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "                X_tr, y_tr, test_size=0.1, stratify=y_tr, random_state=random_state\n",
    "            )\n",
    "\n",
    "            bs_eff = min(batch_size, X_fit.shape[0])\n",
    "            if bs_eff < 2:\n",
    "                continue\n",
    "\n",
    "            mdl = TabNetClassifier(**params)\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                contextlib.redirect_stdout(f), \\\n",
    "                contextlib.redirect_stderr(f):\n",
    "                mdl.fit(\n",
    "                    X_fit, y_fit,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs,\n",
    "                    patience=10,\n",
    "                    batch_size=bs_eff,\n",
    "                    virtual_batch_size=bs_eff,\n",
    "                    num_workers=0,\n",
    "                    drop_last=True\n",
    "                )\n",
    "\n",
    "            prob = mdl.predict_proba(X_te)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_te, prob))\n",
    "            loglosses.append(log_loss(y_te, prob))\n",
    "\n",
    "        mean_auc_value = float(np.mean(aucs)) if aucs else 0.0\n",
    "        mean_logloss_value = float(np.mean(loglosses)) if loglosses else 0.0\n",
    "\n",
    "        rec = {\n",
    "            'trial': trial.number,\n",
    "            'auc': mean_auc_value,\n",
    "            'log_loss': mean_logloss_value,\n",
    "            'n_d': params['n_d'],\n",
    "            'n_a': params['n_a'],\n",
    "            'n_steps': params['n_steps'],\n",
    "            'gamma': params['gamma'],\n",
    "            'lambda_sparse': params['lambda_sparse'],\n",
    "            'momentum': params['momentum'],\n",
    "            'clip_value': params['clip_value'],\n",
    "            'lr': params['optimizer_params']['lr'],\n",
    "            'weight_decay': params['optimizer_params']['weight_decay'],\n",
    "            'step_size': params['scheduler_params']['step_size'],\n",
    "            'scheduler_gamma': params['scheduler_params']['gamma'],\n",
    "        }\n",
    "        trial_history.append(rec)\n",
    "        return (mean_auc_value if target=='auc' else -mean_logloss_value)\n",
    "\n",
    "    def print_callback(study, trial):\n",
    "        t = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S, %f\")[:-3]\n",
    "        best = study.best_trial\n",
    "        mname = 'AUC' if target=='auc' else '-LogLoss'\n",
    "        print(f\"[I {t}] Trial {trial.number} finished with {mname}={trial.value:.6f}; params={trial.params}. Best#{best.number} {mname}={best.value:.6f}.\")\n",
    "\n",
    "    overall_start = datetime.now()\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[print_callback])\n",
    "    df_history = pd.DataFrame(trial_history).sort_values('trial').reset_index(drop=True)\n",
    "    df_history.to_excel(os.path.join(path_table, 'tabnet_normalized_optuna_hyperparameters.xlsx'), index=False)\n",
    "    print(f\"Exported {len(df_history)} trials.\")\n",
    "\n",
    "    elapsed = datetime.now() - overall_start\n",
    "    hrs, rem = divmod(int(elapsed.total_seconds()), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    print(f\"\\n◆ Total optimization time: {hrs}h {mins}m {secs}s\\n\")\n",
    "    print(f\"◆ Best trial {'AUC' if target=='auc' else 'LogLoss'}: {study.best_value:.4f}\")\n",
    "    print(f\"◆ Best params: {study.best_params}\\n\")\n",
    "\n",
    "    tuned = study.best_params\n",
    "    tuned_params = {\n",
    "        'n_d': tuned['n_d'],'n_a': tuned['n_a'],'n_steps': tuned['n_steps'],\n",
    "        'gamma': tuned['gamma'],'lambda_sparse': tuned['lambda_sparse'],\n",
    "        'momentum': tuned['momentum'],'clip_value': tuned['clip_value'],\n",
    "        'optimizer_fn': torch.optim.Adam,\n",
    "        'optimizer_params': {'lr': tuned['lr'],'weight_decay': tuned['wd']},\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "        'scheduler_params': {'step_size': tuned['step_size'],'gamma': tuned['scheduler_gamma']},\n",
    "        'mask_type': 'entmax','device_name': device\n",
    "    }\n",
    "\n",
    "    class TorchTabNetWrapper:\n",
    "        def __init__(self, features, label, params):\n",
    "            self.feature_names = features\n",
    "            self.label_column  = label\n",
    "            self.tabnet_params = params\n",
    "            self.model = None\n",
    "            self.scaler = None\n",
    "\n",
    "        def train(self, train_df):\n",
    "            X = train_df[self.feature_names].values.astype(np.float32)\n",
    "            y = train_df[self.label_column].values.astype(np.int64)\n",
    "            self.scaler = MinMaxScaler().fit(X)\n",
    "            X = self.scaler.transform(X)\n",
    "            X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "                X, y, test_size=0.1, stratify=y, random_state=random_state\n",
    "            )\n",
    "            bs = min(batch_size, X_fit.shape[0])\n",
    "            self.model = TabNetClassifier(**self.tabnet_params)\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                contextlib.redirect_stdout(f), \\\n",
    "                contextlib.redirect_stderr(f):\n",
    "                self.model.fit(\n",
    "                    X_fit, y_fit, eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs, patience=10,\n",
    "                    batch_size=bs, virtual_batch_size=bs,\n",
    "                    num_workers=0, drop_last=True\n",
    "                )\n",
    "            return self\n",
    "\n",
    "        def predict(self, df_):\n",
    "            X = df_[self.feature_names].values.astype(np.float32)\n",
    "            X = self.scaler.transform(X)\n",
    "            return self.model.predict_proba(X)\n",
    "\n",
    "        def variable_importances(self):\n",
    "            imp = self.model.feature_importances_\n",
    "            return [(n, float(imp[i])) for i,n in enumerate(self.feature_names)]\n",
    "\n",
    "        def save_model(self, fname):\n",
    "            os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "            self.model.save_model(fname)\n",
    "\n",
    "\n",
    "    def compute_avg_metrics(\n",
    "        df, splits, feature_names, label_column,\n",
    "        tuned_params, batch_size, random_state,\n",
    "        max_epochs, device, threshold=0.5\n",
    "    ):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import (\n",
    "            confusion_matrix, roc_auc_score, accuracy_score,\n",
    "            precision_score, recall_score, f1_score,\n",
    "            roc_curve, auc, precision_recall_curve,\n",
    "            average_precision_score\n",
    "        )\n",
    "\n",
    "        mets = {\"auc\":[], \"acc\":[], \"prec\":[], \"rec\":[], \"f1\":[]}\n",
    "        tprs, aucs_list = [], []\n",
    "        pr_interp_list, ap_list = [], []\n",
    "\n",
    "        tn_rates, fp_rates, fn_rates, tp_rates = [],[],[],[]\n",
    "        mean_fpr    = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0,1,100)\n",
    "\n",
    "        for tr_idx, te_idx in splits:\n",
    "            tr_df = df.iloc[tr_idx].reset_index(drop=True)\n",
    "            te_df = df.iloc[te_idx].reset_index(drop=True)\n",
    "            mdl = TorchTabNetWrapper(feature_names, label_column, tuned_params).train(tr_df)\n",
    "\n",
    "            y_true = te_df[label_column].to_numpy()\n",
    "            probs  = mdl.predict(te_df)[:,1]\n",
    "            preds  = (probs>=threshold).astype(int)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true,preds).ravel()\n",
    "            total = tn+fp+fn+tp\n",
    "            tn_rates.append(tn/total); fp_rates.append(fp/total)\n",
    "            fn_rates.append(fn/total); tp_rates.append(tp/total)\n",
    "\n",
    "            mets[\"auc\"].append(roc_auc_score(y_true,probs))\n",
    "            mets[\"acc\"].append(accuracy_score(y_true,preds))\n",
    "            mets[\"prec\"].append(precision_score(y_true,preds,zero_division=0))\n",
    "            mets[\"rec\"].append(recall_score(y_true,preds))\n",
    "            mets[\"f1\"].append(f1_score(y_true,preds))\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_true,probs)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr); interp_tpr[0]=0.0\n",
    "            tprs.append(interp_tpr); aucs_list.append(auc(fpr,tpr))\n",
    "\n",
    "            prec, rec, _ = precision_recall_curve(y_true,probs)\n",
    "            # interpolate onto uniform recall grid\n",
    "            idx = np.argsort(rec)\n",
    "            pr_interp = np.interp(mean_recall, rec[idx], prec[idx])\n",
    "            pr_interp_list.append(pr_interp)\n",
    "            ap_list.append(average_precision_score(y_true,probs))\n",
    "\n",
    "        # confusion matrix\n",
    "        fold_tn = np.mean(tn_rates); fold_fp = np.mean(fp_rates)\n",
    "        fold_fn = np.mean(fn_rates); fold_tp = np.mean(tp_rates)\n",
    "        macro_cm = np.array([[fold_tn, fold_fn],[fold_fp, fold_tp]])*100\n",
    "        mean_spec = fold_tn/(fold_tn+fold_fp) if (fold_tn+fold_fp)>0 else 0.0\n",
    "\n",
    "        mean_auc   = np.mean(mets[\"auc\"])\n",
    "        mean_acc   = np.mean(mets[\"acc\"])\n",
    "        mean_prec  = np.mean(mets[\"prec\"])\n",
    "        mean_rec   = np.mean(mets[\"rec\"])\n",
    "        mean_f1    = np.mean(mets[\"f1\"])\n",
    "        mean_pr_auc= np.mean(ap_list)\n",
    "\n",
    "        display_fold_averages(\n",
    "            len(splits), df, macro_cm,\n",
    "            fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "            mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "            mean_spec, mean_auc, mean_auc, mean_pr_auc,\n",
    "            \"TabNet normalized with Optuna\"\n",
    "        )\n",
    "\n",
    "        # foldwise ROC\n",
    "        mean_tpr = np.mean(tprs,axis=0)\n",
    "        roc_label = \"TabNet normalized with Optuna\"\n",
    "        roc_arr = np.array([mean_fpr, mean_tpr, mean_auc, roc_label],dtype=object)\n",
    "\n",
    "        print('\\n□ Foldwise-averaged ROC curve:')\n",
    "        plt.figure()\n",
    "        plt.plot(mean_fpr,mean_tpr,label=f'Foldwise-averaged ROC (AUC={mean_auc:.4f})')\n",
    "        for tr in tprs: plt.plot(mean_fpr,tr,alpha=0.3)\n",
    "        plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "        plt.title('TabNet Normalized foldwise-averaged ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gca().set_aspect('equal',adjustable='box')\n",
    "        plt.savefig(os.path.join(path_figure,roc_label+'.png')); plt.show(); plt.close()\n",
    "\n",
    "        # foldwise PR\n",
    "        mean_pr = np.mean(pr_interp_list,axis=0)\n",
    "        pr_label=\"TabNet_normalized_pr_curve_kfCV_optuna\"\n",
    "        print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "        plt.figure()\n",
    "        plt.plot(mean_recall,mean_pr,label=f'Foldwise-averaged PRC (AUC={mean_pr_auc:.4f})')\n",
    "        for pr in pr_interp_list: plt.plot(mean_recall,pr,alpha=0.3)\n",
    "        plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "        plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "        plt.title('TabNet Normalized foldwise-averaged Precision-Recall Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gca().set_aspect('equal',adjustable='box')\n",
    "        plt.savefig(os.path.join(path_figure,pr_label+'.png')); plt.show(); plt.close()\n",
    "\n",
    "        res = np.array([mean_auc,mean_acc,mean_prec,mean_rec,mean_f1],dtype=object)\n",
    "        res2= pd.DataFrame([res],columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "                            index=['TabNet normalized with Optuna'])\n",
    "        return res2, roc_arr\n",
    "\n",
    "    print('')\n",
    "    fold_metrics_df, roc_arr = compute_avg_metrics(\n",
    "        df=df, splits=splits, feature_names=feature_names,\n",
    "        label_column=label_column, tuned_params=tuned_params,\n",
    "        batch_size=batch_size, random_state=random_state,\n",
    "        max_epochs=max_epochs, device=device, threshold=0.5\n",
    "    )\n",
    "\n",
    "    full_mdl = TorchTabNetWrapper(feature_names,label_column,tuned_params).train(df)\n",
    "    full_mdl.save_model(os.path.join(path_model,\"TabNet_normalized_full_model_optuna\"))\n",
    "\n",
    "    if show_shap:\n",
    "        ShapValueFunction(\n",
    "            model_made=full_mdl, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(), x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='TabNet_normalized_SHAP_optuna',\n",
    "            excel_name='TabNet_normalized_SHAP_values_optuna',\n",
    "            method_name='TabNet normalized with Optuna',\n",
    "            task_type='classification', model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    if perform_lime:\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=full_mdl, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(), x_test_data=df[feature_names].to_numpy(),\n",
    "            t_test_data=df[label_column].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='TabNet_normalized_lime_explanation_optuna',\n",
    "            excel_name='TabNet_normalized_lime_feature_contributions_optuna',\n",
    "            method_name='TabNet normalized with Optuna',\n",
    "            task_type='classification', random_state=random_state, model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    return [fold_metrics_df, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# With true early stopping mechanism by validation\n",
    "def TabNetOptunaKFoldS(\n",
    "     n_splits=k,\n",
    "     show_shap=False,\n",
    "     perform_lime=True,\n",
    "     max_epochs=100,\n",
    "     batch_size=32,\n",
    "     random_state=random_state,\n",
    "     n_trials=20,     # Number of Optuna trials\n",
    "     target='log_loss'     # 'auc' or 'log_loss'\n",
    " ):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import contextlib\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    from datetime import datetime\n",
    "    from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score,\n",
    "        accuracy_score,\n",
    "        precision_score,\n",
    "        recall_score,\n",
    "        f1_score,\n",
    "        roc_curve,\n",
    "        auc,\n",
    "        precision_recall_curve,\n",
    "        average_precision_score,\n",
    "        log_loss,\n",
    "        confusion_matrix\n",
    "    )\n",
    "    import torch\n",
    "    from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "    import optuna\n",
    "    import warnings\n",
    "    # suppress all warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "    # ────── PERFORMING K-FOLD CV WITH OPTUNA TO FIND BEST PARAMS ──────\n",
    "    print('')\n",
    "    print(f'■■■ TabNet (PyTorch) standardized {n_splits}-fold Cross Validation with Optuna (Optimizing {target}, Trial count {n_trials})　■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): '\n",
    "          + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if gpu_available:\n",
    "        using_device = \"GPU \" + gpu_name\n",
    "    else:\n",
    "        using_device = \"CPU\"\n",
    "    print(f\"Using device: {using_device}\")\n",
    "    print('\\n----- Be patient. It will take several tens of minutes. -----\\n')\n",
    "    if using_device == \"CPU\":\n",
    "        print('Warning: CPU selected, this may take many hours. GPU recommended.\\n')\n",
    "\n",
    "    feature_names = df.columns[:-1]\n",
    "    label_column  = df.columns[-1]\n",
    "\n",
    "    # prepare outer folds\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    raw_splits = list(skf.split(df, df[label_column]))\n",
    "    cleaned_splits = []\n",
    "    for idx, (train_idx, test_idx) in enumerate(raw_splits):\n",
    "        if idx == 0 or (len(train_idx) >= 2 and len(test_idx) >= 2):\n",
    "            cleaned_splits.append((train_idx, test_idx))\n",
    "        else:\n",
    "            prev_tr, prev_te = cleaned_splits[-1]\n",
    "            merged_te = np.concatenate([prev_te, test_idx])\n",
    "            merged_tr = np.setdiff1d(np.arange(len(df)), merged_te)\n",
    "            cleaned_splits[-1] = (merged_tr, merged_te)\n",
    "    splits = cleaned_splits\n",
    "\n",
    "    trial_history = []\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'n_d': trial.suggest_int('n_d', 8, 64),\n",
    "            'n_a': trial.suggest_int('n_a', 8, 64),\n",
    "            'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "            'lambda_sparse': trial.suggest_loguniform('lambda_sparse', 1e-6, 1e-2),\n",
    "            'momentum': trial.suggest_float('momentum', 0.0, 0.9),\n",
    "            'clip_value': trial.suggest_float('clip_value', 1.0, 5.0),\n",
    "            'optimizer_fn': torch.optim.Adam,\n",
    "            'optimizer_params': {\n",
    "                'lr': trial.suggest_float('lr', 1e-3, 1e-1, log=True),\n",
    "                'weight_decay': trial.suggest_float('wd', 1e-6, 1e-2, log=True)\n",
    "            },\n",
    "            'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "            'scheduler_params': {\n",
    "                'step_size': trial.suggest_int('step_size', 10, 50),\n",
    "                'gamma': trial.suggest_float('scheduler_gamma', 0.5, 0.99)\n",
    "            },\n",
    "            'mask_type': 'entmax',\n",
    "            'device_name': device\n",
    "        }\n",
    "\n",
    "        aucs, loglosses = [], []\n",
    "        for tr_idx, te_idx in splits:\n",
    "            if len(tr_idx) < 2:\n",
    "                continue\n",
    "\n",
    "            X_tr = df.iloc[tr_idx][feature_names].values.astype(np.float32)\n",
    "            y_tr = df.iloc[tr_idx][label_column].values.astype(np.int64)\n",
    "            X_te = df.iloc[te_idx][feature_names].values.astype(np.float32)\n",
    "            y_te = df.iloc[te_idx][label_column].values.astype(np.int64)\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_tr = scaler.fit_transform(X_tr)\n",
    "            X_te = scaler.transform(X_te)\n",
    "\n",
    "            X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "                X_tr, y_tr, test_size=0.1, stratify=y_tr, random_state=random_state\n",
    "            )\n",
    "\n",
    "            bs_eff = min(batch_size, X_fit.shape[0])\n",
    "            if bs_eff < 2:\n",
    "                continue\n",
    "\n",
    "            mdl = TabNetClassifier(**params)\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                 contextlib.redirect_stdout(f), \\\n",
    "                 contextlib.redirect_stderr(f):\n",
    "                mdl.fit(\n",
    "                    X_fit, y_fit,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs,\n",
    "                    patience=10,\n",
    "                    batch_size=bs_eff,\n",
    "                    virtual_batch_size=bs_eff,\n",
    "                    num_workers=0,\n",
    "                    drop_last=True\n",
    "                )\n",
    "\n",
    "            prob = mdl.predict_proba(X_te)[:, 1]\n",
    "            aucs.append(roc_auc_score(y_te, prob))\n",
    "            loglosses.append(log_loss(y_te, prob))\n",
    "\n",
    "        mean_auc_value = float(np.mean(aucs)) if aucs else 0.0\n",
    "        mean_logloss_value = float(np.mean(loglosses)) if loglosses else 0.0\n",
    "\n",
    "        trial_history.append({\n",
    "            'trial': trial.number,\n",
    "            'auc': mean_auc_value,\n",
    "            'log_loss': mean_logloss_value,\n",
    "            'n_d': params['n_d'],\n",
    "            'n_a': params['n_a'],\n",
    "            'n_steps': params['n_steps'],\n",
    "            'gamma': params['gamma'],\n",
    "            'lambda_sparse': params['lambda_sparse'],\n",
    "            'momentum': params['momentum'],\n",
    "            'clip_value': params['clip_value'],\n",
    "            'lr': params['optimizer_params']['lr'],\n",
    "            'weight_decay': params['optimizer_params']['weight_decay'],\n",
    "            'step_size': params['scheduler_params']['step_size'],\n",
    "            'scheduler_gamma': params['scheduler_params']['gamma'],\n",
    "        })\n",
    "\n",
    "        return mean_auc_value if target=='auc' else -mean_logloss_value\n",
    "\n",
    "    def print_callback(study, trial):\n",
    "        t = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S, %f\")[:-3]\n",
    "        best = study.best_trial\n",
    "        mname = 'AUC' if target=='auc' else '-LogLoss'\n",
    "        print(f\"[I {t}] Trial {trial.number} finished with {mname}={trial.value:.6f}; \"\n",
    "              f\"params={trial.params}. Best#{best.number} {mname}={best.value:.6f}.\")\n",
    "\n",
    "    overall_start = datetime.now()\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[print_callback])\n",
    "\n",
    "    df_history = pd.DataFrame(trial_history).sort_values('trial').reset_index(drop=True)\n",
    "    df_history.to_excel(os.path.join(path_table, 'tabnet_standard_optuna_hyperparameters.xlsx'), index=False)\n",
    "    print(f\"Exported {len(df_history)} trials to tabnet_standard_optuna_hyperparameters.xlsx\")\n",
    "\n",
    "    elapsed = datetime.now() - overall_start\n",
    "    hrs, rem = divmod(int(elapsed.total_seconds()), 3600)\n",
    "    mins, secs = divmod(rem, 60)\n",
    "    print(f\"\\n◆ Total optimization time: {hrs}h {mins}m {secs}s\\n\")\n",
    "    print(f\"◆ Best trial {'AUC' if target=='auc' else 'LogLoss'}: {study.best_value:.4f}\")\n",
    "    print(f\"◆ Best params: {study.best_params}\\n\")\n",
    "\n",
    "    tuned = study.best_params\n",
    "    tuned_params = {\n",
    "        'n_d': tuned['n_d'],\n",
    "        'n_a': tuned['n_a'],\n",
    "        'n_steps': tuned['n_steps'],\n",
    "        'gamma': tuned['gamma'],\n",
    "        'lambda_sparse': tuned['lambda_sparse'],\n",
    "        'momentum': tuned['momentum'],\n",
    "        'clip_value': tuned['clip_value'],\n",
    "        'optimizer_fn': torch.optim.Adam,\n",
    "        'optimizer_params': {'lr': tuned['lr'], 'weight_decay': tuned['wd']},\n",
    "        'scheduler_fn': torch.optim.lr_scheduler.StepLR,\n",
    "        'scheduler_params': {'step_size': tuned['step_size'], 'gamma': tuned['scheduler_gamma']},\n",
    "        'mask_type': 'entmax',\n",
    "        'device_name': device\n",
    "    }\n",
    "\n",
    "    class TorchTabNetWrapper:\n",
    "        def __init__(self, features, label, params):\n",
    "            self.feature_names = features\n",
    "            self.label_column  = label\n",
    "            self.tabnet_params = params\n",
    "            self.model = None\n",
    "            self.scaler = None\n",
    "\n",
    "        def train(self, train_df):\n",
    "            X = train_df[self.feature_names].values.astype(np.float32)\n",
    "            y = train_df[self.label_column].values.astype(np.int64)\n",
    "\n",
    "            self.scaler = StandardScaler().fit(X)\n",
    "            X = self.scaler.transform(X)\n",
    "\n",
    "            X_fit, X_val, y_fit, y_val = train_test_split(\n",
    "                X, y, test_size=0.1, stratify=y, random_state=random_state\n",
    "            )\n",
    "\n",
    "            bs = min(batch_size, X_fit.shape[0])\n",
    "            self.model = TabNetClassifier(**self.tabnet_params)\n",
    "            with open(os.devnull, \"w\") as f, \\\n",
    "                 contextlib.redirect_stdout(f), \\\n",
    "                 contextlib.redirect_stderr(f):\n",
    "                self.model.fit(\n",
    "                    X_fit, y_fit,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    max_epochs=max_epochs,\n",
    "                    patience=10,\n",
    "                    batch_size=bs,\n",
    "                    virtual_batch_size=bs,\n",
    "                    num_workers=0,\n",
    "                    drop_last=True\n",
    "                )\n",
    "            return self\n",
    "\n",
    "        def predict(self, df_):\n",
    "            X = df_[self.feature_names].values.astype(np.float32)\n",
    "            X = self.scaler.transform(X)\n",
    "            return self.model.predict_proba(X)\n",
    "\n",
    "        def variable_importances(self):\n",
    "            imp = self.model.feature_importances_\n",
    "            return [(n, float(imp[i])) for i,n in enumerate(self.feature_names)]\n",
    "\n",
    "        def save_model(self, fname):\n",
    "            os.makedirs(os.path.dirname(fname), exist_ok=True)\n",
    "            self.model.save_model(fname)\n",
    "\n",
    "\n",
    "    def compute_avg_metrics(\n",
    "        df, splits, feature_names, label_column,\n",
    "        tuned_params, batch_size, random_state,\n",
    "        max_epochs, device, threshold=0.5\n",
    "    ):\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import (\n",
    "            confusion_matrix, roc_auc_score, accuracy_score,\n",
    "            precision_score, recall_score, f1_score,\n",
    "            roc_curve, auc, precision_recall_curve,\n",
    "            average_precision_score\n",
    "        )\n",
    "\n",
    "        mets = {\"auc\":[], \"acc\":[], \"prec\":[], \"rec\":[], \"f1\":[]}\n",
    "        tprs, aucs_list = [], []\n",
    "        pr_interp_list, ap_list = [], []\n",
    "\n",
    "        tn_rates, fp_rates, fn_rates, tp_rates = [],[],[],[]\n",
    "        mean_fpr    = np.linspace(0,1,100)\n",
    "        mean_recall = np.linspace(0,1,100)\n",
    "\n",
    "        for tr_idx, te_idx in splits:\n",
    "            tr_df = df.iloc[tr_idx].reset_index(drop=True)\n",
    "            te_df = df.iloc[te_idx].reset_index(drop=True)\n",
    "            mdl = TorchTabNetWrapper(feature_names, label_column, tuned_params).train(tr_df)\n",
    "\n",
    "            y_true = te_df[label_column].to_numpy()\n",
    "            probs  = mdl.predict(te_df)[:,1]\n",
    "            preds  = (probs>=threshold).astype(int)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true,preds).ravel()\n",
    "            total = tn+fp+fn+tp\n",
    "            tn_rates.append(tn/total); fp_rates.append(fp/total)\n",
    "            fn_rates.append(fn/total); tp_rates.append(tp/total)\n",
    "\n",
    "            mets[\"auc\"].append(roc_auc_score(y_true,probs))\n",
    "            mets[\"acc\"].append(accuracy_score(y_true,preds))\n",
    "            mets[\"prec\"].append(precision_score(y_true,preds,zero_division=0))\n",
    "            mets[\"rec\"].append(recall_score(y_true,preds))\n",
    "            mets[\"f1\"].append(f1_score(y_true,preds))\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_true,probs)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs_list.append(auc(fpr,tpr))\n",
    "\n",
    "            prec, rec, _ = precision_recall_curve(y_true,probs)\n",
    "            idx = np.argsort(rec)\n",
    "            pr_interp = np.interp(mean_recall, rec[idx], prec[idx])\n",
    "            pr_interp_list.append(pr_interp)\n",
    "            ap_list.append(average_precision_score(y_true,probs))\n",
    "\n",
    "        fold_tn = np.mean(tn_rates)\n",
    "        fold_fp = np.mean(fp_rates)\n",
    "        fold_fn = np.mean(fn_rates)\n",
    "        fold_tp = np.mean(tp_rates)\n",
    "        macro_cm = np.array([[fold_tn, fold_fn],[fold_fp, fold_tp]])*100\n",
    "        mean_spec = fold_tn/(fold_tn+fold_fp) if (fold_tn+fold_fp)>0 else 0.0\n",
    "\n",
    "        mean_auc   = np.mean(mets[\"auc\"])\n",
    "        mean_acc   = np.mean(mets[\"acc\"])\n",
    "        mean_prec  = np.mean(mets[\"prec\"])\n",
    "        mean_rec   = np.mean(mets[\"rec\"])\n",
    "        mean_f1    = np.mean(mets[\"f1\"])\n",
    "        mean_pr_auc= np.mean(ap_list)\n",
    "\n",
    "        display_fold_averages(\n",
    "            len(splits), df, macro_cm,\n",
    "            fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "            mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "            mean_spec, mean_auc, mean_auc, mean_pr_auc,\n",
    "            \"TabNet standardized with Optuna\"\n",
    "        )\n",
    "\n",
    "        # ROC\n",
    "        mean_tpr = np.mean(tprs,axis=0)\n",
    "        roc_label = \"TabNet standardized with Optuna\"\n",
    "        roc_arr = np.array([mean_fpr, mean_tpr, mean_auc, roc_label],dtype=object)\n",
    "\n",
    "        print('\\n□ Foldwise-averaged ROC curve:')\n",
    "        plt.figure()\n",
    "        plt.plot(mean_fpr,mean_tpr,label=f'Foldwise-averaged ROC (AUC={mean_auc:.4f})')\n",
    "        for tr in tprs: plt.plot(mean_fpr,tr,alpha=0.3)\n",
    "        plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "        plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "        plt.title('TabNet Standardized foldwise-averaged ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gca().set_aspect('equal',adjustable='box')\n",
    "        plt.savefig(os.path.join(path_figure,roc_label+'.png')); plt.show(); plt.close()\n",
    "\n",
    "        # PR\n",
    "        mean_pr = np.mean(pr_interp_list,axis=0)\n",
    "        pr_label=\"TabNet_standardized_pr_curve_kfCV_optuna\"\n",
    "        print('\\n□ Foldwise-averaged Precision-Recall curve:')\n",
    "        plt.figure()\n",
    "        plt.plot(mean_recall,mean_pr,label=f'Foldwise-averaged PRC (AUC={mean_pr_auc:.4f})')\n",
    "        for pr in pr_interp_list: plt.plot(mean_recall,pr,alpha=0.3)\n",
    "        plt.plot([0,1],[0,1],'--',alpha=0.5)\n",
    "        plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "        plt.title('TabNet Standardized foldwise-averaged Precision-Recall Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gca().set_aspect('equal',adjustable='box')\n",
    "        plt.savefig(os.path.join(path_figure,pr_label+'.png')); plt.show(); plt.close()\n",
    "\n",
    "        res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1],dtype=object)\n",
    "        res2 = pd.DataFrame([res],columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "                            index=['TabNet standardized with Optuna'])\n",
    "        return res2, roc_arr\n",
    "\n",
    "    print('')\n",
    "    fold_metrics_df, roc_arr = compute_avg_metrics(\n",
    "        df=df, splits=splits, feature_names=feature_names,\n",
    "        label_column=label_column, tuned_params=tuned_params,\n",
    "        batch_size=batch_size, random_state=random_state,\n",
    "        max_epochs=max_epochs, device=device, threshold=0.5\n",
    "    )\n",
    "\n",
    "    full_mdl = TorchTabNetWrapper(feature_names,label_column,tuned_params).train(df)\n",
    "    full_mdl.save_model(os.path.join(path_model,\"TabNet_standardized_full_model_optuna\"))\n",
    "\n",
    "    if show_shap:\n",
    "        ShapValueFunction(\n",
    "            model_made=full_mdl, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(), x_test_data=df[feature_names].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='TabNet_standardized_SHAP_optuna',\n",
    "            excel_name='TabNet_standardized_SHAP_values_optuna',\n",
    "            method_name='TabNet standardized with Optuna',\n",
    "            task_type='classification', model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    if perform_lime:\n",
    "        LimeContributionValueFunction(\n",
    "            model_made=full_mdl, df_data=df,\n",
    "            x_train_data=df[feature_names].to_numpy(), x_test_data=df[feature_names].to_numpy(),\n",
    "            t_test_data=df[label_column].to_numpy(),\n",
    "            size_x_value=size_x, size_y_value=size_y,\n",
    "            path_figure_info=path_figure, path_table_info=path_table,\n",
    "            figure_name='TabNet_standardized_lime_explanation_optuna',\n",
    "            excel_name='TabNet_standardized_lime_feature_contributions_optuna',\n",
    "            method_name='TabNet standardized with Optuna',\n",
    "            task_type='classification', random_state=random_state, model_type='TabNet'\n",
    "        )\n",
    "\n",
    "    return [fold_metrics_df, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# MLP with selectable scaler\n",
    "def MLPKFold(k=k, scaler='norm', n1=128, n2=32, max_iter=500, perform_lime=True):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score, recall_score,\n",
    "        f1_score, confusion_matrix, roc_curve, precision_recall_curve,\n",
    "        average_precision_score\n",
    "    )\n",
    "\n",
    "    if scaler == 'norm':\n",
    "        scaling_method = \"Normalization\"\n",
    "        scale = 'normalized'\n",
    "    elif scaler == 'stand':\n",
    "        scaling_method = \"Standardization\"\n",
    "        scale = 'standardized'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scaler: {scaler}. Either 'norm' or 'stand' is available.\")\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ Multi-Layer Perceptron kfCV with {scaling_method} ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Choose scaler based on parameter\n",
    "    def _make_scaler():\n",
    "        if scaler == 'norm':\n",
    "            return MinMaxScaler()\n",
    "        elif scaler == 'stand':\n",
    "            return StandardScaler()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown scaler: {scaler}\")\n",
    "\n",
    "    # Use StratifiedKFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For ROC & PR curves per fold\n",
    "    fprs, tprs = [], []\n",
    "    precisions_list, recalls_list = [], []\n",
    "    # For normalized confusion rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    loss_curves = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        scaler_obj = _make_scaler()\n",
    "        x_train_scaled = scaler_obj.fit_transform(X_train)\n",
    "        x_test_scaled  = scaler_obj.transform(X_test)\n",
    "\n",
    "        model = MLPClassifier(\n",
    "            hidden_layer_sizes=(n1, n2),\n",
    "            random_state=random_state,\n",
    "            max_iter=max_iter\n",
    "        )\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        loss_curves.append(model.loss_curve_)\n",
    "\n",
    "        y_pred      = model.predict(x_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(x_test_scaled)[:, 1]\n",
    "\n",
    "        # Per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score(y_test, y_pred)\n",
    "        prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score(y_test, y_pred)\n",
    "        f1_fold   = f1_score(y_test, y_pred)\n",
    "        ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp)\n",
    "\n",
    "        aucs.append(auc_fold)\n",
    "        accs.append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s.append(f1_fold)\n",
    "        aps.append(ap_fold)\n",
    "        specs.append(spec_fold)\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions_list.append(prec_vals)\n",
    "        recalls_list.append(rec_vals)\n",
    "\n",
    "    # Compute foldwise-averaged metrics\n",
    "    mean_auc     = np.mean(aucs)\n",
    "    mean_acc     = np.mean(accs)\n",
    "    mean_prec    = np.mean(precs)\n",
    "    mean_rec     = np.mean(recs)\n",
    "    mean_f1      = np.mean(f1s)\n",
    "    mean_spec    = np.mean(specs)\n",
    "    mean_pr_auc  = np.mean(aps)\n",
    "    mean_cind    = mean_auc\n",
    "\n",
    "    # Foldwise-averaged confusion matrix rates\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged binary-classification table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"Multi-Layer Perceptron \" + scale\n",
    "    )\n",
    "\n",
    "    # Plot loss curves\n",
    "    print('')\n",
    "    print('◇ Training completed - Loss curves below.')\n",
    "    max_length = max(len(curve) for curve in loss_curves)\n",
    "    extended = [curve + [curve[-1]] * (max_length - len(curve))\n",
    "                for curve in loss_curves]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    for curve in extended:\n",
    "        plt.plot(curve, color='blue', alpha=0.2)\n",
    "    plt.plot(np.mean(extended, axis=0),\n",
    "             color='red', label='Average Loss Curve')\n",
    "    plt.title('Loss Curves per Fold and Average for MLP ' + scale)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path_figure, 'MLP_loss_curve_kfCV_' + scale + '.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "                      for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_arr = np.array([mean_fpr,\n",
    "                        mean_tpr_curve,\n",
    "                        mean_auc,\n",
    "                        'Multi-Layer Perceptron' + scale],\n",
    "                       dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve,\n",
    "             label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1],\n",
    "             linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'MLP_roc_curve_kfCV_' + scale + '.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls_list)):\n",
    "        idx_sort = np.argsort(recalls_list[i])\n",
    "        recall_sorted    = recalls_list[i][idx_sort]\n",
    "        precision_sorted = precisions_list[i][idx_sort]\n",
    "        precisions_interp.append(\n",
    "            np.interp(mean_recall, recall_sorted, precision_sorted)\n",
    "        )\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve,\n",
    "             label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls_list)):\n",
    "        plt.plot(recalls_list[i], precisions_list[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'MLP_prerec_curve_kfCV_' + scale + '.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    scaler_obj = _make_scaler()\n",
    "    X_scaled = scaler_obj.fit_transform(X)\n",
    "    model_full = MLPClassifier(\n",
    "        hidden_layer_sizes=(n1, n2),\n",
    "        random_state=random_state,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Save the full model\n",
    "    model_filename = os.path.join(path_model, 'MLP_full_' + scale + '.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out training for LIME\n",
    "    scaler_obj = _make_scaler()\n",
    "    x_train_scaled = scaler_obj.fit_transform(x_train)\n",
    "    x_test_scaled  = scaler_obj.transform(x_test)\n",
    "    model_holdout = MLPClassifier(\n",
    "        hidden_layer_sizes=(n1, n2),\n",
    "        random_state=random_state,\n",
    "        max_iter=max_iter\n",
    "    )\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    print('')\n",
    "    print('・　Feature importance cannot be extracted from the MLP ' + scale + ' model.')\n",
    "    print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df,\n",
    "            x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y,\n",
    "            path_figure, path_table,\n",
    "            'MLP_lime_explanation_holdout_' + scale,\n",
    "            'MLP_lime_feature_contributions_holdout_' + scale,\n",
    "            'MLP ' + scale, task_type='classification',\n",
    "            random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Prepare and return results\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1],\n",
    "                   dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['MLP ' + scale]\n",
    "    )\n",
    "\n",
    "    return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gradient Boosting Machine kfCV\n",
    "def GradientBoostingKFold(k=k, show_shap=True, perform_lime=True):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Gradient Boosting Machine kfCV ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For ROC & PR curves per fold\n",
    "    fprs, tprs = [], []\n",
    "    precisions_list, recalls_list = [], []\n",
    "    # For normalized confusion rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    # For loss (training deviance) curves per fold\n",
    "    loss_curves = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = GradientBoostingClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # collect training deviance per iteration\n",
    "        loss_curves.append(list(model.train_score_))\n",
    "\n",
    "        # Predict classes and probabilities\n",
    "        y_pred      = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score(y_test, y_pred)\n",
    "        prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score(y_test, y_pred)\n",
    "        f1_fold   = f1_score(y_test, y_pred)\n",
    "        ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "        aucs.append(auc_fold)\n",
    "        accs.append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s.append(f1_fold)\n",
    "        aps.append(ap_fold)\n",
    "        specs.append(spec_fold)\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions_list.append(prec_vals)\n",
    "        recalls_list.append(rec_vals)\n",
    "\n",
    "    # Compute foldwise-averaged metrics\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_pr_auc = np.mean(aps)\n",
    "    mean_cind   = mean_auc\n",
    "\n",
    "    # Foldwise-averaged confusion matrix rates\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged binary-classification table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"Gradient Boosting Machine\"\n",
    "    )\n",
    "\n",
    "    # Plot loss curves\n",
    "    print('')\n",
    "    print('◇ Training completed - Loss curves below.')\n",
    "    max_length = max(len(curve) for curve in loss_curves)\n",
    "    extended = [curve + [curve[-1]] * (max_length - len(curve))\n",
    "                for curve in loss_curves]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    for curve in extended:\n",
    "        plt.plot(curve, color='blue', alpha=0.2)\n",
    "    plt.plot(np.mean(extended, axis=0),\n",
    "             color='red', label='Average Deviance Curve')\n",
    "    plt.title('Deviance Curves per Fold and Average for Gradient Boosting')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Deviance')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path_figure, 'GradientBoosting_loss_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "                      for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_arr = np.array([mean_fpr,\n",
    "                        mean_tpr_curve,\n",
    "                        mean_auc,\n",
    "                        'Gradient Boosting Machine'],\n",
    "                       dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve,\n",
    "             label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1],\n",
    "             linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'GradientBoosting_roc_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls_list)):\n",
    "        idx_sort = np.argsort(recalls_list[i])\n",
    "        recall_sorted    = recalls_list[i][idx_sort]\n",
    "        precision_sorted = precisions_list[i][idx_sort]\n",
    "        precisions_interp.append(\n",
    "            np.interp(mean_recall, recall_sorted, precision_sorted)\n",
    "        )\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve,\n",
    "             label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls_list)):\n",
    "        plt.plot(recalls_list[i], precisions_list[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'GradientBoosting_prerec_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = GradientBoostingClassifier(random_state=random_state)\n",
    "    model_full.fit(X, y)\n",
    "\n",
    "    # Save the full model\n",
    "    model_filename = os.path.join(path_model, 'GradientBoosting_kfCV.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out model for SHAP and LIME\n",
    "    model_holdout = GradientBoostingClassifier(random_state=random_state)\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap == True:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'GradientBoosting_shap_values_holdout',\n",
    "            'GradientBoosting_shap_values_holdout',\n",
    "            'Gradient Boosting Machine', task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'GradientBoosting_lime_explanation_holdout',\n",
    "            'GradientBoosting_lime_feature_contributions_holdout',\n",
    "            'Gradient Boosting Machine', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['Gradient Boosting Machine']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AdaBoost Machine kfCV\n",
    "def AdaBoostKFold(k=k, show_shap=True, perform_lime=True):\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "\n",
    "    print('')\n",
    "    print('■■■ AdaBoost Machine kfCV ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For ROC & PR curves per fold\n",
    "    fprs, tprs = [], []\n",
    "    precisions_list, recalls_list = [], []\n",
    "    # For normalized confusion rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    # For staged-error curves per fold\n",
    "    error_curves = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = AdaBoostClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # collect training error per iteration\n",
    "        error_curves.append([1 - score for score in model.staged_score(X_train, y_train)])\n",
    "\n",
    "        # Predict classes and probabilities\n",
    "        y_pred      = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score(y_test, y_pred)\n",
    "        prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score(y_test, y_pred)\n",
    "        f1_fold   = f1_score(y_test, y_pred)\n",
    "        ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "        aucs.append(auc_fold)\n",
    "        accs.append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s.append(f1_fold)\n",
    "        aps.append(ap_fold)\n",
    "        specs.append(spec_fold)\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions_list.append(prec_vals)\n",
    "        recalls_list.append(rec_vals)\n",
    "\n",
    "    # Compute foldwise-averaged metrics\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_pr_auc = np.mean(aps)\n",
    "    mean_cind   = mean_auc\n",
    "\n",
    "    # Foldwise-averaged confusion matrix rates\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged binary-classification table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"AdaBoost\"\n",
    "    )\n",
    "\n",
    "    # Plot error curves\n",
    "    print('')\n",
    "    print('◇ Training completed - Error curves below.')\n",
    "    max_length = max(len(curve) for curve in error_curves)\n",
    "    extended = [curve + [curve[-1]] * (max_length - len(curve))\n",
    "                for curve in error_curves]\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    for curve in extended:\n",
    "        plt.plot(curve, color='blue', alpha=0.2)\n",
    "    plt.plot(np.mean(extended, axis=0),\n",
    "             color='red', label='Average Training Error Curve')\n",
    "    plt.title('Training Error per Iteration - AdaBoost')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Error')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(path_figure, 'AdaBoost_error_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "                      for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_arr = np.array([mean_fpr,\n",
    "                        mean_tpr_curve,\n",
    "                        mean_auc,\n",
    "                        'AdaBoost'],\n",
    "                       dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve,\n",
    "             label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1],\n",
    "             linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'AdaBoost_roc_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls_list)):\n",
    "        idx_sort = np.argsort(recalls_list[i])\n",
    "        recall_sorted    = recalls_list[i][idx_sort]\n",
    "        precision_sorted = precisions_list[i][idx_sort]\n",
    "        precisions_interp.append(\n",
    "            np.interp(mean_recall, recall_sorted, precision_sorted)\n",
    "        )\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve,\n",
    "             label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls_list)):\n",
    "        plt.plot(recalls_list[i], precisions_list[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, 'AdaBoost_prerec_curve_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = AdaBoostClassifier(random_state=random_state)\n",
    "    model_full.fit(X, y)\n",
    "\n",
    "    # Save the full model\n",
    "    model_filename = os.path.join(path_model, 'AdaBoost_kfCV.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out model for SHAP and LIME\n",
    "    model_holdout = AdaBoostClassifier(random_state=random_state)\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'AdaBoost_shap_values_holdout',\n",
    "            'AdaBoost_shap_values_holdout',\n",
    "            'AdaBoost', task_type='classification', model_type='tree'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'AdaBoost_lime_explanation_holdout',\n",
    "            'AdaBoost_lime_feature_contributions_holdout',\n",
    "            'AdaBoost', task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=['AdaBoost']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "# Linear Discriminant Analysis kfCV with selectable scaler\n",
    "def LinearDiscriminantAnalysisKFold(k=k, scaler='norm', show_shap=True, perform_lime=True):\n",
    "    # 'norm' = MinMaxScaler, 'stand' = StandardScaler\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "\n",
    "    # Choose scaler based on parameter by the value of scaler, either 'norm' or 'stand'\n",
    "    if scaler == 'norm':\n",
    "        Scaler = MinMaxScaler\n",
    "        scale_name = 'normalized'\n",
    "    elif scaler == 'stand':\n",
    "        Scaler = StandardScaler\n",
    "        scale_name = 'standardized'\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown scale: {scaler}. Use 'norm' or 'stand'.\")\n",
    "\n",
    "    print('')\n",
    "    print(f'■■■ Linear Discriminant Analysis kfCV ({scale_name}) ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Use StratifiedKFold for balanced splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Lists for foldwise metrics\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    # For ROC & PR curves per fold\n",
    "    fprs, tprs = [], []\n",
    "    precisions_list, recalls_list = [], []\n",
    "    # For normalized confusion rates\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Scale features\n",
    "        scaler_method = Scaler()\n",
    "        X_train_scaled = scaler_method.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler_method.transform(X_test)\n",
    "\n",
    "        # Initialize the Linear Discriminant Analysis model\n",
    "        model = LinearDiscriminantAnalysis()\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict classes and probabilities\n",
    "        y_pred      = model.predict(X_test_scaled)\n",
    "        y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # Per-fold confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Per-fold metrics\n",
    "        auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "        acc_fold  = accuracy_score(y_test, y_pred)\n",
    "        prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec_fold  = recall_score(y_test, y_pred)\n",
    "        f1_fold   = f1_score(y_test, y_pred)\n",
    "        ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "        spec_fold = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "        aucs.append(auc_fold)\n",
    "        accs.append(acc_fold)\n",
    "        precs.append(prec_fold)\n",
    "        recs.append(rec_fold)\n",
    "        f1s.append(f1_fold)\n",
    "        aps.append(ap_fold)\n",
    "        specs.append(spec_fold)\n",
    "\n",
    "        # ROC curve data\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "\n",
    "        # Precision-Recall curve data\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions_list.append(prec_vals)\n",
    "        recalls_list.append(rec_vals)\n",
    "\n",
    "    # Compute foldwise-averaged metrics\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_pr_auc = np.mean(aps)\n",
    "    mean_cind   = mean_auc\n",
    "\n",
    "    # Foldwise-averaged confusion matrix rates\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    # Display foldwise-averaged binary-classification table\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        f\"Linear Discriminant Analysis ({scale_name})\"\n",
    "    )\n",
    "\n",
    "    # -----------------Plot foldwise-averaged ROC curve-----------------\n",
    "    mean_fpr       = np.linspace(0, 1, 100)\n",
    "    tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "                      for i in range(len(fprs))]\n",
    "    mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "    roc_arr = np.array([mean_fpr,\n",
    "                        mean_tpr_curve,\n",
    "                        mean_auc,\n",
    "                        f'Linear Discriminant Analysis {scale_name}'],\n",
    "                       dtype=object)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr_curve,\n",
    "             label=f'Foldwise-averaged ROC (AUC = {mean_auc:.4f})')\n",
    "    for i in range(len(fprs)):\n",
    "        plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1],\n",
    "             linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, f'LDA_roc_curve_kfCV_{scale_name}.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # -----------------Plot foldwise-averaged Precision-Recall curve-----------------\n",
    "    mean_recall = np.linspace(0, 1, 100)\n",
    "    precisions_interp = []\n",
    "    for i in range(len(recalls_list)):\n",
    "        idx_sort = np.argsort(recalls_list[i])\n",
    "        recall_sorted    = recalls_list[i][idx_sort]\n",
    "        precision_sorted = precisions_list[i][idx_sort]\n",
    "        precisions_interp.append(\n",
    "            np.interp(mean_recall, recall_sorted, precision_sorted)\n",
    "        )\n",
    "    mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise-averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_recall, mean_pr_curve,\n",
    "             label=f'Foldwise-averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "    for i in range(len(recalls_list)):\n",
    "        plt.plot(recalls_list[i], precisions_list[i], alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve - Foldwise-Averaged over {k} Folds')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, f'LDA_pr_curve_kfCV_{scale_name}.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    scaler_method = Scaler()\n",
    "    X_scaled = scaler_method.fit_transform(X)\n",
    "    model_full = LinearDiscriminantAnalysis()\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Save the full model\n",
    "    model_filename = os.path.join(path_model, f'LDA_kfCV_{scale_name}.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Hold-out model for SHAP and LIME\n",
    "    scaler_method = Scaler()\n",
    "    x_train_scaled = scaler_method.fit_transform(x_train)\n",
    "    x_test_scaled  = scaler_method.transform(x_test)\n",
    "    model_holdout = LinearDiscriminantAnalysis()\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'LDA_shap_values_holdout',\n",
    "            'LDA_shap_values_holdout',\n",
    "            'Linear Discriminant Analysis' + scale_name, task_type='classification', model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(\n",
    "            model_holdout, df, x_train_scaled, x_test_scaled, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'LDA_lime_explanation_holdout',\n",
    "            'LDA_lime_feature_contributions_holdout',\n",
    "            'Linear Discriminant Analysis' + scale_name, task_type='classification', random_state=random_state\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "        index=[f'Linear Discriminant Analysis {scale_name}']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GaussianProcessKFold(\n",
    "    k=k,\n",
    "    show_shap=True,\n",
    "    perform_lime=True,\n",
    "    scaler='norm'   # 'norm' = MinMaxScaler, 'stand' = StandardScaler, else no scaling\n",
    "):\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "    from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import (\n",
    "        roc_auc_score, accuracy_score, precision_score,\n",
    "        recall_score, f1_score, confusion_matrix,\n",
    "        roc_curve, precision_recall_curve, average_precision_score\n",
    "    )\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pickle\n",
    "\n",
    "    print('')\n",
    "    print('■■■ Gaussian Process Classifier kfCV ■■■')\n",
    "    print('')\n",
    "    print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "          str(round(100 * (np.count_nonzero(y > 0) / len(y)), 5)) + ' %)')\n",
    "    print('')\n",
    "\n",
    "    # Build a Pipeline: scaler + GP\n",
    "    if scaler == 'norm':\n",
    "        scaler_step = MinMaxScaler()\n",
    "        scaler_name = 'normalized'\n",
    "    elif scaler == 'stand':\n",
    "        scaler_step = StandardScaler()\n",
    "        scaler_name = 'standardized'\n",
    "    else:\n",
    "        scaler_step = 'passthrough'\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', scaler_step),\n",
    "        ('gp', GaussianProcessClassifier())\n",
    "    ])\n",
    "\n",
    "    # Stratified k-fold\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Storage for metrics and curve data\n",
    "    aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "    fprs, tprs = [], []\n",
    "    precisions_list, recalls_list = [], []\n",
    "    tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fit pipeline (scale + GP)\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred      = pipeline.predict(X_test)\n",
    "        y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Confusion rates\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        total = tn + fp + fn + tp\n",
    "        tn_rates.append(tn / total)\n",
    "        fp_rates.append(fp / total)\n",
    "        fn_rates.append(fn / total)\n",
    "        tp_rates.append(tp / total)\n",
    "\n",
    "        # Metrics\n",
    "        aucs.append(roc_auc_score(y_test, y_pred_prob))\n",
    "        accs.append(accuracy_score(y_test, y_pred))\n",
    "        precs.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recs.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        aps.append(average_precision_score(y_test, y_pred_prob))\n",
    "        specs.append(tn / (tn + fp) if (tn + fp) > 0 else 0.0)\n",
    "\n",
    "        # ROC curve points\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "        fprs.append(fpr); tprs.append(tpr)\n",
    "\n",
    "        # PR curve points\n",
    "        prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "        precisions_list.append(prec_vals)\n",
    "        recalls_list.append(rec_vals)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    mean_auc    = np.mean(aucs)\n",
    "    mean_acc    = np.mean(accs)\n",
    "    mean_prec   = np.mean(precs)\n",
    "    mean_rec    = np.mean(recs)\n",
    "    mean_f1     = np.mean(f1s)\n",
    "    mean_spec   = np.mean(specs)\n",
    "    mean_pr_auc = np.mean(aps)\n",
    "    mean_cind   = mean_auc\n",
    "\n",
    "    # Aggregate confusion matrix\n",
    "    fold_tn = np.mean(tn_rates)\n",
    "    fold_fp = np.mean(fp_rates)\n",
    "    fold_fn = np.mean(fn_rates)\n",
    "    fold_tp = np.mean(tp_rates)\n",
    "    fold_cm = np.array([[fold_tn, fold_fn],\n",
    "                        [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "    display_fold_averages(\n",
    "        k, df, fold_cm,\n",
    "        fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "        mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "        mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "        \"Gaussian Process \" + scaler_name\n",
    "    )\n",
    "\n",
    "    # Prepare averaged ROC curve\n",
    "    mean_fpr    = np.linspace(0, 1, 100)\n",
    "    tprs_interp = [np.interp(mean_fpr, fprs[i], tprs[i]) for i in range(len(fprs))]\n",
    "    mean_tpr    = np.mean(tprs_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise‐averaged ROC curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_fpr, mean_tpr, label=f'AUC = {mean_auc:.4f}')\n",
    "    for fpr, tpr in zip(fprs, tprs):\n",
    "        plt.plot(fpr, tpr, alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve over {k} folds')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, f'GaussianProcess_roc_curve_kfCV_{scaler_name}.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Prepare averaged PR curve\n",
    "    mean_rec    = np.linspace(0, 1, 100)\n",
    "    precs_interp = []\n",
    "    for precs_i, recs_i in zip(precisions_list, recalls_list):\n",
    "        idx = np.argsort(recs_i)\n",
    "        precs_interp.append(np.interp(mean_rec, recs_i[idx], precs_i[idx]))\n",
    "    mean_pr = np.mean(precs_interp, axis=0)\n",
    "\n",
    "    print('')\n",
    "    print('□ Foldwise‐averaged Precision-Recall curve:')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.plot(mean_rec, mean_pr, label=f'PR AUC = {mean_pr_auc:.4f}')\n",
    "    for recs_i, precs_i in zip(recalls_list, precisions_list):\n",
    "        plt.plot(recs_i, precs_i, alpha=0.3)\n",
    "    plt.plot([0,1],[0,1], linestyle='--', alpha=0.5)\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall over {k} folds')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(path_figure, f'GaussianProcess_pr_curve_kfCV_{scaler_name}.png'))\n",
    "    plt.show(); plt.close()\n",
    "\n",
    "    # Retrain on full data\n",
    "    pipeline_full = Pipeline([\n",
    "        ('scaler', scaler_step),\n",
    "        ('gp', GaussianProcessClassifier())\n",
    "    ])\n",
    "    pipeline_full.fit(X, y)\n",
    "    with open(os.path.join(path_model, f'GaussianProcess_kfCV_{scaler_name}.pkl'), 'wb') as f:\n",
    "        pickle.dump(pipeline_full, f)\n",
    "\n",
    "    # Hold‐out for SHAP & LIME: use the same pipeline\n",
    "    pipeline_holdout = Pipeline([\n",
    "        ('scaler', scaler_step),\n",
    "        ('gp', GaussianProcessClassifier())\n",
    "    ])\n",
    "    pipeline_holdout.fit(x_train, t_train)\n",
    "\n",
    "    if show_shap:\n",
    "        print('')\n",
    "        ShapValueFunction(\n",
    "            pipeline_holdout, df, x_train, x_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'GaussianProcess_shap_values_holdout_' + scaler_name,\n",
    "            'GaussianProcess_shap_values_holdout_' + scaler_name,\n",
    "            'Gaussian Process ' + scaler_name,\n",
    "            task_type='classification',\n",
    "            model_type='general'\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    if perform_lime:\n",
    "        print('')\n",
    "        # Pass the pipeline to LIME so it scales internally\n",
    "        LimeContributionValueFunction(\n",
    "            pipeline_holdout,    # now a Pipeline(scaler + GP)\n",
    "            df, x_train, x_test, t_test,\n",
    "            size_x, size_y, path_figure, path_table,\n",
    "            'GaussianProcess_lime_explanation_holdout_' + scaler_name,\n",
    "            'GaussianProcess_lime_feature_contributions_holdout_' + scaler_name,\n",
    "            'Gaussian Process ' + scaler_name,\n",
    "            task_type='classification',\n",
    "            random_state=random_state,\n",
    "            model_type='general'  # Pipeline has a predict_proba method\n",
    "        )\n",
    "        print('')\n",
    "\n",
    "    # Ensure roc_arr is defined\n",
    "    roc_arr = np.array([\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        mean_auc,\n",
    "        f'Gaussian Process {scaler_name}'\n",
    "    ], dtype=object)\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame(\n",
    "        [res],\n",
    "        columns=['AUC','Accuracy','Precision','Recall','f1-score'],\n",
    "        index=[f'Gaussian Process {scaler_name}']\n",
    "    )\n",
    "\n",
    "    return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Gaussian Process Classifier kfCV with per‐feature ARD length‐scales\n",
    "# def GaussianProcessKFold(k=k, scaler='norm', show_shap=True, perform_lime=True):\n",
    "#     from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#     from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "#     from sklearn.model_selection import StratifiedKFold\n",
    "#     from sklearn.metrics import (\n",
    "#         roc_auc_score, accuracy_score, precision_score,\n",
    "#         recall_score, f1_score, confusion_matrix,\n",
    "#         roc_curve, precision_recall_curve, average_precision_score\n",
    "#     )\n",
    "#     from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#     import numpy as np\n",
    "#     import os\n",
    "#     import pandas as pd\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     import pickle\n",
    "\n",
    "\n",
    "#     # Choose scaler based on parameter by the value of scaler, either 'norm' or 'stand'\n",
    "#     if scaler == 'norm':\n",
    "#         scale_name = 'normalized'\n",
    "#     elif scaler == 'stand':\n",
    "#         scale_name = 'standardized'\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown scale: {scaler}. Use 'norm' or 'stand'.\")\n",
    "\n",
    "\n",
    "#     print('')\n",
    "#     print(f'■■■ Gaussian Process Classifier kfCV ({scale_name}) ■■■')\n",
    "#     print('')\n",
    "#     print('◆ 二値分類　(陽性症例の割合(事前確率): ' +\n",
    "#           str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %)')\n",
    "#     print('')\n",
    "#     print(f'----- Be patient. It takes a few minutes. ------')\n",
    "#     print('')\n",
    "\n",
    "#     # Build ARD RBF kernel: one length‐scale per feature\n",
    "#     n_features = X.shape[1]\n",
    "#     kernel = C(1.0, (1e-3, 1e3)) * RBF(\n",
    "#         length_scale=[1.0] * n_features,\n",
    "#         length_scale_bounds=(1e-2, 1e2)\n",
    "#     )\n",
    "\n",
    "#     # Use StratifiedKFold for balanced splits\n",
    "#     kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "#     # Lists for foldwise metrics\n",
    "#     aucs, accs, precs, recs, f1s, specs, aps = [], [], [], [], [], [], []\n",
    "#     # For ROC & PR curves per fold\n",
    "#     fprs, tprs = [], []\n",
    "#     precisions_list, recalls_list = [], []\n",
    "#     # For normalized confusion rates\n",
    "#     tn_rates, fp_rates, fn_rates, tp_rates = [], [], [], []\n",
    "\n",
    "#     for train_index, test_index in kf.split(X, y):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         # --- ここで前処理 ---\n",
    "#         if scaler == 'norm':\n",
    "#             scaler_obj = MinMaxScaler()\n",
    "#         elif scaler == 'stand':\n",
    "#             scaler_obj = StandardScaler()\n",
    "#         else:\n",
    "#             scaler_obj = None\n",
    "\n",
    "#         if scaler_obj is not None:\n",
    "#             X_train = scaler_obj.fit_transform(X_train)\n",
    "#             X_test  = scaler_obj.transform(X_test)\n",
    "\n",
    "#         # Initialize the Gaussian Process Classifier with ARD kernel\n",
    "#         model = GaussianProcessClassifier(\n",
    "#             kernel=kernel,\n",
    "#             n_restarts_optimizer=5,\n",
    "#             warm_start=True\n",
    "#         )\n",
    "#         model.fit(X_train, y_train)\n",
    "\n",
    "#         # Predict classes and probabilities\n",
    "#         y_pred      = model.predict(X_test)\n",
    "#         y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#         # Per‐fold confusion rates\n",
    "#         tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         total = tn + fp + fn + tp\n",
    "#         tn_rates.append(tn / total)\n",
    "#         fp_rates.append(fp / total)\n",
    "#         fn_rates.append(fn / total)\n",
    "#         tp_rates.append(tp / total)\n",
    "\n",
    "#         # Per‐fold metrics\n",
    "#         auc_fold  = roc_auc_score(y_test, y_pred_prob)\n",
    "#         acc_fold  = accuracy_score(y_test, y_pred)\n",
    "#         prec_fold = precision_score(y_test, y_pred, zero_division=0)\n",
    "#         rec_fold  = recall_score(y_test, y_pred)\n",
    "#         f1_fold   = f1_score(y_test, y_pred)\n",
    "#         ap_fold   = average_precision_score(y_test, y_pred_prob)\n",
    "#         spec_fold = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
    "\n",
    "#         aucs.append(auc_fold)\n",
    "#         accs.append(acc_fold)\n",
    "#         precs.append(prec_fold)\n",
    "#         recs.append(rec_fold)\n",
    "#         f1s.append(f1_fold)\n",
    "#         aps.append(ap_fold)\n",
    "#         specs.append(spec_fold)\n",
    "\n",
    "#         # ROC curve data\n",
    "#         fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "#         fprs.append(fpr)\n",
    "#         tprs.append(tpr)\n",
    "\n",
    "#         # Precision‐Recall curve data\n",
    "#         prec_vals, rec_vals, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "#         precisions_list.append(prec_vals)\n",
    "#         recalls_list.append(rec_vals)\n",
    "\n",
    "#     # Compute foldwise‐averaged metrics\n",
    "#     mean_auc    = np.mean(aucs)\n",
    "#     mean_acc    = np.mean(accs)\n",
    "#     mean_prec   = np.mean(precs)\n",
    "#     mean_rec    = np.mean(recs)\n",
    "#     mean_f1     = np.mean(f1s)\n",
    "#     mean_spec   = np.mean(specs)\n",
    "#     mean_pr_auc = np.mean(aps)\n",
    "#     mean_cind   = mean_auc\n",
    "\n",
    "#     # Foldwise‐averaged confusion matrix rates\n",
    "#     fold_tn = np.mean(tn_rates)\n",
    "#     fold_fp = np.mean(fp_rates)\n",
    "#     fold_fn = np.mean(fn_rates)\n",
    "#     fold_tp = np.mean(tp_rates)\n",
    "#     fold_cm = np.array([[fold_tn, fold_fn],\n",
    "#                         [fold_fp, fold_tp]]) * 100\n",
    "\n",
    "#     # Display foldwise‐averaged binary‐classification table\n",
    "#     display_fold_averages(\n",
    "#         k, df, fold_cm,\n",
    "#         fold_tp, fold_fp, fold_fn, fold_tn,\n",
    "#         mean_acc, mean_prec, mean_rec, mean_f1,\n",
    "#         mean_spec, mean_auc, mean_cind, mean_pr_auc,\n",
    "#         \"Gaussian Process Classifier (ARD)\"\n",
    "#     )\n",
    "\n",
    "#     # -----------------Plot foldwise‐averaged ROC curve-----------------\n",
    "#     mean_fpr       = np.linspace(0, 1, 100)\n",
    "#     tprs_interp    = [np.interp(mean_fpr, fprs[i], tprs[i])\n",
    "#                       for i in range(len(fprs))]\n",
    "#     mean_tpr_curve = np.mean(tprs_interp, axis=0)\n",
    "#     roc_arr = np.array([mean_fpr,\n",
    "#                         mean_tpr_curve,\n",
    "#                         mean_auc,\n",
    "#                         'GaussianProcess_roc_curve_kfCV.png'],\n",
    "#                        dtype=object)\n",
    "\n",
    "#     print('')\n",
    "#     print('□ Foldwise‐averaged ROC curve:')\n",
    "#     plt.figure(figsize=(size_x, size_y))\n",
    "#     plt.plot(mean_fpr, mean_tpr_curve,\n",
    "#              label=f'Foldwise‐averaged ROC (AUC = {mean_auc:.4f})')\n",
    "#     for i in range(len(fprs)):\n",
    "#         plt.plot(fprs[i], tprs[i], alpha=0.3)\n",
    "#     plt.plot([0, 1], [0, 1],\n",
    "#              linestyle='--', alpha=0.5)\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.title(f'ROC Curve - Foldwise‐Averaged over {k} Folds')\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_aspect('equal', adjustable='box')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.savefig(os.path.join(path_figure, 'GaussianProcess_roc_curve_kfCV.png'))\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "#     # -----------------Plot foldwise‐averaged Precision‐Recall curve-----------------\n",
    "#     mean_recall = np.linspace(0, 1, 100)\n",
    "#     precisions_interp = []\n",
    "#     for i in range(len(recalls_list)):\n",
    "#         idx_sort = np.argsort(recalls_list[i])\n",
    "#         recall_sorted    = recalls_list[i][idx_sort]\n",
    "#         precision_sorted = precisions_list[i][idx_sort]\n",
    "#         precisions_interp.append(\n",
    "#             np.interp(mean_recall, recall_sorted, precision_sorted)\n",
    "#         )\n",
    "#     mean_pr_curve = np.mean(precisions_interp, axis=0)\n",
    "\n",
    "#     print('')\n",
    "#     print('□ Foldwise‐averaged Precision‐Recall curve:')\n",
    "#     plt.figure(figsize=(size_x, size_y))\n",
    "#     plt.plot(mean_recall, mean_pr_curve,\n",
    "#              label=f'Foldwise‐averaged PRC (AUC = {mean_pr_auc:.4f})')\n",
    "#     for i in range(len(recalls_list)):\n",
    "#         plt.plot(recalls_list[i], precisions_list[i], alpha=0.3)\n",
    "#     plt.plot([0, 1], [0, 1], linestyle='--', alpha=0.5)\n",
    "#     plt.xlabel('Recall')\n",
    "#     plt.ylabel('Precision')\n",
    "#     plt.title(f'Precision‐Recall Curve - Foldwise‐Averaged over {k} Folds')\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_aspect('equal', adjustable='box')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.savefig(os.path.join(path_figure, 'GaussianProcess_pr_curve_kfCV.png'))\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "\n",
    "#     # Optionally retrain the model on the full dataset\n",
    "#     # （必要に応じて同様にスケーリングを挟んでください）\n",
    "#     model_full = GaussianProcessClassifier(\n",
    "#         kernel=kernel,\n",
    "#         n_restarts_optimizer=5,\n",
    "#         warm_start=True\n",
    "#     )\n",
    "#     model_full.fit(X, y)\n",
    "\n",
    "#     # Save the full model\n",
    "#     model_filename = os.path.join(path_model, 'GaussianProcess_kfCV.pkl')\n",
    "#     with open(model_filename, 'wb') as file:\n",
    "#         pickle.dump(model_full, file)\n",
    "\n",
    "#     # Hold‐out model for SHAP and LIME\n",
    "#     model_holdout = GaussianProcessClassifier(\n",
    "#         kernel=kernel,\n",
    "#         n_restarts_optimizer=5,\n",
    "#         warm_start=True\n",
    "#     )\n",
    "#     model_holdout.fit(x_train, t_train)\n",
    "\n",
    "#     if show_shap:\n",
    "#         print('')\n",
    "#         ShapValueFunction(\n",
    "#             model_holdout, df, x_train, x_test,\n",
    "#             size_x, size_y, path_figure, path_table,\n",
    "#             'GaussianProcess_shap_values_holdout',\n",
    "#             'GaussianProcess_shap_values_holdout',\n",
    "#             'GaussianProcessClassifier', task_type='classification', model_type='kernel'\n",
    "#         )\n",
    "#         print('')\n",
    "\n",
    "#     if perform_lime:\n",
    "#         print('')\n",
    "#         LimeContributionValueFunction(\n",
    "#             model_holdout, df, x_train, x_test, t_test,\n",
    "#             size_x, size_y, path_figure, path_table,\n",
    "#             'GaussianProcess_lime_explanation_holdout',\n",
    "#             'GaussianProcess_lime_feature_contributions_holdout',\n",
    "#             'GaussianProcessClassifier', task_type='classification', random_state=random_state\n",
    "#         )\n",
    "#         print('')\n",
    "\n",
    "#     res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "#     res2 = pd.DataFrame(\n",
    "#         [res],\n",
    "#         columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'],\n",
    "#         index=['Gaussian Process Classifier']\n",
    "#     )\n",
    "\n",
    "#     return [res2, roc_arr]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------------  以下はMicro-Averaged Metricsによる評価がされている  ------------------------------------------------\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "def DecisionTreeKFold(k=k, perform_lime=True):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    print('')\n",
    "    print('■ Decision Tree')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    auc_scores, accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], [], []\n",
    "\n",
    "    # For ROC and Precision-Recall curve plotting\n",
    "    all_y_test = []\n",
    "    all_predictions = []\n",
    "\n",
    "    # Initialize array to store feature importances\n",
    "    feature_importances = np.zeros((df.shape[1] - 1,))\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the Decision Tree model\n",
    "        model = DecisionTreeClassifier(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Feature importances are directly available for decision trees\n",
    "        feature_importances += model.feature_importances_\n",
    "\n",
    "        # Predict classes and probabilities for evaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Compute metrics for the current fold\n",
    "        auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Append scores\n",
    "        auc_scores.append(auc)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        all_y_test.extend(y_test)\n",
    "        all_predictions.extend(y_pred_prob)\n",
    "\n",
    "    # Calculate mean scores\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    mean_acc = np.mean(accuracy_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_rec = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Calculate and print the mean of each metric\n",
    "    print(f'□ {k}-fold Cross Validation を用いた Decision Tree による2値分類の検定結果')\n",
    "    print('')\n",
    "    print(f'Mean AUC: {mean_auc:.4f}')\n",
    "    print(f'Mean Accuracy: {mean_acc:.4f}')\n",
    "    print(f'Mean Precision: {mean_prec:.4f}')\n",
    "    print(f'Mean Recall: {mean_rec:.4f}')\n",
    "    print(f'Mean F1 Score: {mean_f1:.4f}')\n",
    "    print('')\n",
    "\n",
    "    hmname=os.path.join(path_figure, 'decision_tree_confusion_heatmap_kfCV.png')\n",
    "    rocname=os.path.join(path_figure, 'decision_tree_roc_curve_kfCV.png')\n",
    "    prerecname=os.path.join(path_figure, 'decision_tree_prerec_curve_kfCV.png')\n",
    "\n",
    "    roc_decisiontree=showscores(all_y_test, all_predictions, hmname, rocname, prerecname)\n",
    "\n",
    "    # Average the feature importances over all folds\n",
    "    feature_importances /= k\n",
    "    # Get the feature names\n",
    "    feature_names = df.columns[:-1]\n",
    "\n",
    "    # Sort the features by importance in descending order\n",
    "    sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "    sorted_importance = feature_importances[sorted_idx]\n",
    "    sorted_features = feature_names[sorted_idx]\n",
    "\n",
    "    # Export feature importances\n",
    "    feature_importances_df = pd.DataFrame({'Feature': sorted_features, 'Importance': sorted_importance})\n",
    "    excel_filename = os.path.join(path_table, 'decision_tree_feature_importances_kfold.xlsx')\n",
    "    feature_importances_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "    # Plot only the top 10 features\n",
    "    top_features = sorted_features[:10]\n",
    "    top_importances = sorted_importance[:10]\n",
    "\n",
    "    # Plot only the top 10 features\n",
    "    top_features = sorted_features[::-1]\n",
    "    top_importances = sorted_importance[::-1]\n",
    "\n",
    "    print('')\n",
    "    print(f'◇ {k}-fold Cross Validation で得られた Decision Tree における Feature Importance')\n",
    "    print('')\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(top_features, top_importances, color='skyblue')\n",
    "    plt.xlabel('Average Feature Importance')\n",
    "    plt.title(f'Top 10 Feature Importances in {k}-fold CV of Decision Tree')\n",
    "\n",
    "    # フォントファイルのパスを確認\n",
    "    font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "    # フォントプロパティを設定\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "\n",
    "    plt.savefig(os.path.join(path_figure, 'decision_tree_feature_importances_kfCV.png'))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = DecisionTreeClassifier(random_state=random_state)\n",
    "    model_full.fit(X, y)\n",
    "\n",
    "    # Save the full model\n",
    "    model_filename = os.path.join(path_model, 'decision_tree_kfCV.pkl')\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Holtout data\n",
    "    model_holdout = DecisionTreeClassifier(random_state=random_state)\n",
    "    model_holdout.fit(x_train, t_train)\n",
    "\n",
    "\n",
    "    if len(df.columns)<250:\n",
    "\n",
    "        print('')\n",
    "        ShapValueFunction(model_holdout, df, x_train, x_test, size_x, size_y, path_figure, path_table, 'decision_treee_shap_values_holdout', 'decision_tree_shap_values_holdout', 'DecisionTree', task_type='classification', model_type='tree')\n",
    "        print('')\n",
    "\n",
    "    else:\n",
    "        print('')\n",
    "        print('◇ 説明変数の数が250以上あるため、Decision Tree のSHAP値の計算は回避されました。')\n",
    "        print('')\n",
    "\n",
    "    if perform_lime == True:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(model_holdout, df, x_train, x_test, t_test, size_x, size_y, path_figure, path_table, 'decision_tree_lime_explanation_holdout', 'decision_tree_lime_feature_contributions_holdout', 'DecisionTree', task_type='classification', random_state=random_state)\n",
    "        print('')\n",
    "\n",
    "\n",
    "    res = np.array([mean_auc, mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)\n",
    "    res2 = pd.DataFrame([res], columns=['AUC', 'Accuracy', 'Precision', 'Recall', 'f1-score'], index=['Decision Tree'])\n",
    "\n",
    "    return [res2, roc_decisiontree]\n",
    "\n",
    "\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "def KNearestNeighborsKFoldN(k=k, perform_lime=True):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    print('')\n",
    "    print('■ k-Nearest Neighbors normalized')\n",
    "    print('')\n",
    "\n",
    "\n",
    "    # Initialize MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    auc_scores, accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the k-Nearest Neighbors model\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict classes for evaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        # k-NN does not directly provide probability estimates for AUC calculation in a consistent way like decision trees,\n",
    "        # hence it's commented out. If needed, use `predict_proba` method carefully considering k-NN's behavior.\n",
    "        # y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        # auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "        # Compute metrics for the current fold\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Append scores (excluding AUC due to the above comment)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Calculate mean scores\n",
    "    mean_acc = np.mean(accuracy_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_rec = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Calculate and print the mean of each metric\n",
    "    print(f'□ {k}-fold Cross Validation を用いた k-Nearest Neighbors normalized による2値分類の検定結果')\n",
    "    print('')\n",
    "    print(f'Mean Accuracy: {mean_acc:.4f}')\n",
    "    print(f'Mean Precision: {mean_prec:.4f}')\n",
    "    print(f'Mean Recall: {mean_rec:.4f}')\n",
    "    print(f'Mean F1 Score: {mean_f1:.4f}')\n",
    "    print('')\n",
    "\n",
    "    # k-NN does not use feature importances, so related output is removed\n",
    "\n",
    "    print('')\n",
    "    print('・ AUC and feature importance cannot be figured out in the k-Nearest Neighbors in a consistent way like other models.')\n",
    "    print('')\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = KNeighborsClassifier()\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Ensure the path exists\n",
    "    model_filename = os.path.join(path_model, 'kNN_normalized_full.pkl')\n",
    "    # Save the full model\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Holdout model\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = KNeighborsClassifier()\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if perform_lime == True:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(model_holdout, df, x_train_scaled, x_test_scaled, t_test, size_x, size_y, path_figure, path_table, 'kNN_normalized_lime_explanation_holdout', 'kNN_normalized_lime_feature_contributions_holdout', 'k-Nearst Neighbors normalized', task_type='classification', random_state=random_state)\n",
    "        print('')\n",
    "\n",
    "    res = np.array([mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)  # Note: AUC is excluded\n",
    "    res2 = pd.DataFrame([res], columns=['Accuracy', 'Precision', 'Recall', 'f1-score'], index=['k-Nearest Neighbors normalized'])\n",
    "\n",
    "    return [res2, np.array([np.nan, np.nan, np.nan, np.nan], dtype=object)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "def KNearestNeighborsKFoldS(k=k, perform_lime=True):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    print('')\n",
    "    print('■ k-Nearest Neighbors standardized')\n",
    "    print('')\n",
    "\n",
    "    # Initialize StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    auc_scores, accuracy_scores, precision_scores, recall_scores, f1_scores = [], [], [], [], []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_scaled):\n",
    "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Initialize the k-Nearest Neighbors model\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict classes for evaluation\n",
    "        y_pred = model.predict(X_test)\n",
    "        # k-NN does not directly provide probability estimates for AUC calculation in a consistent way like decision trees,\n",
    "        # hence it's commented out. If needed, use `predict_proba` method carefully considering k-NN's behavior.\n",
    "        # y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "        # auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "        # Compute metrics for the current fold\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        # Append scores (excluding AUC due to the above comment)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Calculate mean scores\n",
    "    mean_acc = np.mean(accuracy_scores)\n",
    "    mean_prec = np.mean(precision_scores)\n",
    "    mean_rec = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "\n",
    "    # Calculate and print the mean of each metric\n",
    "    print(f'□ {k}-fold Cross Validation を用いた k-Nearest Neighbors standardized による2値分類の検定結果')\n",
    "    print('')\n",
    "    print(f'Mean Accuracy: {mean_acc:.4f}')\n",
    "    print(f'Mean Precision: {mean_prec:.4f}')\n",
    "    print(f'Mean Recall: {mean_rec:.4f}')\n",
    "    print(f'Mean F1 Score: {mean_f1:.4f}')\n",
    "    print('')\n",
    "\n",
    "    # k-NN does not use feature importances, so related output is removed\n",
    "\n",
    "    print('')\n",
    "    print('・ AUC and feature importance cannot be figured out in the k-Nearest Neighbors in a consistent way like other models.')\n",
    "    print('')\n",
    "\n",
    "    # Optionally retrain the model on the full dataset\n",
    "    model_full = KNeighborsClassifier()\n",
    "    model_full.fit(X_scaled, y)\n",
    "\n",
    "    # Ensure the path exists\n",
    "    model_filename = os.path.join(path_model, 'kNN_standardized_full.pkl')\n",
    "    # Save the full model\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(model_full, file)\n",
    "\n",
    "    # Holdtou model\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model_holdout = KNeighborsClassifier()\n",
    "    model_holdout.fit(x_train_scaled, t_train)\n",
    "\n",
    "    if perform_lime == True:\n",
    "        print('')\n",
    "        LimeContributionValueFunction(model_holdout, df, x_train_scaled, x_test_scaled, t_test, size_x, size_y, path_figure, path_table, 'kNN_standardized_lime_explanation_holdout', 'kNN_standardized_lime_feature_contributions_holdout', 'k-Nearst Neighbors standardized', task_type='classification', random_state=random_state)\n",
    "        print('')\n",
    "\n",
    "\n",
    "    res = np.array([mean_acc, mean_prec, mean_rec, mean_f1], dtype=object)  # Note: AUC is excluded\n",
    "    res2 = pd.DataFrame([res], columns=['Accuracy', 'Precision', 'Recall', 'f1-score'], index=['k-Nearest Neighbors standardized'])\n",
    "\n",
    "    return [res2, np.array([np.nan, np.nan, np.nan, np.nan], dtype=object)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyyK3juOs_eY"
   },
   "source": [
    "# ■ 実行コマンド"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Hl7zCEWKth7"
   },
   "source": [
    "## 1) 簡易モデル Set (９個の機械学習モデル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxEDAtfPKz4m"
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('■ 二値分類の簡易Verson')\n",
    "print('')\n",
    "print(f'◆ The sample size of dataset: {n_samples}')\n",
    "print('')\n",
    "\n",
    "# 説明変数と目的変数を分離: Pandas形式\n",
    "X0 = df.iloc[:, :-1]\n",
    "y0 = df.iloc[:, -1]\n",
    "\n",
    "# データの大きさ\n",
    "print('◆　行と列の数')\n",
    "rows, cols = df.shape\n",
    "print(f'データの行数(サンプル数) {rows},  データの列数(説明変数＋目的変数の数) {cols}')\n",
    "if rows >= 5000 or cols >= 5000:\n",
    "    bigdata = 1\n",
    "    print('')\n",
    "    print('◇ データは Big Data のため、Random Forest と LightGBM への Optuna適用 と CatBoost の利用が省かれる。')\n",
    "elif rows < 5000 and cols < 5000:\n",
    "    bigdata = 0\n",
    "    print('')\n",
    "    print('◇ データは Big Data ではないため、Optuna は適用可能なモデルには適用する。')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "# データの分割数 k\n",
    "print(f\"◆ Chosen value of k for k-fold cross-validation: {k}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# 目的変数の分布の表示\n",
    "print('◆　目的変数の分布')\n",
    "sns.displot(df.iloc[:,-1].dropna())\n",
    "print('　　　　　陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %')\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データの線形性の確認\n",
    "\n",
    "# 線形回帰モデルによる決定係数R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# (二値分類のため)Logistic回帰モデルによる擬似決定係数R2: NagelkerkeのR2 (Cox-Snellの擬似R2を0〜1にscalingしたもの)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def nagelkerke_r2(X, y, **logistic_kwargs):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "    y: array-like of shape (n_samples,), binary target (0 or 1)\n",
    "    logistic_kwargs:\n",
    "        追加の LogisticRegression 引数（solver, C, penalty など）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Nagelkerke の R²\n",
    "    \"\"\"\n",
    "    # 1) モデルのフィッティング\n",
    "    model = LogisticRegression(**logistic_kwargs)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 2) 予測確率（正クラス）の取得\n",
    "    p = model.predict_proba(X)[:, 1]\n",
    "    # log(0) を防ぐため eps 分だけクリップ\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # 3) フルモデルの対数尤度\n",
    "    ll_model = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # 4) ヌルモデル（切片のみ、常に y の平均を予測）の対数尤度\n",
    "    p_null = np.clip(np.mean(y), eps, 1 - eps)\n",
    "    ll_null = np.sum(y * np.log(p_null) + (1 - y) * np.log(1 - p_null))\n",
    "\n",
    "    # 5) Cox–Snell の R²\n",
    "    n = len(y)\n",
    "    r2_cs = 1 - np.exp((ll_null - ll_model) * 2 / n)\n",
    "\n",
    "    # 6) Nagelkerke の R²\n",
    "    r2_nagelkerke = r2_cs / (1 - np.exp(2 * ll_null / n))\n",
    "\n",
    "    return r2_nagelkerke\n",
    "\n",
    "pseudo_r2 = nagelkerke_r2(\n",
    "    X, y,\n",
    "    penalty='l2',     # リッジ（L2）正則化\n",
    "    C=1.0,            # デフォルト付近からスタート\n",
    "    solver='lbfgs',   # 中小規模向き\n",
    "    max_iter=500,     # 収束用に少し余裕を\n",
    "    tol=1e-6,          # 精度重視\n",
    "    class_weight='balanced' # Imbalanced Dataにも対応\n",
    ")\n",
    "\n",
    "\n",
    "print(f'◆　説明変数と目的変数の間の決定係数R2')\n",
    "print('')\n",
    "print(f'◇ Nagelkerke の擬似R² (標準設定) = {pseudo_r2:.4f}')\n",
    "print(f'  擬似決係数R²の見方　0.2未満: 弱い説明力、0.2〜0.5: 中程度の説明力、0.5以上: 強い説明力')\n",
    "print('')\n",
    "print(f'◇ 線形回帰による決定係数R² = {r2:.4f}')\n",
    "print('   決定係数R²の見方　 0.3未満: 線形性なし、0.3〜0.5: 弱い線形性、0.5〜0.7: 中程度の線形性、0.7〜0.9: 強い線形性、0.9以上: 完全に線形')\n",
    "print('')\n",
    "print('  (擬似決係数R² > 0.5　または  決定係数R² > 0.7 のとき、線形性があると見なせる。二値分類では擬似R²の方が妥当)')\n",
    "print('')\n",
    "if pseudo_r2 >= 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性が見られるため、SVM の kernel と XGBoost の booster を線形にする。')\n",
    "    linear = 1\n",
    "elif pseudo_r2 < 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性はそれほど見られないため、線形モデルの優先は行わない。')\n",
    "    linear = 0\n",
    "print('')\n",
    "print(f'linear = {linear:.1f}')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 残差プロット\n",
    "print('◆　線形モデルによる目的変数の予測値の残差(誤差の)プロット')\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('予測値', fontproperties=font_prop)\n",
    "plt.ylabel('残差', fontproperties=font_prop)\n",
    "plt.title('予測値と残差のプロット', fontproperties=font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 連続変数の場合の線形性の判定\n",
    "\n",
    "# # RESET（Regression Specification Error Test）\n",
    "# from statsmodels.stats.diagnostic import linear_reset\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# ols = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "# print(linear_reset(ols, power=2))\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 線形モデル vs 多項式モデル（2次項・3次項を加えたモデル）\n",
    "# poly2 = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "# score_lin = cross_val_score(LinearRegression(), X, y, cv=5, scoring=\"r2\").mean()\n",
    "# score_poly2 = cross_val_score(poly2, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "# print(\"線形モデル R²:\", score_lin)\n",
    "# print(\"2次多項式モデル R²:\", score_poly2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定数列を除外する関数\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_columns:\n",
    "        print(f'以下の定数列を除外します: {constant_columns}')\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    else:\n",
    "        print('定数列は存在しません。')\n",
    "    return df\n",
    "\n",
    "# 欠損値を確認・除外する関数\n",
    "def check_missing_values(df_X, df_y):\n",
    "    missing_X = df_X.isnull().sum()\n",
    "    missing_y = df_y.isnull().sum()\n",
    "    if missing_X.sum() > 0:\n",
    "        print('説明変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_X = df_X.dropna()\n",
    "    if missing_y > 0:\n",
    "        print('目的変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_y = df_y.dropna()\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "print('◆ 説明変数と目的変数のPearsonの相関係数: 線形な相関のみ')\n",
    "# 定数列の除外\n",
    "X0 = remove_constant_columns(X0)\n",
    "\n",
    "# 目的変数が定数か確認\n",
    "if y0.nunique() <= 1:\n",
    "    raise ValueError('目的変数 y0 が定数列です。相関係数を計算できません。')\n",
    "\n",
    "# 欠損値の除外\n",
    "X0, y0 = check_missing_values(X0, y0)\n",
    "\n",
    "\n",
    "# 各説明変数と目的変数との相関係数を計算\n",
    "correlations = {}\n",
    "for column in X0.columns:\n",
    "    correlations[column] = X0[column].corr(y0)\n",
    "\n",
    "# 相関係数をSeriesに変換\n",
    "correlation_series = pd.Series(correlations)\n",
    "\n",
    "# 絶対値の降順にソートし、元の符号を保持\n",
    "top_10_correlations = correlation_series.reindex(correlation_series.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Top 10の相関係数を昇べき順にソート\n",
    "sorted_top_10_correlations = top_10_correlations.sort_values(ascending=True)\n",
    "\n",
    "# 色を決定\n",
    "colors = ['skyblue' if val > 0 else 'lightcoral' for val in correlation_series.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(correlation_series.index, correlation_series.values, color=colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "\n",
    "print('□ 青は正の相関、赤は負の相関。　1に近いほど強い正の相関、-1に近いほど強い負の相関。0は線形での相関無し')\n",
    "print('□　　相関係数の絶対値Cの目安： C > 0.7 強い相関、0.4〜0.7 中程度の相関、0.2〜0.4 弱い相関　　C < 0.2 相関無し')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のPearsonの相関係数: 相関係数のTop 10 のみ')\n",
    "\n",
    "# Top 10 correlation colors\n",
    "top_10_colors = ['skyblue' if val > 0 else 'lightcoral' for val in sorted_top_10_correlations.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_top_10_correlations.index, sorted_top_10_correlations.values, color=top_10_colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Top 10 Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# XiCorの相関係数のプロット関数\n",
    "print('◆ 説明変数と目的変数のChatterjee`sの相関係数: 非線形な相関も含む (参考値)')\n",
    "\n",
    "def xicor(x, y, ties=True):\n",
    "    np.random.seed(42)\n",
    "    n = len(x)\n",
    "    order = np.argsort(x)\n",
    "    ranked_y = np.argsort(np.argsort(y[order], kind='mergesort'))\n",
    "\n",
    "    if ties:\n",
    "        l = np.argsort(np.argsort(y[order], kind='max'))\n",
    "        r = ranked_y.copy()\n",
    "        return 1 - n * np.sum(np.abs(r[1:] - r[:-1])) / (2 * np.sum(l * (n - l)))\n",
    "    else:\n",
    "        return 1 - 3 * np.sum(np.abs(ranked_y[1:] - ranked_y[:-1])) / (n**2 - 1)\n",
    "\n",
    "def plot_xicor(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor(df)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のChatterjee`sの相関係数: 相関係数のTop 10 のみ')\n",
    "def plot_xicor10(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)[-10:]  # 上位10の特徴量を選択\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # グラフのサイズを調整\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('Top 10 XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor10(df)\n",
    "print('')\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thttps://arxiv.org/abs/1909.10140 参照')\n",
    "print('')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time2 = start_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# 出力ファイル\n",
    "filename0 = os.path.basename(path_table)\n",
    "filename = os.path.splitext(filename0)[0]\n",
    "filepath = path_table + '/AllEvaluationResultsFor' + filename + str(formatted_start_time2) + '.xlsx'\n",
    "filepath2 = path_table + '/AllAUCResultsFor' + filename + str(formatted_start_time2) + '.csv'\n",
    "print('◆　計算結果の出力先')\n",
    "print(filepath)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 現在時刻（計算開始時）\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time = start_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "formatted_start_time2 = start_time.strftime('%Y年%m月%d日 %H時%M分%')\n",
    "print(f'◆ Present Time (Start): {formatted_start_time}')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 各機械学習モデルの実行\n",
    "\n",
    "# データがそれほど大きくないとき\n",
    "if bigdata ==0:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_logistic_S = LogisticKFoldS()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_lasso_S = LassoKFoldS(0.01)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_N = RidgeKFoldN(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_S = RidgeKFoldS(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_SVM_S = SVMKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_YDF = YggdrasilDecisionForestKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "    res_list = [\n",
    "                res_linear,\n",
    "                res_logistic_N,\n",
    "                # res_logistic_S,\n",
    "                res_lasso_N,\n",
    "                # res_lasso_S,\n",
    "                # res_lasso_optuna_N,\n",
    "                # res_lasso_optuna_S,\n",
    "                # res_ridge_N,\n",
    "                # res_ridge_S,\n",
    "                # res_ridge_optuna_N,\n",
    "                # res_ridge_optuna_S,\n",
    "                res_SVM_N,\n",
    "                # res_SVM_S,\n",
    "                # res_LDAn,\n",
    "                # res_LDAs,\n",
    "                # res_GaussianN,\n",
    "                # res_GaussianS,\n",
    "                # res_Gradient_Boosting,\n",
    "                res_Adaboost,\n",
    "                res_RandomForest,\n",
    "                # res_RandomForest_optuna,\n",
    "                res_XGBoost,\n",
    "                # res_XGBoost_optuna,\n",
    "                res_LightGBM,\n",
    "                # res_LightGBM_optuna,\n",
    "                # res_LightGBMTuner_optuna,\n",
    "                # res_CatBoost,\n",
    "                # res_YDF,\n",
    "                # res_YDF_optuna,\n",
    "                res_MLPn,\n",
    "                # res_MLPs,\n",
    "                # res_TabNetN,\n",
    "                # res_TabNetS,\n",
    "                # res_TabNetN_optuna,\n",
    "                # res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list], axis=0)\n",
    "    res_auc = [item[1] for item in res_list]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# データが大きいとき\n",
    "else:\n",
    "\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_logistic_S = LogisticKFoldS()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_lasso_S = LassoKFoldS(0.01)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_N = RidgeKFoldN(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_S = RidgeKFoldS(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_SVM_N = SVMKFoldN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_SVM_S = SVMKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_YDF = YggdrasilDecisionForestKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "    res_list2 = [\n",
    "                res_linear,\n",
    "                                res_logistic_N,\n",
    "                                # res_logistic_S,\n",
    "                                res_lasso_N,\n",
    "                                # res_lasso_S,\n",
    "                                # res_lasso_optuna_N,\n",
    "                                # res_lasso_optuna_S,\n",
    "                                # res_ridge_N,\n",
    "                                # res_ridge_S,\n",
    "                                # res_ridge_optuna_N,\n",
    "                                # res_ridge_optuna_S,\n",
    "                                # res_SVM_N,\n",
    "                                # res_SVM_S,\n",
    "                                # res_LDAn,\n",
    "                                # res_LDAs,\n",
    "                                # res_GaussianN,\n",
    "                                # res_GaussianS,\n",
    "                                # res_Gradient_Boosting,\n",
    "                                res_Adaboost,\n",
    "                                res_RandomForest,\n",
    "                                # res_RandomForest_optuna,\n",
    "                                res_XGBoost,\n",
    "                                # res_XGBoost_optuna,\n",
    "                                res_LightGBM,\n",
    "                                # res_LightGBM_optuna,\n",
    "                                # res_LightGBMTuner_optuna,\n",
    "                                # res_CatBoost,\n",
    "                                # res_YDF,\n",
    "                                # res_YDF_optuna,\n",
    "                                res_MLPn,\n",
    "                                # res_MLPs,\n",
    "                                # res_TabNetN,\n",
    "                                # res_TabNetS,\n",
    "                                # res_TabNetN_optuna,\n",
    "                                # res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list2], axis=0)\n",
    "    res_auc = [item[1] for item in res_list2]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# プロットの準備\n",
    "plt.figure(figsize=(14, 10))  # 図のサイズを少し大きく設定\n",
    "\n",
    "# AUCが大きい順にデータをソート。res_auc の各エントリは (fpr, tpr, auc, name) の形式\n",
    "data_sorted = sorted(res_auc, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 最もAUCが高いエントリを取得\n",
    "if data_sorted:\n",
    "    top_auc = data_sorted[0][2]\n",
    "else:\n",
    "    top_auc = None\n",
    "\n",
    "# 各エントリをループしてプロット\n",
    "for idx, entry in enumerate(data_sorted):\n",
    "    fpr, tpr, auc, name = entry\n",
    "    # NaNが含まれているエントリはスキップ\n",
    "    if np.isnan(auc) or np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "        continue\n",
    "    # 最もAUCが高いエントリは太くプロット\n",
    "    if idx == 0:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=3.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=1.5)\n",
    "\n",
    "# 対角線のプロット\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='random prediction')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curves Comparison', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# アスペクト比を1に設定\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 軸の範囲を0から1に設定\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 凡例を図の右側外側に配置\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop=font_prop)\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_plot_path = os.path.join(path_figure, \"all_ROC_curves.png\")\n",
    "plt.savefig(roc_plot_path, bbox_inches='tight')\n",
    "\n",
    "print('')\n",
    "print(\"■ Figure overlaying all the ROC curves by all the ML models\")\n",
    "print('')\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('')\n",
    "print(f\"■ All the ROC curves saved to: {roc_plot_path}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 計算終了時の現在時刻\n",
    "end_time = datetime.now()\n",
    "formatted_end_time = end_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "print(f'◆ Present Time (End): {formatted_end_time}')\n",
    "\n",
    "# 計算に要した時間（終了時刻 - 開始時刻）\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 時間、分、秒に分割して表示\n",
    "hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print('')\n",
    "print(f'計算に要した時間: {hours} 時間, {minutes} 分, {seconds} 秒')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◆　計算結果の出力先')\n",
    "print('')\n",
    "print('1. 数値データ:   ' + path_table)\n",
    "print('')\n",
    "print('2. 画像データ:   ' + path_figure)\n",
    "print('')\n",
    "print('3. モデル:      ' + path_model)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBYYl0T2ymNH"
   },
   "source": [
    "## 2) 頻用モデル Set (12個の機械学習モデル)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwzVTZcUyvG8"
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('■ 二値分類の簡易Verson')\n",
    "print('')\n",
    "print(f'◆ The sample size of dataset: {n_samples}')\n",
    "print('')\n",
    "\n",
    "# 説明変数と目的変数を分離: Pandas形式\n",
    "X0 = df.iloc[:, :-1]\n",
    "y0 = df.iloc[:, -1]\n",
    "\n",
    "# データの大きさ\n",
    "print('◆　行と列の数')\n",
    "rows, cols = df.shape\n",
    "print(f'データの行数(サンプル数) {rows},  データの列数(説明変数＋目的変数の数) {cols}')\n",
    "if rows >= 5000 or cols >= 5000:\n",
    "    bigdata = 1\n",
    "    print('')\n",
    "    print('◇ データは Big Data のため、Random Forest と LightGBM への Optuna適用 と CatBoost の利用が省かれる。')\n",
    "elif rows < 5000 and cols < 5000:\n",
    "    bigdata = 0\n",
    "    print('')\n",
    "    print('◇ データは Big Data ではないため、Optuna は適用可能なモデルには適用する。')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "# データの分割数 k\n",
    "print(f\"◆ Chosen value of k for k-fold cross-validation: {k}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# 目的変数の分布の表示\n",
    "print('◆　目的変数の分布')\n",
    "sns.displot(df.iloc[:,-1].dropna())\n",
    "print('　　　　　陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %')\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "\n",
    "# データの線形性の確認\n",
    "\n",
    "# 線形回帰モデルによる決定係数R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "\n",
    "# (二値分類のため)Logistic回帰モデルによる擬似決定係数R2: NagelkerkeのR2 (Cox-Snellの擬似R2を0〜1にscalingしたもの)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def nagelkerke_r2(X, y, **logistic_kwargs):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "    y: array-like of shape (n_samples,), binary target (0 or 1)\n",
    "    logistic_kwargs:\n",
    "        追加の LogisticRegression 引数（solver, C, penalty など）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Nagelkerke の R²\n",
    "    \"\"\"\n",
    "    # 1) モデルのフィッティング\n",
    "    model = LogisticRegression(**logistic_kwargs)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 2) 予測確率（正クラス）の取得\n",
    "    p = model.predict_proba(X)[:, 1]\n",
    "    # log(0) を防ぐため eps 分だけクリップ\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # 3) フルモデルの対数尤度\n",
    "    ll_model = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # 4) ヌルモデル（切片のみ、常に y の平均を予測）の対数尤度\n",
    "    p_null = np.clip(np.mean(y), eps, 1 - eps)\n",
    "    ll_null = np.sum(y * np.log(p_null) + (1 - y) * np.log(1 - p_null))\n",
    "\n",
    "    # 5) Cox–Snell の R²\n",
    "    n = len(y)\n",
    "    r2_cs = 1 - np.exp((ll_null - ll_model) * 2 / n)\n",
    "\n",
    "    # 6) Nagelkerke の R²\n",
    "    r2_nagelkerke = r2_cs / (1 - np.exp(2 * ll_null / n))\n",
    "\n",
    "    return r2_nagelkerke\n",
    "\n",
    "pseudo_r2 = nagelkerke_r2(\n",
    "    X, y,\n",
    "    penalty='l2',     # リッジ（L2）正則化\n",
    "    C=1.0,            # デフォルト付近からスタート\n",
    "    solver='lbfgs',   # 中小規模向き\n",
    "    max_iter=500,     # 収束用に少し余裕を\n",
    "    tol=1e-6,          # 精度重視\n",
    "    class_weight='balanced' # Imbalanced Dataにも対応\n",
    ")\n",
    "\n",
    "\n",
    "print(f'◆　説明変数と目的変数の間の決定係数R2')\n",
    "print('')\n",
    "print(f'◇ Nagelkerke の擬似R² (標準設定) = {pseudo_r2:.4f}')\n",
    "print(f'  擬似決係数R²の見方　0.2未満: 弱い説明力、0.2〜0.5: 中程度の説明力、0.5以上: 強い説明力')\n",
    "print('')\n",
    "print(f'◇ 線形回帰による決定係数R² = {r2:.4f}')\n",
    "print('   決定係数R²の見方　 0.3未満: 線形性なし、0.3〜0.5: 弱い線形性、0.5〜0.7: 中程度の線形性、0.7〜0.9: 強い線形性、0.9以上: 完全に線形')\n",
    "print('')\n",
    "print('  (擬似決係数R² > 0.5　または  決定係数R² > 0.7 のとき、線形性があると見なせる。二値分類では擬似R²の方が妥当)')\n",
    "print('')\n",
    "if pseudo_r2 >= 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性が見られるため、SVM の kernel と XGBoost の booster を線形にする。')\n",
    "    linear = 1\n",
    "elif pseudo_r2 < 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性はそれほど見られないため、線形モデルの優先は行わない。')\n",
    "    linear = 0\n",
    "print('')\n",
    "print(f'linear = {linear:.1f}')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 残差プロット\n",
    "print('◆　線形モデルによる目的変数の予測値の残差(誤差の)プロット')\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('予測値', fontproperties=font_prop)\n",
    "plt.ylabel('残差', fontproperties=font_prop)\n",
    "plt.title('予測値と残差のプロット', fontproperties=font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 連続変数の場合の線形性の判定\n",
    "\n",
    "# # RESET（Regression Specification Error Test）\n",
    "# from statsmodels.stats.diagnostic import linear_reset\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# ols = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "# print(linear_reset(ols, power=2))\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 線形モデル vs 多項式モデル（2次項・3次項を加えたモデル）\n",
    "# poly2 = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "# score_lin = cross_val_score(LinearRegression(), X, y, cv=5, scoring=\"r2\").mean()\n",
    "# score_poly2 = cross_val_score(poly2, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "# print(\"線形モデル R²:\", score_lin)\n",
    "# print(\"2次多項式モデル R²:\", score_poly2)\n",
    "\n",
    "\n",
    "\n",
    "# 定数列を除外する関数\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_columns:\n",
    "        print(f'以下の定数列を除外します: {constant_columns}')\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    else:\n",
    "        print('定数列は存在しません。')\n",
    "    return df\n",
    "\n",
    "# 欠損値を確認・除外する関数\n",
    "def check_missing_values(df_X, df_y):\n",
    "    missing_X = df_X.isnull().sum()\n",
    "    missing_y = df_y.isnull().sum()\n",
    "    if missing_X.sum() > 0:\n",
    "        print('説明変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_X = df_X.dropna()\n",
    "    if missing_y > 0:\n",
    "        print('目的変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_y = df_y.dropna()\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "print('◆ 説明変数と目的変数のPearsonの相関係数: 線形な相関のみ')\n",
    "# 定数列の除外\n",
    "X0 = remove_constant_columns(X0)\n",
    "\n",
    "# 目的変数が定数か確認\n",
    "if y0.nunique() <= 1:\n",
    "    raise ValueError('目的変数 y0 が定数列です。相関係数を計算できません。')\n",
    "\n",
    "# 欠損値の除外\n",
    "X0, y0 = check_missing_values(X0, y0)\n",
    "\n",
    "\n",
    "# 各説明変数と目的変数との相関係数を計算\n",
    "correlations = {}\n",
    "for column in X0.columns:\n",
    "    correlations[column] = X0[column].corr(y0)\n",
    "\n",
    "# 相関係数をSeriesに変換\n",
    "correlation_series = pd.Series(correlations)\n",
    "\n",
    "# 絶対値の降順にソートし、元の符号を保持\n",
    "top_10_correlations = correlation_series.reindex(correlation_series.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Top 10の相関係数を昇べき順にソート\n",
    "sorted_top_10_correlations = top_10_correlations.sort_values(ascending=True)\n",
    "\n",
    "# 色を決定\n",
    "colors = ['skyblue' if val > 0 else 'lightcoral' for val in correlation_series.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(correlation_series.index, correlation_series.values, color=colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "\n",
    "print('□ 青は正の相関、赤は負の相関。　1に近いほど強い正の相関、-1に近いほど強い負の相関。0は線形での相関無し')\n",
    "print('□　　相関係数の絶対値Cの目安： C > 0.7 強い相関、0.4〜0.7 中程度の相関、0.2〜0.4 弱い相関　　C < 0.2 相関無し')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のPearsonの相関係数: 相関係数のTop 10 のみ')\n",
    "\n",
    "# Top 10 correlation colors\n",
    "top_10_colors = ['skyblue' if val > 0 else 'lightcoral' for val in sorted_top_10_correlations.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_top_10_correlations.index, sorted_top_10_correlations.values, color=top_10_colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Top 10 Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# XiCorの相関係数のプロット関数\n",
    "print('◆ 説明変数と目的変数のChatterjee`sの相関係数: 非線形な相関も含む (参考値)')\n",
    "\n",
    "def xicor(x, y, ties=True):\n",
    "    np.random.seed(42)\n",
    "    n = len(x)\n",
    "    order = np.argsort(x)\n",
    "    ranked_y = np.argsort(np.argsort(y[order], kind='mergesort'))\n",
    "\n",
    "    if ties:\n",
    "        l = np.argsort(np.argsort(y[order], kind='max'))\n",
    "        r = ranked_y.copy()\n",
    "        return 1 - n * np.sum(np.abs(r[1:] - r[:-1])) / (2 * np.sum(l * (n - l)))\n",
    "    else:\n",
    "        return 1 - 3 * np.sum(np.abs(ranked_y[1:] - ranked_y[:-1])) / (n**2 - 1)\n",
    "\n",
    "def plot_xicor(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor(df)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のChatterjee`sの相関係数: 相関係数のTop 10 のみ')\n",
    "def plot_xicor10(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)[-10:]  # 上位10の特徴量を選択\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # グラフのサイズを調整\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('Top 10 XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor10(df)\n",
    "print('')\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thttps://arxiv.org/abs/1909.10140 参照')\n",
    "print('')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time2 = start_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# 出力ファイル\n",
    "filename0 = os.path.basename(path_table)\n",
    "filename = os.path.splitext(filename0)[0]\n",
    "filepath = path_table + '/AllEvaluationResultsFor' + filename + str(formatted_start_time2) + '.xlsx'\n",
    "filepath2 = path_table + '/AllAUCResultsFor' + filename + str(formatted_start_time2) + '.csv'\n",
    "print('◆　計算結果の出力先')\n",
    "print(filepath)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 現在時刻（計算開始時）\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time = start_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "formatted_start_time2 = start_time.strftime('%Y年%m月%d日 %H時%M分%')\n",
    "print(f'◆ Present Time (Start): {formatted_start_time}')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 各機械学習モデルの実行\n",
    "\n",
    "# データがそれほど大きくないとき\n",
    "if bigdata ==0:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_logistic_S = LogisticKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_N = LassoKFoldN(0.01)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_S = LassoKFoldS(0.01)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_N = RidgeKFoldN(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_S = RidgeKFoldS(1.0)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_SVM_S = SVMKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_RandomForest = RandomForestKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_XGBoost = XGBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_LightGBM = LightGBMKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "    res_list = [\n",
    "                res_linear,\n",
    "                res_logistic_N,\n",
    "                # res_logistic_S,\n",
    "                # res_lasso_N,\n",
    "                # res_lasso_S,\n",
    "                res_lasso_optuna_N,\n",
    "                # res_lasso_optuna_S,\n",
    "                # res_ridge_N,\n",
    "                # res_ridge_S,\n",
    "                res_ridge_optuna_N,\n",
    "                # res_ridge_optuna_S,\n",
    "                res_SVM_N,\n",
    "                # res_SVM_S,\n",
    "                # res_LDAn,\n",
    "                # res_LDAs,\n",
    "                # res_GaussianN,\n",
    "                # res_GaussianS,\n",
    "                # res_Gradient_Boosting,\n",
    "                res_Adaboost,\n",
    "                # res_RandomForest,\n",
    "                res_RandomForest_optuna,\n",
    "                # res_XGBoost,\n",
    "                res_XGBoost_optuna,\n",
    "                # res_LightGBM,\n",
    "                # res_LightGBM_optuna,\n",
    "                res_LightGBMTuner_optuna,\n",
    "                # res_CatBoost,\n",
    "                res_YDF,\n",
    "                # res_YDF_optuna,\n",
    "                res_MLPn,\n",
    "                # res_MLPs,\n",
    "                # res_TabNetN,\n",
    "                res_TabNetS,\n",
    "                # res_TabNetN_optuna,\n",
    "                # res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list], axis=0)\n",
    "    res_auc = [item[1] for item in res_list]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# データが大きいとき\n",
    "else:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_logistic_S = LogisticKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_N = LassoKFoldN(0.01)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_lasso_S = LassoKFoldS(0.01)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_N = RidgeKFoldN(1.0)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_ridge_S = RidgeKFoldS(1.0)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_SVM_N = SVMKFoldN()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_SVM_S = SVMKFoldS()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_RandomForest = RandomForestKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_XGBoost = XGBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_LightGBM = LightGBMKFold()\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "    res_list2 = [\n",
    "                res_linear,\n",
    "                res_logistic_N,\n",
    "                # res_logistic_S,\n",
    "                # res_lasso_N,\n",
    "                # res_lasso_S,\n",
    "                res_lasso_optuna_N,\n",
    "                # res_lasso_optuna_S,\n",
    "                # res_ridge_N,\n",
    "                # res_ridge_S,\n",
    "                res_ridge_optuna_N,\n",
    "                # res_ridge_optuna_S,\n",
    "                # res_SVM_N,\n",
    "                # res_SVM_S,\n",
    "                # res_LDAn,\n",
    "                # res_LDAs,\n",
    "                # res_GaussianN,\n",
    "                # res_GaussianS,\n",
    "                # res_Gradient_Boosting,\n",
    "                res_Adaboost,\n",
    "                # res_RandomForest,\n",
    "                res_RandomForest_optuna,\n",
    "                # res_XGBoost,\n",
    "                res_XGBoost_optuna,\n",
    "                # res_LightGBM,\n",
    "                # res_LightGBM_optuna,\n",
    "                res_LightGBMTuner_optuna,\n",
    "                # res_CatBoost,\n",
    "                res_YDF,\n",
    "                # res_YDF_optuna,\n",
    "                res_MLPn,\n",
    "                # res_MLPs,\n",
    "                # res_TabNetN,\n",
    "                res_TabNetS,\n",
    "                # res_TabNetN_optuna,\n",
    "                # res_TabNetS_optuna\n",
    "]\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list2], axis=0)\n",
    "    res_auc = [item[1] for item in res_list2]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# プロットの準備\n",
    "plt.figure(figsize=(14, 10))  # 図のサイズを少し大きく設定\n",
    "\n",
    "# AUCが大きい順にデータをソート。res_auc の各エントリは (fpr, tpr, auc, name) の形式\n",
    "data_sorted = sorted(res_auc, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 最もAUCが高いエントリを取得\n",
    "if data_sorted:\n",
    "    top_auc = data_sorted[0][2]\n",
    "else:\n",
    "    top_auc = None\n",
    "\n",
    "# 各エントリをループしてプロット\n",
    "for idx, entry in enumerate(data_sorted):\n",
    "    fpr, tpr, auc, name = entry\n",
    "    # NaNが含まれているエントリはスキップ\n",
    "    if np.isnan(auc) or np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "        continue\n",
    "    # 最もAUCが高いエントリは太くプロット\n",
    "    if idx == 0:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=3.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=1.5)\n",
    "\n",
    "# 対角線のプロット\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='random prediction')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curves Comparison', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# アスペクト比を1に設定\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 軸の範囲を0から1に設定\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 凡例を図の右側外側に配置\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop=font_prop)\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_plot_path = os.path.join(path_figure, \"all_ROC_curves.png\")\n",
    "plt.savefig(roc_plot_path, bbox_inches='tight')\n",
    "\n",
    "print('')\n",
    "print(\"■ Figure overlaying all the ROC curves by all the ML models\")\n",
    "print('')\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('')\n",
    "print(f\"■ All the ROC curves saved to: {roc_plot_path}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 計算終了時の現在時刻\n",
    "end_time = datetime.now()\n",
    "formatted_end_time = end_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "print(f'◆ Present Time (End): {formatted_end_time}')\n",
    "\n",
    "# 計算に要した時間（終了時刻 - 開始時刻）\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 時間、分、秒に分割して表示\n",
    "hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print('')\n",
    "print(f'計算に要した時間: {hours} 時間, {minutes} 分, {seconds} 秒')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◆　計算結果の出力先')\n",
    "print('')\n",
    "print('1. 数値データ:   ' + path_table)\n",
    "print('')\n",
    "print('2. 画像データ:   ' + path_figure)\n",
    "print('')\n",
    "print('3. モデル:      ' + path_model)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ_u_qyIZEqX"
   },
   "source": [
    "## 3) 任意の機械学習モデル Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEU5gbHJZWEu"
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('■ 二値分類のFull Verson')\n",
    "print('')\n",
    "print(f'◆ The sample size of dataset: {n_samples}')\n",
    "print('')\n",
    "\n",
    "# 説明変数と目的変数を分離: Pandas形式\n",
    "X0 = df.iloc[:, :-1]\n",
    "y0 = df.iloc[:, -1]\n",
    "\n",
    "# データの大きさ\n",
    "print('◆　行と列の数')\n",
    "rows, cols = df.shape\n",
    "print(f'データの行数(サンプル数) {rows},  データの列数(説明変数＋目的変数の数) {cols}')\n",
    "if rows >= 5000 or cols >= 5000:\n",
    "    bigdata = 1\n",
    "    print('')\n",
    "    print('◇ データは Big Data のため、Random Forest と LightGBM への Optuna適用 と CatBoost の利用が省かれる。')\n",
    "elif rows < 5000 and cols < 5000:\n",
    "    bigdata = 0\n",
    "    print('')\n",
    "    print('◇ データは Big Data ではないため、Optuna は適用可能なモデルには適用する。')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "# データの分割数 k\n",
    "print(f\"◆ Chosen value of k for k-fold cross-validation: {k}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# 目的変数の分布の表示\n",
    "print('◆　目的変数の分布')\n",
    "sns.displot(df.iloc[:,-1].dropna())\n",
    "print('　　　　　陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %')\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "\n",
    "# データの線形性の確認\n",
    "\n",
    "# 線形回帰モデルによる決定係数R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# (二値分類のため)Logistic回帰モデルによる擬似決定係数R2: NagelkerkeのR2 (Cox-Snellの擬似R2を0〜1にscalingしたもの)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def nagelkerke_r2(X, y, **logistic_kwargs):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "    y: array-like of shape (n_samples,), binary target (0 or 1)\n",
    "    logistic_kwargs:\n",
    "        追加の LogisticRegression 引数（solver, C, penalty など）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Nagelkerke の R²\n",
    "    \"\"\"\n",
    "    # 1) モデルのフィッティング\n",
    "    model = LogisticRegression(**logistic_kwargs)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 2) 予測確率（正クラス）の取得\n",
    "    p = model.predict_proba(X)[:, 1]\n",
    "    # log(0) を防ぐため eps 分だけクリップ\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # 3) フルモデルの対数尤度\n",
    "    ll_model = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # 4) ヌルモデル（切片のみ、常に y の平均を予測）の対数尤度\n",
    "    p_null = np.clip(np.mean(y), eps, 1 - eps)\n",
    "    ll_null = np.sum(y * np.log(p_null) + (1 - y) * np.log(1 - p_null))\n",
    "\n",
    "    # 5) Cox–Snell の R²\n",
    "    n = len(y)\n",
    "    r2_cs = 1 - np.exp((ll_null - ll_model) * 2 / n)\n",
    "\n",
    "    # 6) Nagelkerke の R²\n",
    "    r2_nagelkerke = r2_cs / (1 - np.exp(2 * ll_null / n))\n",
    "\n",
    "    return r2_nagelkerke\n",
    "\n",
    "pseudo_r2 = nagelkerke_r2(\n",
    "    X, y,\n",
    "    penalty='l2',     # リッジ（L2）正則化\n",
    "    C=1.0,            # デフォルト付近からスタート\n",
    "    solver='lbfgs',   # 中小規模向き\n",
    "    max_iter=500,     # 収束用に少し余裕を\n",
    "    tol=1e-6,          # 精度重視\n",
    "    class_weight='balanced' # Imbalanced Dataにも対応\n",
    ")\n",
    "\n",
    "\n",
    "print(f'◆　説明変数と目的変数の間の決定係数R2')\n",
    "print('')\n",
    "print(f'◇ Nagelkerke の擬似R² (標準設定) = {pseudo_r2:.4f}')\n",
    "print(f'  擬似決係数R²の見方　0.2未満: 弱い説明力、0.2〜0.5: 中程度の説明力、0.5以上: 強い説明力')\n",
    "print('')\n",
    "print(f'◇ 線形回帰による決定係数R² = {r2:.4f}')\n",
    "print('   決定係数R²の見方　 0.3未満: 線形性なし、0.3〜0.5: 弱い線形性、0.5〜0.7: 中程度の線形性、0.7〜0.9: 強い線形性、0.9以上: 完全に線形')\n",
    "print('')\n",
    "print('  (擬似決係数R² > 0.5　または  決定係数R² > 0.7 のとき、線形性があると見なせる。二値分類では擬似R²の方が妥当)')\n",
    "print('')\n",
    "if pseudo_r2 >= 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性が見られるため、SVM の kernel と XGBoost の booster を線形にする。')\n",
    "    linear = 1\n",
    "elif pseudo_r2 < 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性はそれほど見られないため、線形モデルの優先は行わない。')\n",
    "    linear = 0\n",
    "print('')\n",
    "print(f'linear = {linear:.1f}')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 残差プロット\n",
    "print('◆　線形モデルによる目的変数の予測値の残差プロット')\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('予測値', fontproperties=font_prop)\n",
    "plt.ylabel('残差', fontproperties=font_prop)\n",
    "plt.title('予測値と残差のプロット', fontproperties=font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 連続変数の場合の線形性の判定\n",
    "\n",
    "# # RESET（Regression Specification Error Test）\n",
    "# from statsmodels.stats.diagnostic import linear_reset\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# ols = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "# print(linear_reset(ols, power=2))\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 線形モデル vs 多項式モデル（2次項・3次項を加えたモデル）\n",
    "# poly2 = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "# score_lin = cross_val_score(LinearRegression(), X, y, cv=5, scoring=\"r2\").mean()\n",
    "# score_poly2 = cross_val_score(poly2, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "# print(\"線形モデル R²:\", score_lin)\n",
    "# print(\"2次多項式モデル R²:\", score_poly2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 定数列を除外する関数\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_columns:\n",
    "        print(f'以下の定数列を除外します: {constant_columns}')\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    else:\n",
    "        print('定数列は存在しません。')\n",
    "    return df\n",
    "\n",
    "# 欠損値を確認・除外する関数\n",
    "def check_missing_values(df_X, df_y):\n",
    "    missing_X = df_X.isnull().sum()\n",
    "    missing_y = df_y.isnull().sum()\n",
    "    if missing_X.sum() > 0:\n",
    "        print('説明変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_X = df_X.dropna()\n",
    "    if missing_y > 0:\n",
    "        print('目的変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_y = df_y.dropna()\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "print('◆ 説明変数と目的変数のPearsonの相関係数: 線形な相関のみ')\n",
    "# 定数列の除外\n",
    "X0 = remove_constant_columns(X0)\n",
    "\n",
    "# 目的変数が定数か確認\n",
    "if y0.nunique() <= 1:\n",
    "    raise ValueError('目的変数 y0 が定数列です。相関係数を計算できません。')\n",
    "\n",
    "# 欠損値の除外\n",
    "X0, y0 = check_missing_values(X0, y0)\n",
    "\n",
    "\n",
    "# 各説明変数と目的変数との相関係数を計算\n",
    "correlations = {}\n",
    "for column in X0.columns:\n",
    "    correlations[column] = X0[column].corr(y0)\n",
    "\n",
    "# 相関係数をSeriesに変換\n",
    "correlation_series = pd.Series(correlations)\n",
    "\n",
    "# 絶対値の降順にソートし、元の符号を保持\n",
    "top_10_correlations = correlation_series.reindex(correlation_series.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Top 10の相関係数を昇べき順にソート\n",
    "sorted_top_10_correlations = top_10_correlations.sort_values(ascending=True)\n",
    "\n",
    "# 色を決定\n",
    "colors = ['skyblue' if val > 0 else 'lightcoral' for val in correlation_series.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(correlation_series.index, correlation_series.values, color=colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "\n",
    "print('□ 青は正の相関、赤は負の相関。　1に近いほど強い正の相関、-1に近いほど強い負の相関。0は線形での相関無し')\n",
    "print('□　　相関係数の絶対値Cの目安： C > 0.7 強い相関、0.4〜0.7 中程度の相関、0.2〜0.4 弱い相関　　C < 0.2 相関無し')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のPearsonの相関係数: 相関係数のTop 10 のみ')\n",
    "\n",
    "# Top 10 correlation colors\n",
    "top_10_colors = ['skyblue' if val > 0 else 'lightcoral' for val in sorted_top_10_correlations.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_top_10_correlations.index, sorted_top_10_correlations.values, color=top_10_colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Top 10 Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# XiCorの相関係数のプロット関数\n",
    "print('◆ 説明変数と目的変数のChatterjee`sの相関係数: 非線形な相関も含む (参考値)')\n",
    "\n",
    "def xicor(x, y, ties=True):\n",
    "    np.random.seed(42)\n",
    "    n = len(x)\n",
    "    order = np.argsort(x)\n",
    "    ranked_y = np.argsort(np.argsort(y[order], kind='mergesort'))\n",
    "\n",
    "    if ties:\n",
    "        l = np.argsort(np.argsort(y[order], kind='max'))\n",
    "        r = ranked_y.copy()\n",
    "        return 1 - n * np.sum(np.abs(r[1:] - r[:-1])) / (2 * np.sum(l * (n - l)))\n",
    "    else:\n",
    "        return 1 - 3 * np.sum(np.abs(ranked_y[1:] - ranked_y[:-1])) / (n**2 - 1)\n",
    "\n",
    "def plot_xicor(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor(df)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のChatterjee`sの相関係数: 相関係数のTop 10 のみ')\n",
    "def plot_xicor10(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)[-10:]  # 上位10の特徴量を選択\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # グラフのサイズを調整\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('Top 10 XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor10(df)\n",
    "print('')\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thttps://arxiv.org/abs/1909.10140 参照')\n",
    "print('')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time2 = start_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# 出力ファイル\n",
    "filename0 = os.path.basename(path_table)\n",
    "filename = os.path.splitext(filename0)[0]\n",
    "filepath = path_table + '/AllEvaluationResultsFor' + filename + str(formatted_start_time2) + '.xlsx'\n",
    "filepath2 = path_table + '/AllAUCResultsFor' + filename + str(formatted_start_time2) + '.csv'\n",
    "print('◆　計算結果の出力先')\n",
    "print(filepath)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 現在時刻（計算開始時）\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time = start_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "formatted_start_time2 = start_time.strftime('%Y年%m月%d日 %H時%M分%')\n",
    "print(f'◆ Present Time (Start): {formatted_start_time}')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 各機械学習モデルの実行\n",
    "\n",
    "# 32種類の機械学習モデルの名称と実行用関数を、番号とともに辞書で定義します\n",
    "models = {\n",
    "    1:  {\"name\": \"LinearKFold\",                  \"func\": lambda: LinearKFold()},\n",
    "    2:  {\"name\": \"LogisticKFoldN\",               \"func\": lambda: LogisticKFoldN()},\n",
    "    3:  {\"name\": \"LogisticKFoldS\",               \"func\": lambda: LogisticKFoldS()},\n",
    "    4:  {\"name\": \"LassoKFoldN (0.01)\",           \"func\": lambda: LassoKFoldN(0.01)},\n",
    "    5:  {\"name\": \"LassoKFoldS (0.01)\",           \"func\": lambda: LassoKFoldS(0.01)},\n",
    "    6:  {\"name\": \"LassoKFoldOptunaN\",            \"func\": lambda: LassoKFoldOptunaN()},\n",
    "    7:  {\"name\": \"LassoKFoldOptunaS\",            \"func\": lambda: LassoKFoldOptunaS()},\n",
    "    8:  {\"name\": \"RidgeKFoldN (1.0)\",            \"func\": lambda: RidgeKFoldN(1.0)},\n",
    "    9:  {\"name\": \"RidgeKFoldS (1.0)\",            \"func\": lambda: RidgeKFoldS(1.0)},\n",
    "    10: {\"name\": \"RidgeKFoldOptunaN\",            \"func\": lambda: RidgeKFoldOptunaN()},\n",
    "    11: {\"name\": \"RidgeKFoldOptunaS\",            \"func\": lambda: RidgeKFoldOptunaS()},\n",
    "    12: {\"name\": \"SVMKFoldN\",                    \"func\": lambda: SVMKFoldN()},\n",
    "    13: {\"name\": \"SVMKFoldS\",                    \"func\": lambda: SVMKFoldS()},\n",
    "    14: {\"name\": \"LinearDiscriminantAnalysisKFold Normalized\", \"func\": lambda: LinearDiscriminantAnalysisKFold(scaler='norm')},\n",
    "    15: {\"name\": \"LinearDiscriminantAnalysisKFold Standard\",   \"func\": lambda: LinearDiscriminantAnalysisKFold(scaler='stand')},\n",
    "    16: {\"name\": \"GausseanProcessKFold Normalized\",            \"func\": lambda: GaussianProcessKFold(scaler='norm')},\n",
    "    17: {\"name\": \"GausseanProcessKFold Standardized\",          \"func\": lambda: GaussianProcessKFold(scaler='stand')},\n",
    "    18: {\"name\": \"GradientBoostingKFold\",        \"func\": lambda: GradientBoostingKFold()},\n",
    "    19: {\"name\": \"AdaBoostKFold\",                \"func\": lambda: AdaBoostKFold()},\n",
    "    20: {\"name\": \"RandomForestKFold\",            \"func\": lambda: RandomForestKFold()},\n",
    "    21: {\"name\": \"RandomForestOptunaKFold\",      \"func\": lambda: RandomForestOptunaKFold()},\n",
    "    22: {\"name\": \"XGBoostKFold\",                 \"func\": lambda: XGBoostKFold()},\n",
    "    23: {\"name\": \"XGBoostOptunaKFold\",           \"func\": lambda: XGBoostOptunaKFold()},\n",
    "    24: {\"name\": \"LightGBMKFold\",                \"func\": lambda: LightGBMKFold()},\n",
    "    25: {\"name\": \"LightGBMOptunaKFold\",          \"func\": lambda: LightGBMOptunaKFold()},\n",
    "    26: {\"name\": \"LightGBMTunerOptunaKFold\",     \"func\": lambda: LightGBMTunerOptunaKFold()},\n",
    "    27: {\"name\": \"CatBoostKFold\",                \"func\": lambda: CatBoostKFold()},\n",
    "    28: {\"name\": \"YDFKFold\",                     \"func\": lambda: YggdrasilDecisionForestKFold()},\n",
    "    29: {\"name\": \"YDFKFoldOptuna\",               \"func\": lambda: YggdrasilDecisionForestOptunaKFold()},\n",
    "    30: {\"name\": \"MLPKFoldN\",                    \"func\": lambda: MLPKFold(n1=128, n2=32, max_iter=500, scaler='norm')},\n",
    "    31: {\"name\": \"MLPKFoldS\",                    \"func\": lambda: MLPKFold(n1=128, n2=32, max_iter=500, scaler='stand')},\n",
    "    32: {\"name\": \"TabNetKFoldN\",                 \"func\": lambda: TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)},\n",
    "    33: {\"name\": \"TabNetKFoldS\",                 \"func\": lambda: TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)},\n",
    "    34: {\"name\": \"TabNetOptunaKFoldN\",           \"func\": lambda: TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)},\n",
    "    35: {\"name\": \"TabNetOptunaKFoldS\",           \"func\": lambda: TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)}\n",
    "}\n",
    "\n",
    "\n",
    "print('')\n",
    "# bigdata == 1 の場合、CatBoostKFold (キー: 20) を削除\n",
    "if bigdata == 1 and 21 in models:\n",
    "    sample_num = len(df)\n",
    "    del models[20]\n",
    "    if cols >= 5000 and rows < 5000:\n",
    "        print(f'□ サンプル数({cols})が5000以上のため、CatBoostモデルは削除されました。')\n",
    "    elif cols < 5000 and rows >= 5000:\n",
    "        print(f'□ 説明変数の数({rows})が5000以上のため、CatBoostモデルは削除されました。')\n",
    "    elif cols >= 5000 and rows >= 5000:\n",
    "        print(f'□ サンプル数({cols})も説明変数の数({rows})も共に5000以上のため、CatBoostモデルは削除されました。')\n",
    "else:\n",
    "    print(f'□ サンプル数({cols})も説明変数の数({rows})も共に5000未満のため、CatBoostモデルも候補に入れます。')\n",
    "print('')\n",
    "\n",
    "# まず、27種類のモデル一覧を表示します\n",
    "print('')\n",
    "print(\"■ 実行可能な機械学習モデル一覧:\")\n",
    "print('')\n",
    "for key in sorted(models.keys()):\n",
    "    print(f\"{key}: {models[key]['name']}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# ユーザーに、実行したいモデルの番号をカンマ区切りで入力してもらいます\n",
    "selected_input = input(\"\\n■ 実行したいモデルの番号をカンマ区切りで入力してください。    例 1,3,7,11,17,19   　(見えない場合は左にスライドする)\")\n",
    "\n",
    "# 入力文字列をパースして、整数のリストに変換します\n",
    "try:\n",
    "    selected_numbers = [int(num.strip()) for num in selected_input.split(',') if num.strip()]\n",
    "except ValueError:\n",
    "    print(\"入力の形式が正しくありません。整数をカンマ区切りで入力してください。\")\n",
    "    raise\n",
    "print('')\n",
    "\n",
    "\n",
    "# 入力された番号が有効かチェックします\n",
    "invalid_numbers = [num for num in selected_numbers if num not in models]\n",
    "if invalid_numbers:\n",
    "    print(f\"無効な番号が含まれています: {invalid_numbers}\")\n",
    "    raise ValueError(\"無効な番号が含まれています。\")\n",
    "else:\n",
    "    print(\"◇ 入力されたすべての番号が有効です。\")\n",
    "    print(f'　　入力された番号: {selected_numbers}')\n",
    "    print('    選択されたモデル:')\n",
    "    for num in selected_numbers:\n",
    "        print(f'  {num}: {models[num][\"name\"]}')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 選択されたモデルのみを実行し、その結果をリストに格納します\n",
    "results_list = []\n",
    "auc_list = []  # 各モデルから返される[1]要素を格納するリスト\n",
    "for num in selected_numbers:\n",
    "    print(\"\\n\" + \"=\"*180)\n",
    "    print(f\"□ モデル {num}: {models[num]['name']} を実行中...\")\n",
    "    # 関数を呼び出して結果を取得\n",
    "    res = models[num]['func']()\n",
    "    # 戻り値は (結果DataFrame, auc値) と仮定\n",
    "    results_list.append(res[0])\n",
    "    auc_list.append(res[1])\n",
    "    print(f\"□ モデル {num}: {models[num]['name']} の実行が完了しました。\")\n",
    "    print(\"=\"*180)\n",
    "    print('')\n",
    "    print('')\n",
    "    print('')\n",
    "\n",
    "# 全ての結果DataFrameを結合し、Excelファイルに出力します\n",
    "final_results = pd.concat(results_list, axis=0)\n",
    "final_results.to_excel(filepath)\n",
    "print(\"\\nすべての選択されたモデルの結果がExcelファイルに出力されました。\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# すべてのROC曲線のプロットの準備\n",
    "plt.figure(figsize=(14, 10))  # 図のサイズを少し大きく設定\n",
    "\n",
    "# AUCが大きい順にデータをソート。res_auc の各エントリは (fpr, tpr, auc, name) の形式\n",
    "data_sorted = sorted(auc_list, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 最もAUCが高いエントリを取得\n",
    "if data_sorted:\n",
    "    top_auc = data_sorted[0][2]\n",
    "else:\n",
    "    top_auc = None\n",
    "\n",
    "# 各エントリをループしてプロット\n",
    "for idx, entry in enumerate(data_sorted):\n",
    "    fpr, tpr, auc, name = entry\n",
    "    # NaNが含まれているエントリはスキップ\n",
    "    if np.isnan(auc) or np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "        continue\n",
    "    # 最もAUCが高いエントリは太くプロット\n",
    "    if idx == 0:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=3.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=1.5)\n",
    "\n",
    "# 対角線のプロット\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='random prediction')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curves Comparison', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# アスペクト比を1に設定\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 軸の範囲を0から1に設定\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 凡例を図の右側外側に配置\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop=font_prop)\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_plot_path = os.path.join(path_figure, \"all_ROC_curves.png\")\n",
    "plt.savefig(roc_plot_path, bbox_inches='tight')\n",
    "\n",
    "print('')\n",
    "print(\"■ Figure overlaying all the ROC curves by all the ML models\")\n",
    "print('')\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('')\n",
    "print(f\"■ All the ROC curves saved to: {roc_plot_path}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 計算終了時の現在時刻\n",
    "end_time = datetime.now()\n",
    "formatted_end_time = end_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "print(f'◆ Present Time (End): {formatted_end_time}')\n",
    "\n",
    "# 計算に要した時間（終了時刻 - 開始時刻）\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 時間、分、秒に分割して表示\n",
    "hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print('')\n",
    "print(f'計算に要した時間: {hours} 時間, {minutes} 分, {seconds} 秒')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◆　計算結果の出力先')\n",
    "print('')\n",
    "print('1. 数値データ:   ' + path_table)\n",
    "print('')\n",
    "print('2. 画像データ:   ' + path_figure)\n",
    "print('')\n",
    "print('3. モデル:      ' + path_model)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDlBFqFsugkP"
   },
   "source": [
    "## 4) Full Set without TabNetOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ZyVM2VEuoiL"
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('■ 二値分類のFull Verson')\n",
    "print('')\n",
    "print(f'◆ The sample size of dataset: {n_samples}')\n",
    "print('')\n",
    "\n",
    "# 説明変数と目的変数を分離: Pandas形式\n",
    "X0 = df.iloc[:, :-1]\n",
    "y0 = df.iloc[:, -1]\n",
    "\n",
    "# データの大きさ\n",
    "print('◆　行と列の数')\n",
    "rows, cols = df.shape\n",
    "print(f'データの行数(サンプル数) {rows},  データの列数(説明変数＋目的変数の数) {cols}')\n",
    "if rows >= 5000 or cols >= 5000:\n",
    "    bigdata = 1\n",
    "    print('')\n",
    "    print('◇ データは Big Data のため、Random Forest と LightGBM への Optuna適用 と CatBoost の利用が省かれる。')\n",
    "elif rows < 5000 and cols < 5000:\n",
    "    bigdata = 0\n",
    "    print('')\n",
    "    print('◇ データは Big Data ではないため、Optuna は適用可能なモデルには適用する。')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "# データの分割数 k\n",
    "print(f\"◆ Chosen value of k for k-fold cross-validation: {k}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# 目的変数の分布の表示\n",
    "print('◆　目的変数の分布')\n",
    "sns.displot(df.iloc[:,-1].dropna())\n",
    "print('　　　　　陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %')\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データの線形性の確認\n",
    "\n",
    "# 線形回帰モデルによる決定係数R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# (二値分類のため)Logistic回帰モデルによる擬似決定係数R2: NagelkerkeのR2 (Cox-Snellの擬似R2を0〜1にscalingしたもの)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def nagelkerke_r2(X, y, **logistic_kwargs):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "    y: array-like of shape (n_samples,), binary target (0 or 1)\n",
    "    logistic_kwargs:\n",
    "        追加の LogisticRegression 引数（solver, C, penalty など）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Nagelkerke の R²\n",
    "    \"\"\"\n",
    "    # 1) モデルのフィッティング\n",
    "    model = LogisticRegression(**logistic_kwargs)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 2) 予測確率（正クラス）の取得\n",
    "    p = model.predict_proba(X)[:, 1]\n",
    "    # log(0) を防ぐため eps 分だけクリップ\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # 3) フルモデルの対数尤度\n",
    "    ll_model = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # 4) ヌルモデル（切片のみ、常に y の平均を予測）の対数尤度\n",
    "    p_null = np.clip(np.mean(y), eps, 1 - eps)\n",
    "    ll_null = np.sum(y * np.log(p_null) + (1 - y) * np.log(1 - p_null))\n",
    "\n",
    "    # 5) Cox–Snell の R²\n",
    "    n = len(y)\n",
    "    r2_cs = 1 - np.exp((ll_null - ll_model) * 2 / n)\n",
    "\n",
    "    # 6) Nagelkerke の R²\n",
    "    r2_nagelkerke = r2_cs / (1 - np.exp(2 * ll_null / n))\n",
    "\n",
    "    return r2_nagelkerke\n",
    "\n",
    "pseudo_r2 = nagelkerke_r2(\n",
    "    X, y,\n",
    "    penalty='l2',     # リッジ（L2）正則化\n",
    "    C=1.0,            # デフォルト付近からスタート\n",
    "    solver='lbfgs',   # 中小規模向き\n",
    "    max_iter=500,     # 収束用に少し余裕を\n",
    "    tol=1e-6,          # 精度重視\n",
    "    class_weight='balanced' # Imbalanced Dataにも対応\n",
    ")\n",
    "\n",
    "\n",
    "print(f'◆　説明変数と目的変数の間の決定係数R2')\n",
    "print('')\n",
    "print(f'◇ Nagelkerke の擬似R² (標準設定) = {pseudo_r2:.4f}')\n",
    "print(f'  擬似決係数R²の見方　0.2未満: 弱い説明力、0.2〜0.5: 中程度の説明力、0.5以上: 強い説明力')\n",
    "print('')\n",
    "print(f'◇ 線形回帰による決定係数R² = {r2:.4f}')\n",
    "print('   決定係数R²の見方　 0.3未満: 線形性なし、0.3〜0.5: 弱い線形性、0.5〜0.7: 中程度の線形性、0.7〜0.9: 強い線形性、0.9以上: 完全に線形')\n",
    "print('')\n",
    "print('  (擬似決係数R² > 0.5　または  決定係数R² > 0.7 のとき、線形性があると見なせる。二値分類では擬似R²の方が妥当)')\n",
    "print('')\n",
    "if pseudo_r2 >= 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性が見られるため、SVM の kernel と XGBoost の booster を線形にする。')\n",
    "    linear = 1\n",
    "elif pseudo_r2 < 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性はそれほど見られないため、線形モデルの優先は行わない。')\n",
    "    linear = 0\n",
    "print('')\n",
    "print(f'linear = {linear:.1f}')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 残差プロット\n",
    "print('◆　線形モデルによる目的変数の予測値の残差プロット')\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('予測値', fontproperties=font_prop)\n",
    "plt.ylabel('残差', fontproperties=font_prop)\n",
    "plt.title('予測値と残差のプロット', fontproperties=font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 連続変数の場合の線形性の判定\n",
    "\n",
    "# # RESET（Regression Specification Error Test）\n",
    "# from statsmodels.stats.diagnostic import linear_reset\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# ols = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "# print(linear_reset(ols, power=2))\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 線形モデル vs 多項式モデル（2次項・3次項を加えたモデル）\n",
    "# poly2 = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "# score_lin = cross_val_score(LinearRegression(), X, y, cv=5, scoring=\"r2\").mean()\n",
    "# score_poly2 = cross_val_score(poly2, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "# print(\"線形モデル R²:\", score_lin)\n",
    "# print(\"2次多項式モデル R²:\", score_poly2)\n",
    "\n",
    "\n",
    "\n",
    "# 定数列を除外する関数\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_columns:\n",
    "        print(f'以下の定数列を除外します: {constant_columns}')\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    else:\n",
    "        print('定数列は存在しません。')\n",
    "    return df\n",
    "\n",
    "# 欠損値を確認・除外する関数\n",
    "def check_missing_values(df_X, df_y):\n",
    "    missing_X = df_X.isnull().sum()\n",
    "    missing_y = df_y.isnull().sum()\n",
    "    if missing_X.sum() > 0:\n",
    "        print('説明変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_X = df_X.dropna()\n",
    "    if missing_y > 0:\n",
    "        print('目的変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_y = df_y.dropna()\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "print('◆ 説明変数と目的変数のPearsonの相関係数: 線形な相関のみ')\n",
    "# 定数列の除外\n",
    "X0 = remove_constant_columns(X0)\n",
    "\n",
    "# 目的変数が定数か確認\n",
    "if y0.nunique() <= 1:\n",
    "    raise ValueError('目的変数 y0 が定数列です。相関係数を計算できません。')\n",
    "\n",
    "# 欠損値の除外\n",
    "X0, y0 = check_missing_values(X0, y0)\n",
    "\n",
    "\n",
    "# 各説明変数と目的変数との相関係数を計算\n",
    "correlations = {}\n",
    "for column in X0.columns:\n",
    "    correlations[column] = X0[column].corr(y0)\n",
    "\n",
    "# 相関係数をSeriesに変換\n",
    "correlation_series = pd.Series(correlations)\n",
    "\n",
    "# 絶対値の降順にソートし、元の符号を保持\n",
    "top_10_correlations = correlation_series.reindex(correlation_series.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Top 10の相関係数を昇べき順にソート\n",
    "sorted_top_10_correlations = top_10_correlations.sort_values(ascending=True)\n",
    "\n",
    "# 色を決定\n",
    "colors = ['skyblue' if val > 0 else 'lightcoral' for val in correlation_series.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(correlation_series.index, correlation_series.values, color=colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "\n",
    "print('□ 青は正の相関、赤は負の相関。　1に近いほど強い正の相関、-1に近いほど強い負の相関。0は線形での相関無し')\n",
    "print('□　　相関係数の絶対値Cの目安： C > 0.7 強い相関、0.4〜0.7 中程度の相関、0.2〜0.4 弱い相関　　C < 0.2 相関無し')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のPearsonの相関係数: 相関係数のTop 10 のみ')\n",
    "\n",
    "# Top 10 correlation colors\n",
    "top_10_colors = ['skyblue' if val > 0 else 'lightcoral' for val in sorted_top_10_correlations.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_top_10_correlations.index, sorted_top_10_correlations.values, color=top_10_colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Top 10 Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# XiCorの相関係数のプロット関数\n",
    "print('◆ 説明変数と目的変数のChatterjee`sの相関係数: 非線形な相関も含む (参考値)')\n",
    "\n",
    "def xicor(x, y, ties=True):\n",
    "    np.random.seed(42)\n",
    "    n = len(x)\n",
    "    order = np.argsort(x)\n",
    "    ranked_y = np.argsort(np.argsort(y[order], kind='mergesort'))\n",
    "\n",
    "    if ties:\n",
    "        l = np.argsort(np.argsort(y[order], kind='max'))\n",
    "        r = ranked_y.copy()\n",
    "        return 1 - n * np.sum(np.abs(r[1:] - r[:-1])) / (2 * np.sum(l * (n - l)))\n",
    "    else:\n",
    "        return 1 - 3 * np.sum(np.abs(ranked_y[1:] - ranked_y[:-1])) / (n**2 - 1)\n",
    "\n",
    "def plot_xicor(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor(df)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のChatterjee`sの相関係数: 相関係数のTop 10 のみ')\n",
    "def plot_xicor10(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)[-10:]  # 上位10の特徴量を選択\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # グラフのサイズを調整\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('Top 10 XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor10(df)\n",
    "print('')\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thttps://arxiv.org/abs/1909.10140 参照')\n",
    "print('')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time2 = start_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# 出力ファイル\n",
    "filename0 = os.path.basename(path_table)\n",
    "filename = os.path.splitext(filename0)[0]\n",
    "filepath = path_table + '/AllEvaluationResultsFor' + filename + str(formatted_start_time2) + '.xlsx'\n",
    "filepath2 = path_table + '/AllAUCResultsFor' + filename + str(formatted_start_time2) + '.csv'\n",
    "print('◆　計算結果の出力先')\n",
    "print(filepath)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 現在時刻（計算開始時）\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time = start_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "formatted_start_time2 = start_time.strftime('%Y年%m月%d日 %H時%M分%')\n",
    "print(f'◆ Present Time (Start): {formatted_start_time}')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 各機械学習モデルの実行\n",
    "\n",
    "# データがそれほど大きくないとき。TabNet Optunaは外してある\n",
    "if bigdata ==0:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_S = LogisticKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_S = LassoKFoldS(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_N = RidgeKFoldN(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_S = RidgeKFoldS(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_S = SVMKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_CatBoost = CatBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "\n",
    "    res_list = [\n",
    "                res_linear,\n",
    "                                res_logistic_N,\n",
    "                                res_logistic_S,\n",
    "                                res_lasso_N,\n",
    "                                res_lasso_S,\n",
    "                                res_lasso_optuna_N,\n",
    "                                res_lasso_optuna_S,\n",
    "                                res_ridge_N,\n",
    "                                res_ridge_S,\n",
    "                                res_ridge_optuna_N,\n",
    "                                res_ridge_optuna_S,\n",
    "                                res_SVM_N,\n",
    "                                res_SVM_S,\n",
    "                                res_LDAn,\n",
    "                                res_LDAs,\n",
    "                                res_GaussianN,\n",
    "                                res_GaussianS,\n",
    "                                res_Gradient_Boosting,\n",
    "                                res_Adaboost,\n",
    "                                res_RandomForest,\n",
    "                                res_RandomForest_optuna,\n",
    "                                res_XGBoost,\n",
    "                                res_XGBoost_optuna,\n",
    "                                res_LightGBM,\n",
    "                                res_LightGBM_optuna,\n",
    "                                res_LightGBMTuner_optuna,\n",
    "                                res_CatBoost,\n",
    "                                res_YDF,\n",
    "                                res_YDF_optuna,\n",
    "                                res_MLPn,\n",
    "                                res_MLPs,\n",
    "                                res_TabNetN,\n",
    "                                res_TabNetS,\n",
    "                                # res_TabNetN_optuna,\n",
    "                                # res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    # res_listの最初の要素を表計算のための出力とする\n",
    "    results = pd.concat([item[0] for item in res_list], axis=0)\n",
    "    res_auc = [item[1] for item in res_list]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# データが大きいとき\n",
    "else:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_S = LogisticKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_S= LassoKFoldS(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_N = RidgeKFoldN(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_S = RidgeKFoldS(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_S = SVMKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFoldN(n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPs = MLPKFoldS(n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=64)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=64)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "    # CatBoostとTabNet Optunaは長時間かかるため外してある。\n",
    "    res_list2 = [\n",
    "                res_linear,\n",
    "                res_logistic_N,\n",
    "                res_logistic_S,\n",
    "                res_lasso_N,\n",
    "                res_lasso_S,\n",
    "                res_lasso_optuna_N,\n",
    "                res_lasso_optuna_S,\n",
    "                res_ridge_N,\n",
    "                res_ridge_S,\n",
    "                res_ridge_optuna_N,\n",
    "                res_ridge_optuna_S,\n",
    "                res_SVM_N,\n",
    "                res_SVM_S,\n",
    "                res_LDAn,\n",
    "                res_LDAs,\n",
    "                res_GaussianN,\n",
    "                res_GaussianS,\n",
    "                res_Gradient_Boosting,\n",
    "                res_Adaboost,\n",
    "                res_RandomForest,\n",
    "                res_RandomForest_optuna,\n",
    "                res_XGBoost,\n",
    "                res_XGBoost_optuna,\n",
    "                res_LightGBM,\n",
    "                res_LightGBM_optuna,\n",
    "                res_LightGBMTuner_optuna,\n",
    "            #  res_CatBoost,\n",
    "                res_YDF,\n",
    "                res_YDF_optuna,\n",
    "                res_MLPn,\n",
    "                res_MLPs,\n",
    "                res_TabNetN,\n",
    "                res_TabNetS,\n",
    "            #  res_TabNetN_optuna,\n",
    "            #  res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list2], axis=0)\n",
    "    res_auc = [item[1] for item in res_list2]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# プロットの準備\n",
    "plt.figure(figsize=(14, 10))  # 図のサイズを少し大きく設定\n",
    "\n",
    "# AUCが大きい順にres_listの２番目のデータをソート。res_auc の各エントリは (fpr, tpr, auc, name) の形式\n",
    "data_sorted = sorted(res_auc, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 最もAUCが高いエントリを取得\n",
    "if data_sorted:\n",
    "    top_auc = data_sorted[0][2]\n",
    "else:\n",
    "    top_auc = None\n",
    "\n",
    "# 各エントリをループしてプロット\n",
    "for idx, entry in enumerate(data_sorted):\n",
    "    fpr, tpr, auc, name = entry\n",
    "    # NaNが含まれているエントリはスキップ\n",
    "    if np.isnan(auc) or np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "        continue\n",
    "    # 最もAUCが高いエントリは太くプロット\n",
    "    if idx == 0:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=3.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=1.5)\n",
    "\n",
    "# 対角線のプロット\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='random prediction')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curves Comparison', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# アスペクト比を1に設定\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 軸の範囲を0から1に設定\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 凡例を図の右側外側に配置\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop=font_prop)\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_plot_path = os.path.join(path_figure, \"all_ROC_curves.png\")\n",
    "plt.savefig(roc_plot_path, bbox_inches='tight')\n",
    "\n",
    "print('')\n",
    "print(\"■ Figure overlaying all the ROC curves by all the ML models\")\n",
    "print('')\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('')\n",
    "print(f\"■ All the ROC curves saved to: {roc_plot_path}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 計算終了時の現在時刻\n",
    "end_time = datetime.now()\n",
    "formatted_end_time = end_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "print(f'◆ Present Time (End): {formatted_end_time}')\n",
    "\n",
    "# 計算に要した時間（終了時刻 - 開始時刻）\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 時間、分、秒に分割して表示\n",
    "hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print('')\n",
    "print(f'計算に要した時間: {hours} 時間, {minutes} 分, {seconds} 秒')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◆　計算結果の出力先')\n",
    "print('')\n",
    "print('1. 数値データ:   ' + path_table)\n",
    "print('')\n",
    "print('2. 画像データ:   ' + path_figure)\n",
    "print('')\n",
    "print('3. モデル:      ' + path_model)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ugZAIIkKnK4"
   },
   "source": [
    "## 5) Full Set (機械学習の全モデル) ☜ GPUが必須"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGe608uTtChc"
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('■ 二値分類のFull Verson')\n",
    "print('')\n",
    "print(f'◆ The sample size of dataset: {n_samples}')\n",
    "print('')\n",
    "\n",
    "# 説明変数と目的変数を分離: Pandas形式\n",
    "X0 = df.iloc[:, :-1]\n",
    "y0 = df.iloc[:, -1]\n",
    "\n",
    "# データの大きさ\n",
    "print('◆　行と列の数')\n",
    "rows, cols = df.shape\n",
    "print(f'データの行数(サンプル数) {rows},  データの列数(説明変数＋目的変数の数) {cols}')\n",
    "if rows >= 5000 or cols >= 5000:\n",
    "    bigdata = 1\n",
    "    print('')\n",
    "    print('◇ データは Big Data のため、Random Forest と LightGBM への Optuna適用 と CatBoost の利用が省かれる。')\n",
    "elif rows < 5000 and cols < 5000:\n",
    "    bigdata = 0\n",
    "    print('')\n",
    "    print('◇ データは Big Data ではないため、Optuna は適用可能なモデルには適用する。')\n",
    "print('')\n",
    "\n",
    "print('')\n",
    "# データの分割数 k\n",
    "print(f\"◆ Chosen value of k for k-fold cross-validation: {k}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "# 目的変数の分布の表示\n",
    "print('◆　目的変数の分布')\n",
    "sns.displot(df.iloc[:,-1].dropna())\n",
    "print('　　　　　陽性症例の割合(事前確率): ' + str(round(100*(np.count_nonzero(y>0)/len(y)), 5)) + ' %')\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "# フォントファイルのパスを確認\n",
    "font_path = '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc'\n",
    "# フォントプロパティを設定\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# データの線形性の確認\n",
    "\n",
    "# 線形回帰モデルによる決定係数R2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "r2 = r2_score(y, y_pred)\n",
    "\n",
    "# (二値分類のため)Logistic回帰モデルによる擬似決定係数R2: NagelkerkeのR2 (Cox-Snellの擬似R2を0〜1にscalingしたもの)\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def nagelkerke_r2(X, y, **logistic_kwargs):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "    y: array-like of shape (n_samples,), binary target (0 or 1)\n",
    "    logistic_kwargs:\n",
    "        追加の LogisticRegression 引数（solver, C, penalty など）\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Nagelkerke の R²\n",
    "    \"\"\"\n",
    "    # 1) モデルのフィッティング\n",
    "    model = LogisticRegression(**logistic_kwargs)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 2) 予測確率（正クラス）の取得\n",
    "    p = model.predict_proba(X)[:, 1]\n",
    "    # log(0) を防ぐため eps 分だけクリップ\n",
    "    eps = np.finfo(float).eps\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # 3) フルモデルの対数尤度\n",
    "    ll_model = np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "\n",
    "    # 4) ヌルモデル（切片のみ、常に y の平均を予測）の対数尤度\n",
    "    p_null = np.clip(np.mean(y), eps, 1 - eps)\n",
    "    ll_null = np.sum(y * np.log(p_null) + (1 - y) * np.log(1 - p_null))\n",
    "\n",
    "    # 5) Cox–Snell の R²\n",
    "    n = len(y)\n",
    "    r2_cs = 1 - np.exp((ll_null - ll_model) * 2 / n)\n",
    "\n",
    "    # 6) Nagelkerke の R²\n",
    "    r2_nagelkerke = r2_cs / (1 - np.exp(2 * ll_null / n))\n",
    "\n",
    "    return r2_nagelkerke\n",
    "\n",
    "pseudo_r2 = nagelkerke_r2(\n",
    "    X, y,\n",
    "    penalty='l2',     # リッジ（L2）正則化\n",
    "    C=1.0,            # デフォルト付近からスタート\n",
    "    solver='lbfgs',   # 中小規模向き\n",
    "    max_iter=500,     # 収束用に少し余裕を\n",
    "    tol=1e-6,          # 精度重視\n",
    "    class_weight='balanced' # Imbalanced Dataにも対応\n",
    ")\n",
    "\n",
    "\n",
    "print(f'◆　説明変数と目的変数の間の決定係数R2')\n",
    "print('')\n",
    "print(f'◇ Nagelkerke の擬似R² (標準設定) = {pseudo_r2:.4f}')\n",
    "print(f'  擬似決係数R²の見方　0.2未満: 弱い説明力、0.2〜0.5: 中程度の説明力、0.5以上: 強い説明力')\n",
    "print('')\n",
    "print(f'◇ 線形回帰による決定係数R² = {r2:.4f}')\n",
    "print('   決定係数R²の見方　 0.3未満: 線形性なし、0.3〜0.5: 弱い線形性、0.5〜0.7: 中程度の線形性、0.7〜0.9: 強い線形性、0.9以上: 完全に線形')\n",
    "print('')\n",
    "print('  (擬似決係数R² > 0.5　または  決定係数R² > 0.7 のとき、線形性があると見なせる。二値分類では擬似R²の方が妥当)')\n",
    "print('')\n",
    "if pseudo_r2 >= 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性が見られるため、SVM の kernel と XGBoost の booster を線形にする。')\n",
    "    linear = 1\n",
    "elif pseudo_r2 < 0.5:\n",
    "    print('')\n",
    "    print('◇ データの線形性はそれほど見られないため、線形モデルの優先は行わない。')\n",
    "    linear = 0\n",
    "print('')\n",
    "print(f'linear = {linear:.1f}')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 残差プロット\n",
    "print('◆　線形モデルによる目的変数の予測値の残差プロット')\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('予測値', fontproperties=font_prop)\n",
    "plt.ylabel('残差', fontproperties=font_prop)\n",
    "plt.title('予測値と残差のプロット', fontproperties=font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 連続変数の場合の線形性の判定\n",
    "\n",
    "# # RESET（Regression Specification Error Test）\n",
    "# from statsmodels.stats.diagnostic import linear_reset\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "# ols = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "# print(linear_reset(ols, power=2))\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # 線形モデル vs 多項式モデル（2次項・3次項を加えたモデル）\n",
    "# poly2 = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "# score_lin = cross_val_score(LinearRegression(), X, y, cv=5, scoring=\"r2\").mean()\n",
    "# score_poly2 = cross_val_score(poly2, X, y, cv=5, scoring=\"r2\").mean()\n",
    "\n",
    "# print(\"線形モデル R²:\", score_lin)\n",
    "# print(\"2次多項式モデル R²:\", score_poly2)\n",
    "\n",
    "\n",
    "\n",
    "# 定数列を除外する関数\n",
    "def remove_constant_columns(df):\n",
    "    constant_columns = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_columns:\n",
    "        print(f'以下の定数列を除外します: {constant_columns}')\n",
    "        df = df.drop(columns=constant_columns)\n",
    "    else:\n",
    "        print('定数列は存在しません。')\n",
    "    return df\n",
    "\n",
    "# 欠損値を確認・除外する関数\n",
    "def check_missing_values(df_X, df_y):\n",
    "    missing_X = df_X.isnull().sum()\n",
    "    missing_y = df_y.isnull().sum()\n",
    "    if missing_X.sum() > 0:\n",
    "        print('説明変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_X = df_X.dropna()\n",
    "    if missing_y > 0:\n",
    "        print('目的変数に欠損値が含まれています。欠損値を除外します。')\n",
    "        df_y = df_y.dropna()\n",
    "    return df_X, df_y\n",
    "\n",
    "\n",
    "print('◆ 説明変数と目的変数のPearsonの相関係数: 線形な相関のみ')\n",
    "# 定数列の除外\n",
    "X0 = remove_constant_columns(X0)\n",
    "\n",
    "# 目的変数が定数か確認\n",
    "if y0.nunique() <= 1:\n",
    "    raise ValueError('目的変数 y0 が定数列です。相関係数を計算できません。')\n",
    "\n",
    "# 欠損値の除外\n",
    "X0, y0 = check_missing_values(X0, y0)\n",
    "\n",
    "\n",
    "# 各説明変数と目的変数との相関係数を計算\n",
    "correlations = {}\n",
    "for column in X0.columns:\n",
    "    correlations[column] = X0[column].corr(y0)\n",
    "\n",
    "# 相関係数をSeriesに変換\n",
    "correlation_series = pd.Series(correlations)\n",
    "\n",
    "# 絶対値の降順にソートし、元の符号を保持\n",
    "top_10_correlations = correlation_series.reindex(correlation_series.abs().sort_values(ascending=False).index).head(10)\n",
    "\n",
    "# Top 10の相関係数を昇べき順にソート\n",
    "sorted_top_10_correlations = top_10_correlations.sort_values(ascending=True)\n",
    "\n",
    "# 色を決定\n",
    "colors = ['skyblue' if val > 0 else 'lightcoral' for val in correlation_series.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(correlation_series.index, correlation_series.values, color=colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "\n",
    "print('□ 青は正の相関、赤は負の相関。　1に近いほど強い正の相関、-1に近いほど強い負の相関。0は線形での相関無し')\n",
    "print('□　　相関係数の絶対値Cの目安： C > 0.7 強い相関、0.4〜0.7 中程度の相関、0.2〜0.4 弱い相関　　C < 0.2 相関無し')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のPearsonの相関係数: 相関係数のTop 10 のみ')\n",
    "\n",
    "# Top 10 correlation colors\n",
    "top_10_colors = ['skyblue' if val > 0 else 'lightcoral' for val in sorted_top_10_correlations.values]\n",
    "\n",
    "# 水平のバープロットを作成\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(sorted_top_10_correlations.index, sorted_top_10_correlations.values, color=top_10_colors)\n",
    "plt.xlabel('Pearson Correlation Coefficient', fontproperties=font_prop)\n",
    "plt.ylabel('Features', fontproperties=font_prop)\n",
    "plt.title('Top 10 Pearson Correlation Coefficient between Features and Target Variable', fontproperties=font_prop)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "# y軸のラベルフォントを変更\n",
    "ax = plt.gca()\n",
    "for label in ax.get_yticklabels():\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.show()\n",
    "print('')\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# XiCorの相関係数のプロット関数\n",
    "print('◆ 説明変数と目的変数のChatterjee`sの相関係数: 非線形な相関も含む (参考値)')\n",
    "\n",
    "def xicor(x, y, ties=True):\n",
    "    np.random.seed(42)\n",
    "    n = len(x)\n",
    "    order = np.argsort(x)\n",
    "    ranked_y = np.argsort(np.argsort(y[order], kind='mergesort'))\n",
    "\n",
    "    if ties:\n",
    "        l = np.argsort(np.argsort(y[order], kind='max'))\n",
    "        r = ranked_y.copy()\n",
    "        return 1 - n * np.sum(np.abs(r[1:] - r[:-1])) / (2 * np.sum(l * (n - l)))\n",
    "    else:\n",
    "        return 1 - 3 * np.sum(np.abs(ranked_y[1:] - ranked_y[:-1])) / (n**2 - 1)\n",
    "\n",
    "def plot_xicor(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(size_x, size_y))\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor(df)\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◇ 説明変数と目的変数のChatterjee`sの相関係数: 相関係数のTop 10 のみ')\n",
    "def plot_xicor10(df):\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "    feature_names = df.columns[:-1]\n",
    "    correlations = []\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        corr = xicor(X[:, i], y)\n",
    "        correlations.append(corr)\n",
    "\n",
    "    sorted_indices = np.argsort(correlations)[-10:]  # 上位10の特徴量を選択\n",
    "    sorted_correlations = np.array(correlations)[sorted_indices]\n",
    "    sorted_feature_names = np.array(feature_names)[sorted_indices]\n",
    "\n",
    "    colors = ['skyblue' if corr > 0 else 'lightcoral' for corr in sorted_correlations]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  # グラフのサイズを調整\n",
    "    plt.barh(sorted_feature_names, sorted_correlations, color=colors)\n",
    "    plt.xlabel('XiCor Value', fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontproperties=font_prop)\n",
    "    plt.title('Top 10 XiCor Values for Features', fontproperties=font_prop)\n",
    "    # y軸のラベルフォントを変更\n",
    "    ax = plt.gca()\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontproperties(font_prop)\n",
    "    plt.show()\n",
    "\n",
    "plot_xicor10(df)\n",
    "print('')\n",
    "print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\thttps://arxiv.org/abs/1909.10140 参照')\n",
    "print('')\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time2 = start_time.strftime('%Y%m%d%H%M')\n",
    "\n",
    "\n",
    "# 出力ファイル\n",
    "filename0 = os.path.basename(path_table)\n",
    "filename = os.path.splitext(filename0)[0]\n",
    "filepath = path_table + '/AllEvaluationResultsFor' + filename + str(formatted_start_time2) + '.xlsx'\n",
    "filepath2 = path_table + '/AllAUCResultsFor' + filename + str(formatted_start_time2) + '.csv'\n",
    "print('◆　計算結果の出力先')\n",
    "print(filepath)\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "# 現在時刻（計算開始時）\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "formatted_start_time = start_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "formatted_start_time2 = start_time.strftime('%Y年%m月%d日 %H時%M分%')\n",
    "print(f'◆ Present Time (Start): {formatted_start_time}')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 各機械学習モデルの実行\n",
    "\n",
    "# データがそれほど大きくないとき\n",
    "if bigdata ==0:\n",
    "\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_S = LogisticKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_S = LassoKFoldS(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_N = RidgeKFoldN(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_S = RidgeKFoldS(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_S = SVMKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_CatBoost = CatBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    print('')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    res_list = [\n",
    "                res_linear,\n",
    "                                res_logistic_N,\n",
    "                                res_logistic_S,\n",
    "                                res_lasso_N,\n",
    "                                res_lasso_S,\n",
    "                                res_lasso_optuna_N,\n",
    "                                res_lasso_optuna_S,\n",
    "                                res_ridge_N,\n",
    "                                res_ridge_S,\n",
    "                                res_ridge_optuna_N,\n",
    "                                res_ridge_optuna_S,\n",
    "                                res_SVM_N,\n",
    "                                res_SVM_S,\n",
    "                                res_LDAn,\n",
    "                                res_LDAs,\n",
    "                                res_GaussianN,\n",
    "                                res_GaussianS,\n",
    "                                res_Gradient_Boosting,\n",
    "                                res_Adaboost,\n",
    "                                res_RandomForest,\n",
    "                                res_RandomForest_optuna,\n",
    "                                res_XGBoost,\n",
    "                                res_XGBoost_optuna,\n",
    "                                res_LightGBM,\n",
    "                                res_LightGBM_optuna,\n",
    "                                res_LightGBMTuner_optuna,\n",
    "                                res_CatBoost,\n",
    "                                res_YDF,\n",
    "                                res_YDF_optuna,\n",
    "                                res_MLPn,\n",
    "                                res_MLPs,\n",
    "                                res_TabNetN,\n",
    "                                res_TabNetS,\n",
    "                                res_TabNetN_optuna,\n",
    "                                res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    # res_listの最初の要素を表計算のための出力とする\n",
    "    results = pd.concat([item[0] for item in res_list], axis=0)\n",
    "    res_auc = [item[1] for item in res_list]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# データが大きいとき\n",
    "else:\n",
    "\n",
    "    # CatBoostとOptunaによるTabNet normalizedは長時間かかるため外してある。\n",
    "    print('')\n",
    "    res_linear = LinearKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_N = LogisticKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_logistic_S = LogisticKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_N = LassoKFoldN(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_S = LassoKFoldS(0.01)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_N = LassoKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_lasso_optuna_S = LassoKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_N = RidgeKFoldN(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_S = RidgeKFoldS(1.0)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_N = RidgeKFoldOptunaN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_ridge_optuna_S = RidgeKFoldOptunaS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_N = SVMKFoldN()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_SVM_S = SVMKFoldS()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAn = LinearDiscriminantAnalysisKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LDAs = LinearDiscriminantAnalysisKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianN = GaussianProcessKFold(scaler='norm')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_GaussianS = GaussianProcessKFold(scaler='stand')\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Gradient_Boosting = GradientBoostingKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_Adaboost = AdaBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest = RandomForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_RandomForest_optuna = RandomForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost = XGBoostKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_XGBoost_optuna = XGBoostOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM = LightGBMKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBM_optuna = LightGBMOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_LightGBMTuner_optuna = LightGBMTunerOptunaKFold()\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_CatBoost = CatBoostKFold()\n",
    "    # print('')\n",
    "    print('')\n",
    "    res_YDF = YggdrasilDecisionForestKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_YDF_optuna = YggdrasilDecisionForestOptunaKFold()\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPn = MLPKFold(scaler='norm', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_MLPs = MLPKFold(scaler='stand', n1=128, n2=32, max_iter=500)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN = TabNetKFoldN(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetS = TabNetKFoldS(n1=32, n2=32, step_size=20, max_epochs=100, batch_size=32)\n",
    "    print('')\n",
    "    print('')\n",
    "    res_TabNetN_optuna = TabNetOptunaKFoldN(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    print('')\n",
    "    # print('')\n",
    "    # res_TabNetS_optuna = TabNetOptunaKFoldS(max_epochs=100, batch_size=32, n_trials=20)\n",
    "    # print('')\n",
    "\n",
    "\n",
    "\n",
    "    # CatBoostとOptunaによるTabNet normalizedは長時間かかるため外してある。\n",
    "    res_list2 = [\n",
    "                res_linear,\n",
    "                res_logistic_N,\n",
    "                res_logistic_S,\n",
    "                res_lasso_N,\n",
    "                res_lasso_S,\n",
    "                res_lasso_optuna_N,\n",
    "                res_lasso_optuna_S,\n",
    "                res_ridge_N,\n",
    "                res_ridge_S,\n",
    "                res_ridge_optuna_N,\n",
    "                res_ridge_optuna_S,\n",
    "                res_SVM_N,\n",
    "                res_SVM_S,\n",
    "                res_LDAn,\n",
    "                res_LDAs,\n",
    "                res_GaussianN,\n",
    "                res_GaussianS,\n",
    "                res_Gradient_Boosting,\n",
    "                res_Adaboost,\n",
    "                res_RandomForest,\n",
    "                res_RandomForest_optuna,\n",
    "                res_XGBoost,\n",
    "                res_XGBoost_optuna,\n",
    "                res_LightGBM,\n",
    "                res_LightGBM_optuna,\n",
    "                res_LightGBMTuner_optuna,\n",
    "                # res_CatBoost,\n",
    "                res_YDF,\n",
    "                res_YDF_optuna,\n",
    "                res_MLPn,\n",
    "                res_MLPs,\n",
    "                res_TabNetN,\n",
    "                res_TabNetS,\n",
    "                res_TabNetN_optuna,\n",
    "                # res_TabNetS_optuna,\n",
    "]\n",
    "\n",
    "    results = pd.concat([item[0] for item in res_list2], axis=0)\n",
    "    res_auc = [item[1] for item in res_list2]\n",
    "    results.to_excel(filepath)\n",
    "\n",
    "\n",
    "# プロットの準備\n",
    "plt.figure(figsize=(14, 10))  # 図のサイズを少し大きく設定\n",
    "\n",
    "# AUCが大きい順にres_listの２番目のデータをソート。res_auc の各エントリは (fpr, tpr, auc, name) の形式\n",
    "data_sorted = sorted(res_auc, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# 最もAUCが高いエントリを取得\n",
    "if data_sorted:\n",
    "    top_auc = data_sorted[0][2]\n",
    "else:\n",
    "    top_auc = None\n",
    "\n",
    "# 各エントリをループしてプロット\n",
    "for idx, entry in enumerate(data_sorted):\n",
    "    fpr, tpr, auc, name = entry\n",
    "    # NaNが含まれているエントリはスキップ\n",
    "    if np.isnan(auc) or np.any(np.isnan(fpr)) or np.any(np.isnan(tpr)):\n",
    "        continue\n",
    "    # 最もAUCが高いエントリは太くプロット\n",
    "    if idx == 0:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=3.5)\n",
    "    else:\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=1.5)\n",
    "\n",
    "# 対角線のプロット\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='random prediction')\n",
    "\n",
    "# グラフの装飾\n",
    "plt.xlabel('False Positive Rate (FPR)', fontsize=14)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "plt.title('ROC Curves Comparison', fontsize=16)\n",
    "plt.grid(True)\n",
    "\n",
    "# アスペクト比を1に設定\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "# 軸の範囲を0から1に設定\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# 凡例を図の右側外側に配置\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, prop=font_prop)\n",
    "\n",
    "# レイアウトの調整\n",
    "plt.tight_layout()\n",
    "\n",
    "roc_plot_path = os.path.join(path_figure, \"all_ROC_curves.png\")\n",
    "plt.savefig(roc_plot_path, bbox_inches='tight')\n",
    "\n",
    "print('')\n",
    "print(\"■ Figure overlaying all the ROC curves by all the ML models\")\n",
    "print('')\n",
    "\n",
    "# プロットの表示\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print('')\n",
    "print(f\"■ All the ROC curves saved to: {roc_plot_path}\")\n",
    "print('')\n",
    "print('')\n",
    "\n",
    "\n",
    "\n",
    "# 計算終了時の現在時刻\n",
    "end_time = datetime.now()\n",
    "formatted_end_time = end_time.strftime('%Y年%m月%d日 %H時%M分%S秒')\n",
    "print(f'◆ Present Time (End): {formatted_end_time}')\n",
    "\n",
    "# 計算に要した時間（終了時刻 - 開始時刻）\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "# 時間、分、秒に分割して表示\n",
    "hours, remainder = divmod(elapsed_time.seconds, 3600)\n",
    "minutes, seconds = divmod(remainder, 60)\n",
    "print('')\n",
    "print(f'計算に要した時間: {hours} 時間, {minutes} 分, {seconds} 秒')\n",
    "print('')\n",
    "\n",
    "\n",
    "print('◆　計算結果の出力先')\n",
    "print('')\n",
    "print('1. 数値データ:   ' + path_table)\n",
    "print('')\n",
    "print('2. 画像データ:   ' + path_figure)\n",
    "print('')\n",
    "print('3. モデル:      ' + path_model)\n",
    "print('')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFMwQ-9G2Ndx"
   },
   "source": [
    "## 6) Model by Model (１つのモデルを評価)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6_VudSdyrO1"
   },
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEE9e0HI2O7m"
   },
   "outputs": [],
   "source": [
    "LinearKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbJIgP35qRk_"
   },
   "source": [
    "### 2. LassoKFoldN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIUogRXy2QBK"
   },
   "outputs": [],
   "source": [
    "LassoKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkTKMUukuC-N"
   },
   "source": [
    "### 3. LassoKFoldS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDSJ9F24uFFt"
   },
   "outputs": [],
   "source": [
    "LassoKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGkhXVGRWyGG"
   },
   "source": [
    "### 4. LassoKFoldOptunaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7E72NoEmW2g_"
   },
   "outputs": [],
   "source": [
    "LassoKFoldOptunaN(n_trials=50, target='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wk9YHQVPrqnd"
   },
   "source": [
    "### 5. LassoKFoldOptunaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4rPgvR9rtZi"
   },
   "outputs": [],
   "source": [
    "LassoKFoldOptunaS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LHI1mnEsSCR"
   },
   "source": [
    "### 6. RidgeKFoldN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4KbKzJ7r0ZO"
   },
   "outputs": [],
   "source": [
    "RidgeKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNgB5dm4zqMu"
   },
   "source": [
    "### 7. RidgeKFoldS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7NFDWQ2zBBY"
   },
   "outputs": [],
   "source": [
    "RidgeKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNVSAT0v1nnb"
   },
   "source": [
    "### 8. RidgeKFoldOptunaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8N60VT2o1doW"
   },
   "outputs": [],
   "source": [
    "RidgeKFoldOptunaN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fy2J7MWy1wOq"
   },
   "source": [
    "### 9. RidgeKFoldOptunaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPPiq9pg1yeX"
   },
   "outputs": [],
   "source": [
    "RidgeKFoldOptunaS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MV2M3WcHgsdx"
   },
   "source": [
    "### 10. LogisticKFoldN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-n7PjPMgvnq"
   },
   "outputs": [],
   "source": [
    "LogisticKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba5VTkIDZz8e"
   },
   "source": [
    "### 11. LogisticKFoldS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HY3T4pilZ186"
   },
   "outputs": [],
   "source": [
    "LogisticKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbX-VB5mcxFw"
   },
   "source": [
    "### 12. SVMKFoldN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S79QuIk8czfL"
   },
   "outputs": [],
   "source": [
    "SVMKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4lmvW1lc0Z2"
   },
   "source": [
    "### 13. SVMKFoldS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmAKEckEc2Kb"
   },
   "outputs": [],
   "source": [
    "SVMKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n3nOrxG8Q0n"
   },
   "source": [
    "### 14. RandomForestKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofU3n0JY8HYG"
   },
   "outputs": [],
   "source": [
    "RandomForestKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmG8wMg68T-U"
   },
   "source": [
    "### 15. RandomForestOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzLz6Jwq8XS7"
   },
   "outputs": [],
   "source": [
    "RandomForestOptunaKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBDR8k0ajmFe"
   },
   "source": [
    "### 16. XGBoostKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61yJ4q7RK6LS"
   },
   "outputs": [],
   "source": [
    "XGBoostKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOGrrKvQDq5v"
   },
   "source": [
    "### 17. XGBoostOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6padUu4jt_N"
   },
   "outputs": [],
   "source": [
    "XGBoostOptunaKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILUqMM-QbOKJ"
   },
   "source": [
    "### 18. LightGBMKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zdbufa7bRAH"
   },
   "outputs": [],
   "source": [
    "LightGBMKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Al5L24V3giry"
   },
   "source": [
    "### 19. LightGBMOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yc5dYL1ibSzd"
   },
   "outputs": [],
   "source": [
    "LightGBMOptunaKFold(target='logloss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vuILIaElTaV_"
   },
   "source": [
    "### 20. LightGBMTunerOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep9dCjx8TbdG"
   },
   "outputs": [],
   "source": [
    "LightGBMTunerOptunaKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CdRYo6dlekn"
   },
   "source": [
    "### 21. CatBoostKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzGMsIRhlgEf"
   },
   "outputs": [],
   "source": [
    "CatBoostKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BG7V4cflgj1"
   },
   "source": [
    "### 22. YggdrasilDecisionForestKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4zS1FUOlj-v"
   },
   "outputs": [],
   "source": [
    "YggdrasilDecisionForestKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4cQt3cHoO7o"
   },
   "source": [
    "### 23. YggdrasilDecisionForestOptunaKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFSmp2FglmPn"
   },
   "outputs": [],
   "source": [
    "YggdrasilDecisionForestOptunaKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-cjie5LxL6b"
   },
   "source": [
    "### 24. TabNetKFoldN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cNEpGDpmxNr9"
   },
   "outputs": [],
   "source": [
    "TabNetKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wi80OCYLxRe1"
   },
   "source": [
    "### 25. TabNetKFoldS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KavZ7eBxTdQ"
   },
   "outputs": [],
   "source": [
    "TabNetKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TS6pZka3xT6I"
   },
   "source": [
    "### 26. TabNetOptunaKFoldN ☜ GPUが必須"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BM7lMlaUxXlG"
   },
   "outputs": [],
   "source": [
    "TabNetOptunaKFoldN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lazAZj7mxYYq"
   },
   "source": [
    "### 27. TabNetOptunaKFoldS ☜ GPUが必須"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRr6bPHsxaiv"
   },
   "outputs": [],
   "source": [
    "TabNetOptunaKFoldS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yf0G22bHx98_"
   },
   "source": [
    "### 28. MLPKFold with normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqrfRG8xyAj6"
   },
   "outputs": [],
   "source": [
    "MLPKFold(scaler='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TnAt1tYyBDL"
   },
   "source": [
    "### 29. MLPKFold with standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rfALkvkyCnD"
   },
   "outputs": [],
   "source": [
    "MLPKFold(scaler='stand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9g0n0iEyEvH"
   },
   "source": [
    "### 30. GradientBoostingKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uc5EApZyyMJv"
   },
   "outputs": [],
   "source": [
    "GradientBoostingKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAfCcoWyzRjq"
   },
   "source": [
    "### 31. AdaBoostKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DtuwFNKkzTgl"
   },
   "outputs": [],
   "source": [
    "AdaBoostKFold()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYGJPYnAzUMN"
   },
   "source": [
    "### 32. LinearDiscriminantAnalysisKFold Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03dp8kILzfvY"
   },
   "outputs": [],
   "source": [
    "LinearDiscriminantAnalysisKFold(scaler='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CO7MKriP2k7G"
   },
   "source": [
    "### 33. LinearDiscriminantAnalysisKFold Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IPr_I8v2lih"
   },
   "outputs": [],
   "source": [
    "LinearDiscriminantAnalysisKFold(scaler='stand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t7OJAXKE2hQ"
   },
   "source": [
    "### 34. GaussianProcessKFold Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1k0TqprLE51d"
   },
   "outputs": [],
   "source": [
    "GaussianProcessKFold(scaler='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGd69mL9E6X_"
   },
   "source": [
    "### 35. GaussianProcessKFold Standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZvmHUc7E9N3"
   },
   "outputs": [],
   "source": [
    "GaussianProcessKFold(scaler='stand')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "czOpSYtHXsmr",
    "b_zxi3imc1pu",
    "xb9gyu3eqcb_",
    "-XX2xHF6qZog",
    "9Hl7zCEWKth7",
    "OBYYl0T2ymNH",
    "LZ_u_qyIZEqX",
    "oDlBFqFsugkP",
    "5ugZAIIkKnK4",
    "oFMwQ-9G2Ndx"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1OffPl7nY-7l1lteeaYg5ct2XmksSHJDE",
     "timestamp": 1717900022149
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
